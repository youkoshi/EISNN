{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2076c6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b35f2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# %matplotlib qt\n",
    "%matplotlib qt\n",
    "\n",
    "# Detect device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5095652",
   "metadata": {},
   "source": [
    "# Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1cae39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchELE(rootPath, ele_pattern = re.compile(r\"(.+?)_归档\")):\n",
    "    '''==================================================\n",
    "        Search all electrode directories in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            ele_pattern: electrode dir name patten\n",
    "        Returen:\n",
    "            ele_list: list of electrode directories\n",
    "        ==================================================\n",
    "    '''\n",
    "    ele_list = []\n",
    "    for i in os.listdir(rootPath):\n",
    "        match_ele = ele_pattern.match(i)\n",
    "        if match_ele:\n",
    "            ele_list.append([os.path.join(rootPath, i),match_ele.group(1)])\n",
    "    return ele_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627168fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-16 19:39:46.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mSearch in D:/Baihm/EISNN/Archive/ and find 218 electrodes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rootPath = \"D:/Baihm/EISNN/Archive/\"\n",
    "ele_list = SearchELE(rootPath)\n",
    "n_ele = len(ele_list)\n",
    "logger.info(f\"Search in {rootPath} and find {n_ele:03d} electrodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7dfda3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blacklist = [\n",
    "    '01067093',     # Not look like EIS\n",
    "    '01067094',     # Connection Error\n",
    "    '02017385',     # Connection Error\n",
    "    '05127177',     # Open to Short\n",
    "    '06047729',     # Open to Short\n",
    "    '06047730',     # Open to Short\n",
    "    '06047731',     # Open to Short\n",
    "    '09207024',     # Connection Error\n",
    "    '10017038',     # Connection Error\n",
    "    '10037050',     # Connection Error\n",
    "    '10047056',     # Connection Error\n",
    "    '10057069',     # Connection Error\n",
    "    '10057083',     # Always Open\n",
    "    '10057084',     # Chaos\n",
    "    '10057087',     # Connection Error\n",
    "    '22017367',     # Connection Error\n",
    "    '22017371',     # Chaos\n",
    "]\n",
    "\n",
    "GrayList = [\n",
    "    '10037051',     # Connection Error\n",
    "    '10037052',     # Connection Error\n",
    "    '10057071',     # Connection Error\n",
    "    '10067077',     # Wired Shape like connection error\n",
    "    '10150201',     # Wired Shape\n",
    "    '10150202',     # Wired Shape\n",
    "    '10150203',     # Wired Shape\n",
    "    '20037515',     # Wired Shape\n",
    "    '20037516',     # Wired Shape\n",
    "    '20037517',     # Wired Shape\n",
    "    '22037378',     # Connection Error\n",
    "    '22037380',     # Connection Error\n",
    "    '22047376',     # Connection Error\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5b4d92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-16 19:39:46.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [0/218]: D:/Baihm/EISNN/Archive/01037160_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [1/218]: D:/Baihm/EISNN/Archive/01037161_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [2/218]: D:/Baihm/EISNN/Archive/01037162_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [5/218]: D:/Baihm/EISNN/Archive/01067095_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [9/218]: D:/Baihm/EISNN/Archive/02027373_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [10/218]: D:/Baihm/EISNN/Archive/02027390_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [11/218]: D:/Baihm/EISNN/Archive/02027393_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [12/218]: D:/Baihm/EISNN/Archive/02027406_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:46.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [13/218]: D:/Baihm/EISNN/Archive/02027407_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [14/218]: D:/Baihm/EISNN/Archive/02027408_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [15/218]: D:/Baihm/EISNN/Archive/02027409_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [16/218]: D:/Baihm/EISNN/Archive/02027410_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [18/218]: D:/Baihm/EISNN/Archive/02067447_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [19/218]: D:/Baihm/EISNN/Archive/02067448_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [21/218]: D:/Baihm/EISNN/Archive/02067450_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [22/218]: D:/Baihm/EISNN/Archive/05087163_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [23/218]: D:/Baihm/EISNN/Archive/05087164_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [24/218]: D:/Baihm/EISNN/Archive/05097165_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [25/218]: D:/Baihm/EISNN/Archive/05097166_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [26/218]: D:/Baihm/EISNN/Archive/05107167_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [27/218]: D:/Baihm/EISNN/Archive/05107180_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [28/218]: D:/Baihm/EISNN/Archive/05117174_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [29/218]: D:/Baihm/EISNN/Archive/05117178_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [30/218]: D:/Baihm/EISNN/Archive/05127168_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [32/218]: D:/Baihm/EISNN/Archive/06017403_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [33/218]: D:/Baihm/EISNN/Archive/06017404_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [34/218]: D:/Baihm/EISNN/Archive/06017405_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [35/218]: D:/Baihm/EISNN/Archive/06017758_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [36/218]: D:/Baihm/EISNN/Archive/06017760_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [40/218]: D:/Baihm/EISNN/Archive/08260405_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [41/218]: D:/Baihm/EISNN/Archive/08260407_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:47.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [42/218]: D:/Baihm/EISNN/Archive/08260408_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [50/218]: D:/Baihm/EISNN/Archive/09047412_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [55/218]: D:/Baihm/EISNN/Archive/09047417_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [60/218]: D:/Baihm/EISNN/Archive/09047492_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [62/218]: D:/Baihm/EISNN/Archive/09060402_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [63/218]: D:/Baihm/EISNN/Archive/09060403_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [64/218]: D:/Baihm/EISNN/Archive/09190702_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [65/218]: D:/Baihm/EISNN/Archive/09190703_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [66/218]: D:/Baihm/EISNN/Archive/09190704_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [69/218]: D:/Baihm/EISNN/Archive/09207021_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [72/218]: D:/Baihm/EISNN/Archive/09207029_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [73/218]: D:/Baihm/EISNN/Archive/09207030_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [74/218]: D:/Baihm/EISNN/Archive/09207031_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [75/218]: D:/Baihm/EISNN/Archive/09230301_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [76/218]: D:/Baihm/EISNN/Archive/09230302_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [77/218]: D:/Baihm/EISNN/Archive/09230303_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [78/218]: D:/Baihm/EISNN/Archive/09230410_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [79/218]: D:/Baihm/EISNN/Archive/09230509_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:48.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [80/218]: D:/Baihm/EISNN/Archive/09230510_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [81/218]: D:/Baihm/EISNN/Archive/09230513_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [82/218]: D:/Baihm/EISNN/Archive/09230602_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [94/218]: D:/Baihm/EISNN/Archive/09231409_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [95/218]: D:/Baihm/EISNN/Archive/09250102_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [96/218]: D:/Baihm/EISNN/Archive/09250103_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [97/218]: D:/Baihm/EISNN/Archive/09250104_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [98/218]: D:/Baihm/EISNN/Archive/09250210_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [99/218]: D:/Baihm/EISNN/Archive/09290311_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [100/218]: D:/Baihm/EISNN/Archive/09290312_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [101/218]: D:/Baihm/EISNN/Archive/09290314_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [102/218]: D:/Baihm/EISNN/Archive/09290511_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [104/218]: D:/Baihm/EISNN/Archive/10017037_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [107/218]: D:/Baihm/EISNN/Archive/10037051_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [108/218]: D:/Baihm/EISNN/Archive/10037052_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [110/218]: D:/Baihm/EISNN/Archive/10047059_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [111/218]: D:/Baihm/EISNN/Archive/10047060_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [114/218]: D:/Baihm/EISNN/Archive/10057071_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [118/218]: D:/Baihm/EISNN/Archive/10067077_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:49.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [119/218]: D:/Baihm/EISNN/Archive/10067078_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [120/218]: D:/Baihm/EISNN/Archive/10067080_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [121/218]: D:/Baihm/EISNN/Archive/10080508_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [122/218]: D:/Baihm/EISNN/Archive/10080509_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [124/218]: D:/Baihm/EISNN/Archive/10080601_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [126/218]: D:/Baihm/EISNN/Archive/10080603_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [127/218]: D:/Baihm/EISNN/Archive/10080706_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [128/218]: D:/Baihm/EISNN/Archive/10080708_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [132/218]: D:/Baihm/EISNN/Archive/10150201_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [133/218]: D:/Baihm/EISNN/Archive/10150202_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [134/218]: D:/Baihm/EISNN/Archive/10150203_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [135/218]: D:/Baihm/EISNN/Archive/10160301_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [136/218]: D:/Baihm/EISNN/Archive/10160302_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [138/218]: D:/Baihm/EISNN/Archive/10210301_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [139/218]: D:/Baihm/EISNN/Archive/10210302_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [140/218]: D:/Baihm/EISNN/Archive/10210303_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [146/218]: D:/Baihm/EISNN/Archive/11037454_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [149/218]: D:/Baihm/EISNN/Archive/11037715_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:50.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [150/218]: D:/Baihm/EISNN/Archive/11037716_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [151/218]: D:/Baihm/EISNN/Archive/11037717_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [152/218]: D:/Baihm/EISNN/Archive/11047722_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [153/218]: D:/Baihm/EISNN/Archive/11047725_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [154/218]: D:/Baihm/EISNN/Archive/11047726_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [155/218]: D:/Baihm/EISNN/Archive/11050201_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [156/218]: D:/Baihm/EISNN/Archive/11050202_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [157/218]: D:/Baihm/EISNN/Archive/11050203_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [158/218]: D:/Baihm/EISNN/Archive/11057709_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [159/218]: D:/Baihm/EISNN/Archive/11057710_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [160/218]: D:/Baihm/EISNN/Archive/11057712_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [162/218]: D:/Baihm/EISNN/Archive/11067222_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [163/218]: D:/Baihm/EISNN/Archive/11067223_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [164/218]: D:/Baihm/EISNN/Archive/11067224_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [179/218]: D:/Baihm/EISNN/Archive/16037225_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [180/218]: D:/Baihm/EISNN/Archive/16037226_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [181/218]: D:/Baihm/EISNN/Archive/16037227_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [182/218]: D:/Baihm/EISNN/Archive/20037515_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:51.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [183/218]: D:/Baihm/EISNN/Archive/20037516_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [184/218]: D:/Baihm/EISNN/Archive/20037517_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [185/218]: D:/Baihm/EISNN/Archive/20057520_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [186/218]: D:/Baihm/EISNN/Archive/20057521_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [187/218]: D:/Baihm/EISNN/Archive/20067523_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [188/218]: D:/Baihm/EISNN/Archive/20067524_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [189/218]: D:/Baihm/EISNN/Archive/20067525_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [191/218]: D:/Baihm/EISNN/Archive/22017368_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [192/218]: D:/Baihm/EISNN/Archive/22017369_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [193/218]: D:/Baihm/EISNN/Archive/22017370_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [195/218]: D:/Baihm/EISNN/Archive/22017372_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [197/218]: D:/Baihm/EISNN/Archive/22027365_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [198/218]: D:/Baihm/EISNN/Archive/22027366_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [199/218]: D:/Baihm/EISNN/Archive/22037378_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [200/218]: D:/Baihm/EISNN/Archive/22037379_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [201/218]: D:/Baihm/EISNN/Archive/22037380_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [202/218]: D:/Baihm/EISNN/Archive/22047374_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [203/218]: D:/Baihm/EISNN/Archive/22047376_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [204/218]: D:/Baihm/EISNN/Archive/22047377_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [210/218]: D:/Baihm/EISNN/Archive/23177396_归档\u001b[0m\n",
      "\u001b[32m2025-04-16 19:39:52.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mELE [217/218]: D:/Baihm/EISNN/Archive/29036057_归档\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "847"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MODEL_SUFFIX = \"Matern12_Ver01\"\n",
    "\n",
    "all_data_list = []\n",
    "all_id_list = []\n",
    "\n",
    "_ch_pattern = re.compile(r\"ch_(\\d{3})\")\n",
    "\n",
    "for i in range(n_ele):\n",
    "# for i in range(3):\n",
    "    if ele_list[i][1] in Blacklist:\n",
    "        continue\n",
    "\n",
    "    fd_pt = os.path.join(ele_list[i][0], MODEL_SUFFIX, f\"{ele_list[i][1]}_{MODEL_SUFFIX}.pt\")\n",
    "    if not os.path.exists(fd_pt):\n",
    "        # logger.warning(f\"{fd_pt} does not exist\")\n",
    "        continue\n",
    "    data_pt = torch.load(fd_pt, weights_only=False)\n",
    "    _meta_group = data_pt[\"meta_group\"]\n",
    "    _data_group = data_pt[\"data_group\"]\n",
    "\n",
    "    n_day       = _meta_group[\"n_day\"]\n",
    "    n_ch        = _meta_group[\"n_ch\"]\n",
    "    n_valid_ch  = len(_data_group[\"Channels\"])\n",
    "\n",
    "    # ignore abnormal ele\n",
    "    if n_ch != 128 or n_valid_ch != n_ch:\n",
    "        if n_day < 5 or n_valid_ch <= 100:\n",
    "            continue\n",
    "\n",
    "    logger.info(f\"ELE [{i}/{n_ele}]: {ele_list[i][0]}\")\n",
    "\n",
    "\n",
    "    ele_data_list = []\n",
    "    ele_id_list = []\n",
    "    # Iteration by channel\n",
    "    for j in _data_group['Channels']:\n",
    "        _ch_data = _data_group[j][\"y_eval\"]\n",
    "        ele_data_list.append(_ch_data)\n",
    "\n",
    "        _ch_id = _ch_pattern.match(j)\n",
    "        _ch_id = int(_ch_id.group(1))\n",
    "\n",
    "        _id = [i, _ch_id] * np.shape(_ch_data)[0]\n",
    "        _id = np.array(_id).reshape(-1,2)\n",
    "        ele_id_list.append(_id)\n",
    "        \n",
    "    \n",
    "    all_data_list.append(ele_data_list)\n",
    "    all_id_list.append(ele_id_list)\n",
    "    \n",
    "    # ele_data_list = np.vstack(ele_data_list)\n",
    "    # all_data_list.append(ele_data_list)\n",
    "\n",
    "# all_data_list = np.vstack(all_data_list)\n",
    "# all_id_list = np.vstack(all_id_list)\n",
    "\n",
    "\n",
    "del data_pt, _meta_group, _data_group, _ch_data\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080fa61",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6bf01b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all2seq(data_list, id_list = None):\n",
    "    seq_data_list    = []\n",
    "    seq_id_list     = []\n",
    "    for i in range(len(data_list)):\n",
    "        for j in range(len(data_list[i])):\n",
    "            seq_data_list.append(data_list[i][j])\n",
    "            if id_list is not None:\n",
    "                seq_id_list.append(id_list[i][j])\n",
    "    return seq_data_list, seq_id_list\n",
    "\n",
    "def load_all2ch(data_list, id_list = None):\n",
    "    ch_data_list, ch_id_list = load_all2seq(data_list, id_list)\n",
    "    ch_data_list = np.vstack(ch_data_list)\n",
    "    if id_list is not None:\n",
    "        ch_id_list = np.vstack(ch_id_list)\n",
    "    return ch_data_list, ch_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ecafb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f596e",
   "metadata": {},
   "source": [
    "# EISVAE_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a479c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee210d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EISDataset_CNN(Dataset):\n",
    "    def __init__(self, data_list, id_list = None):\n",
    "        # data_list: n x m x k x l x 2 list\n",
    "        # n: number of electrodes\n",
    "        # m: number of channels\n",
    "        # k: number of timestamps\n",
    "        # l: number of freq as dimensions\n",
    "        # 2: real and imaginary parts after logrithm\n",
    "\n",
    "        _data, _id  = load_all2ch(data_list, id_list)\n",
    "        _data = [torch.tensor(x, dtype=torch.float32) for x in _data]\n",
    "\n",
    "        self.data = _data\n",
    "        self.id = _id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return [2,101] for Conv1D\n",
    "        return self.data[idx].permute(1,0)  # [2,101] [in_ch, in_dim]\n",
    "    \n",
    "class EISVAE_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Layer Parameters\n",
    "        self.in_ch  = 2\n",
    "        self.in_dim = 101\n",
    "        self.hid_ch = 16\n",
    "        self.z_dim  = 32\n",
    "        self.k      = 5\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1  = nn.Conv1d(self.in_ch, self.hid_ch, kernel_size=self.k, stride=1, padding=self.k//2)\n",
    "        self.bn1   = nn.BatchNorm1d(self.hid_ch)\n",
    "        # self.ln1    = nn.LayerNorm(self.hid_ch)\n",
    "\n",
    "        # self.pool1  = nn.AdaptiveAvgPool1d(1)\n",
    "        self.pool1  = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc_mu  = nn.Linear(self.hid_ch, self.z_dim)\n",
    "        self.fc_lv  = nn.Linear(self.hid_ch, self.z_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc_dec = nn.Linear(self.z_dim, self.hid_ch * self.in_dim)\n",
    "        self.deconv = nn.Conv1d(self.hid_ch, self.in_ch, kernel_size=self.k, padding=self.k//2)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.bn1(self.conv1(x)))  # [B,hid_ch,in_dim]\n",
    "        h = self.pool1(h).squeeze(-1)         # [B,hid_ch]\n",
    "\n",
    "        # h = self.conv1(x)                   # [B,hid_ch,in_dim]\n",
    "        # h = h.permute(0, 2, 1)              # [B,in_dim,hid_ch]\n",
    "        # h = self.ln1(h)                     # [B,in_dim,hid_ch]\n",
    "        # h = F.relu(h)                       # [B,in_dim,hid_ch]\n",
    "        # h = h.permute(0, 2, 1)              # [B,hid_ch,in_dim]\n",
    "\n",
    "        # h = self.pool1(h).squeeze(-1)        # [B,hid_ch]\n",
    "\n",
    "        return self.fc_mu(h), self.fc_lv(h) # [B,z_dim], [B,z_dim]\n",
    "\n",
    "    def reparam(self, mu, logvar):\n",
    "        std = (0.5 * logvar).exp()\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.fc_dec(z)                  # [B,hid_ch]\n",
    "        h = h.view(-1, self.conv1.out_channels, self.in_dim)  # [B,hid_ch,in_dim]\n",
    "        return self.deconv(h)               # [B,in_ch,in_dim]\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, lv = self.encode(x)\n",
    "        z = self.reparam(mu, lv)\n",
    "        x_rec = self.decode(z)\n",
    "        return x_rec, mu, lv\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45aa73",
   "metadata": {},
   "source": [
    "## Tran & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ebd1b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x_rec, x, mu, logvar, kld_weight=1e-3):\n",
    "    rec = F.mse_loss(x_rec, x)\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return rec + kld_weight * kld\n",
    "\n",
    "# ===== 训练函数 =====\n",
    "def train_EISVAECNN(model, train_list, val_list, num_epochs=20, batch_size=64, lr=1e-3):\n",
    "    train_ds = EISDataset_CNN(train_list)\n",
    "    val_ds   = EISDataset_CNN(val_list)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss_recorder = []\n",
    "    eval_loss_recorder = []\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x in train_loader:\n",
    "            x = x.to(device)\n",
    "\n",
    "            x_rec, mu, lv = model(x)\n",
    "            loss = vae_loss(x_rec, x, mu, lv)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x in val_loader:\n",
    "                x = x.to(device)\n",
    "\n",
    "                x_rec, mu, lv = model(x)\n",
    "                loss = vae_loss(x_rec, x, mu, lv)\n",
    "                # mu, lv = model.encode(x)\n",
    "                # x_rec = model.decode(mu)\n",
    "                # loss = vae_loss(x_rec, x, mu, lv)\n",
    "                \n",
    "                val_loss += loss.item() * x.size(0)\n",
    "\n",
    "        train_loss /= len(train_ds)\n",
    "        val_loss   /= len(val_ds)\n",
    "\n",
    "        train_loss_recorder.append(train_loss)\n",
    "        eval_loss_recorder.append(val_loss)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}  Train: {train_loss:.6f}  Val: {val_loss:.6f}\")\n",
    "\n",
    "    return model, train_loss_recorder, eval_loss_recorder\n",
    "\n",
    "\n",
    "# ===== 可视化重建 =====\n",
    "def visualize_EISVAECNN(model, data_list, num=5):\n",
    "    ds = EISDataset_CNN(data_list)\n",
    "    loader = DataLoader(ds, batch_size=num, shuffle=True)\n",
    "    x = next(iter(loader)).to(device)   # [num,2,101]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_rec, mu, lv = model(x)\n",
    "\n",
    "    x = x.cpu().numpy()\n",
    "    x_rec = x_rec.cpu().numpy()\n",
    "\n",
    "    for i in range(num):\n",
    "        plt.figure(figsize=(6,3))\n",
    "        # 实部\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x[i,0], label=\"orig\")\n",
    "        plt.plot(x_rec[i,0], '--', label=\"rec\")\n",
    "        plt.title(f\"Sample {i} Real\")\n",
    "        plt.legend()\n",
    "        # 虚部\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(x[i,1], label=\"orig\")\n",
    "        plt.plot(x_rec[i,1], '--', label=\"rec\")\n",
    "        plt.title(f\"Sample {i} Imag\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98113e63",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f67a9979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54786\n"
     ]
    }
   ],
   "source": [
    "vae_cnn = EISVAE_CNN().to(device)\n",
    "print(count_parameters(vae_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "533d493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50  Train: 0.934713  Val: 0.077396\n",
      "Epoch 2/50  Train: 0.064415  Val: 0.043070\n",
      "Epoch 3/50  Train: 0.046682  Val: 0.034819\n",
      "Epoch 4/50  Train: 0.041548  Val: 0.034531\n",
      "Epoch 5/50  Train: 0.038677  Val: 0.026297\n",
      "Epoch 6/50  Train: 0.037090  Val: 0.025684\n",
      "Epoch 7/50  Train: 0.034826  Val: 0.029447\n",
      "Epoch 8/50  Train: 0.033338  Val: 0.022685\n",
      "Epoch 9/50  Train: 0.032089  Val: 0.031085\n",
      "Epoch 10/50  Train: 0.029957  Val: 0.034249\n",
      "Epoch 11/50  Train: 0.028945  Val: 0.025520\n",
      "Epoch 12/50  Train: 0.028416  Val: 0.022151\n",
      "Epoch 13/50  Train: 0.027731  Val: 0.021714\n",
      "Epoch 14/50  Train: 0.026826  Val: 0.020643\n",
      "Epoch 15/50  Train: 0.026423  Val: 0.020434\n",
      "Epoch 16/50  Train: 0.025923  Val: 0.019325\n",
      "Epoch 17/50  Train: 0.025127  Val: 0.018264\n",
      "Epoch 18/50  Train: 0.025183  Val: 0.021697\n",
      "Epoch 19/50  Train: 0.024773  Val: 0.020805\n",
      "Epoch 20/50  Train: 0.024102  Val: 0.019732\n",
      "Epoch 21/50  Train: 0.023932  Val: 0.018427\n",
      "Epoch 22/50  Train: 0.023751  Val: 0.025145\n",
      "Epoch 23/50  Train: 0.023142  Val: 0.019886\n",
      "Epoch 24/50  Train: 0.023620  Val: 0.018464\n",
      "Epoch 25/50  Train: 0.022910  Val: 0.023143\n",
      "Epoch 26/50  Train: 0.022888  Val: 0.023472\n",
      "Epoch 27/50  Train: 0.022634  Val: 0.018746\n",
      "Epoch 28/50  Train: 0.022601  Val: 0.020708\n",
      "Epoch 29/50  Train: 0.022574  Val: 0.037990\n",
      "Epoch 30/50  Train: 0.022025  Val: 0.018767\n",
      "Epoch 31/50  Train: 0.021883  Val: 0.018123\n",
      "Epoch 32/50  Train: 0.022037  Val: 0.018331\n",
      "Epoch 33/50  Train: 0.021538  Val: 0.024781\n",
      "Epoch 34/50  Train: 0.021379  Val: 0.033978\n",
      "Epoch 35/50  Train: 0.021454  Val: 0.019627\n",
      "Epoch 36/50  Train: 0.021226  Val: 0.018160\n",
      "Epoch 37/50  Train: 0.021248  Val: 0.017111\n",
      "Epoch 38/50  Train: 0.020729  Val: 0.021147\n",
      "Epoch 39/50  Train: 0.020667  Val: 0.030043\n",
      "Epoch 40/50  Train: 0.020524  Val: 0.016524\n",
      "Epoch 41/50  Train: 0.019411  Val: 0.015973\n",
      "Epoch 42/50  Train: 0.018991  Val: 0.017474\n",
      "Epoch 43/50  Train: 0.018791  Val: 0.022149\n",
      "Epoch 44/50  Train: 0.018501  Val: 0.015524\n",
      "Epoch 45/50  Train: 0.018495  Val: 0.023428\n",
      "Epoch 46/50  Train: 0.018475  Val: 0.017639\n",
      "Epoch 47/50  Train: 0.017947  Val: 0.018794\n",
      "Epoch 48/50  Train: 0.018142  Val: 0.019220\n",
      "Epoch 49/50  Train: 0.018243  Val: 0.015338\n",
      "Epoch 50/50  Train: 0.018078  Val: 0.019087\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size=128\n",
    "lr=1e-3\n",
    "random_state = None\n",
    "\n",
    "train_list, val_list = train_test_split(all_data_list, test_size=0.2, random_state=random_state)\n",
    "vae_cnn, train_loss, eval_loss = train_EISVAECNN(vae_cnn, train_list, val_list, num_epochs=num_epochs, batch_size=batch_size, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f73341b",
   "metadata": {},
   "source": [
    "### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9ed1e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.semilogy(train_loss, label=\"train\")\n",
    "# plt.semilogy(eval_loss, label=\"eval\")\n",
    "plt.semilogy(train_loss, label=\"train\")\n",
    "plt.semilogy(eval_loss, label=\"eval\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472660b0",
   "metadata": {},
   "source": [
    "### Plot Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3612577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_EISVAECNN(vae_cnn, val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d8460",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "16a40cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_latent(model, dataset, batch_size=64):\n",
    "    # x: [B,2,101]\n",
    "    ds = EISDataset_CNN(dataset)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    _len_data = ds.__len__()\n",
    "    _poi = 0\n",
    "\n",
    "    latent_space_inst = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            x = x.to(device)\n",
    "            mu, lv = model.encode(x)\n",
    "            latent_space_inst.append(mu.cpu().numpy())\n",
    "\n",
    "            _poi = _poi + x.size(0)\n",
    "            if _poi % 1000 == 0:\n",
    "                logger.info(f\"[{_poi}]/[{_len_data}]\")\n",
    "\n",
    "    latent_space_inst = np.concatenate(latent_space_inst, axis=0)  # [B,z_dim]\n",
    "\n",
    "    if latent_space_inst.shape[1] > 2:\n",
    "        _pca_inst = PCA(n_components=2)\n",
    "        latent_dd = _pca_inst.fit_transform(latent_space_inst)\n",
    "    else:\n",
    "        latent_dd = latent_space_inst\n",
    "\n",
    "    return latent_dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8034d57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-15 17:56:07.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[8000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:07.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[16000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:07.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[24000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:07.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[32000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:07.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[40000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:07.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[48000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:07.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[56000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:07.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[64000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[72000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[80000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[88000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[96000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[104000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[112000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[120000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[128000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[136000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[144000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[152000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[160000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[168000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[176000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:08.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[184000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[192000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[200000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[208000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[216000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[224000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[232000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[240000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[248000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[256000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[264000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[272000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[280000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[288000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[296000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:09.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[304000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:10.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[312000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:10.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[320000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:56:10.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[328000]/[333535]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "latent_expr = VAE_latent(vae_cnn, all_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b8ff0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.scatter(latent_expr[:, 0], -latent_expr[:, 1], alpha=0.5, s = 0.001)\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title(\"Latent Space\")\n",
    "plt.xlabel(\"Latent Dimension 1\")\n",
    "plt.ylabel(\"Latent Dimension 2\")\n",
    "# plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b8a8e",
   "metadata": {},
   "source": [
    "# EISVAE_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d4f1e2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333535, 202)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,_ = load_all2ch(all_data_list, all_id_list)\n",
    "b = np.concatenate((a[:,:,0],a[:,:,1]), axis=1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04788d42",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2d6b5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EISDataset_DNN(Dataset):\n",
    "    def __init__(self, data_list, id_list = None):\n",
    "        # data_list: n x m x k x l x 2 list\n",
    "        # n: number of electrodes\n",
    "        # m: number of channels\n",
    "        # k: number of timestamps\n",
    "        # l: number of freq as dimensions\n",
    "        # 2: real and imaginary parts after logrithm\n",
    "\n",
    "        _data, _id  = load_all2ch(data_list, id_list)\n",
    "        _data       = np.concatenate((_data[:,:,0],_data[:,:,1]), axis=1)  # [n,2,101] -> [n,202]\n",
    "        # _id         = np.concatenate((_id[:,:,0],_id[:,:,1]), axis=1)  # [n,2,101] -> [n,202]\n",
    "        _data       = [torch.tensor(x, dtype=torch.float32) for x in _data]\n",
    "\n",
    "        self.data   = _data\n",
    "        self.id     = _id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]  # [202] [in_ch x in_dim]\n",
    "    \n",
    "class EISVAE_DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Layer Parameters\n",
    "        self.input_dim=202\n",
    "        self.hidden_dims=[512,256,128,64]\n",
    "        self.z_dim  = 2\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        hidden_dims = self.hidden_dims\n",
    "        z_dim = self.z_dim\n",
    "\n",
    "# --- Encoder ---\n",
    "        self.enc_fc1 = nn.Linear(input_dim, hidden_dims[0])  # 160 → 512\n",
    "        self.enc_fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])  # 512 → 256\n",
    "        self.enc_fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])  # 256 → 128\n",
    "        self.enc_fc4 = nn.Linear(hidden_dims[2], hidden_dims[3])  # 128 → 64\n",
    "        # mean & logvar\n",
    "        self.fc_mu    = nn.Linear(hidden_dims[3], z_dim)     # 64 → 2\n",
    "        self.fc_logvar= nn.Linear(hidden_dims[3], z_dim)     # 64 → 2\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.dec_fc1 = nn.Linear(z_dim,        hidden_dims[3])  # 2 → 64\n",
    "        self.dec_fc2 = nn.Linear(hidden_dims[3], hidden_dims[2])# 64 → 128\n",
    "        self.dec_fc3 = nn.Linear(hidden_dims[2], hidden_dims[1])# 128 → 256\n",
    "        self.dec_fc4 = nn.Linear(hidden_dims[1], hidden_dims[0])# 256 → 512\n",
    "        self.dec_fc5 = nn.Linear(hidden_dims[0], input_dim)     # 512 → 160\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.enc_fc1(x))\n",
    "        h = F.relu(self.enc_fc2(h))\n",
    "        h = F.relu(self.enc_fc3(h))\n",
    "        h = F.relu(self.enc_fc4(h))\n",
    "        mu     = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparam(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.dec_fc1(z))\n",
    "        h = F.relu(self.dec_fc2(h))\n",
    "        h = F.relu(self.dec_fc3(h))\n",
    "        h = F.relu(self.dec_fc4(h))\n",
    "        x_rec = self.dec_fc5(h)\n",
    "        return x_rec             # [B,in_ch,in_dim]\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, lv = self.encode(x)\n",
    "        z = self.reparam(mu, lv)\n",
    "        x_rec = self.decode(z)\n",
    "        return x_rec, mu, lv\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31a39b",
   "metadata": {},
   "source": [
    "## Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b8f795fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vae_loss(x_rec, x, mu, logvar, kld_weight=1e-3):\n",
    "    \"\"\"\n",
    "    重建误差 + KL 散度\n",
    "    \"\"\"\n",
    "    rec_loss = F.mse_loss(x_rec, x, reduction='mean')\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return rec_loss + kld_weight * kld\n",
    "\n",
    "def train_EISVAEDNN(model, train_list, val_list, num_epochs=20, batch_size=64, lr=1e-3):\n",
    "    train_ds = EISDataset_DNN(train_list)\n",
    "    val_ds   = EISDataset_DNN(val_list)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss_recorder = []\n",
    "    eval_loss_recorder = []\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x in train_loader:\n",
    "            x = x.to(device)\n",
    "            x_rec, mu, lv = model(x)\n",
    "            loss = vae_loss(x_rec, x, mu, lv)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x in val_loader:\n",
    "                x = x.to(device)\n",
    "                x_rec, mu, lv = model(x)\n",
    "                loss = vae_loss(x_rec, x, mu, lv)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "        train_loss /= len(train_ds)\n",
    "        val_loss   /= len(val_ds)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}  Train: {train_loss:.4f}  Val: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "        train_loss_recorder.append(train_loss)\n",
    "        eval_loss_recorder.append(val_loss)\n",
    "\n",
    "    return model, train_loss_recorder, eval_loss_recorder\n",
    "\n",
    "\n",
    "# ===== 可视化重建 =====\n",
    "def visualize_EISVAEDNN(model, data_list, num=5):\n",
    "    ds = EISDataset_DNN(data_list)\n",
    "    loader = DataLoader(ds, batch_size=num, shuffle=True)\n",
    "    x = next(iter(loader)).to(device)   # [num,2,101]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_rec, mu, lv = model(x)\n",
    "\n",
    "    x = x.cpu().numpy()\n",
    "    x_rec = x_rec.cpu().numpy()\n",
    "\n",
    "\n",
    "    for i in range(num):\n",
    "        plt.figure(figsize=(6,3))\n",
    "        # 实部\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x[i,:101], label=\"orig\")\n",
    "        plt.plot(x_rec[i,:101], '--', label=\"rec\")\n",
    "        plt.title(f\"Sample {i} Real\")\n",
    "        plt.legend()\n",
    "        # 虚部\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(x[i,101:], label=\"orig\")\n",
    "        plt.plot(x_rec[i,101:], '--', label=\"rec\")\n",
    "        plt.title(f\"Sample {i} Imag\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0aae4a",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1d55dd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553422\n"
     ]
    }
   ],
   "source": [
    "vae_dnn = EISVAE_DNN().to(device)\n",
    "print(count_parameters(vae_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d20808f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50  Train: 0.5635  Val: 0.0800\n",
      "Epoch 2/50  Train: 0.0654  Val: 0.0504\n",
      "Epoch 3/50  Train: 0.0431  Val: 0.0436\n",
      "Epoch 4/50  Train: 0.0363  Val: 0.0290\n",
      "Epoch 5/50  Train: 0.0322  Val: 0.0465\n",
      "Epoch 6/50  Train: 0.0284  Val: 0.0277\n",
      "Epoch 7/50  Train: 0.0270  Val: 0.0237\n",
      "Epoch 8/50  Train: 0.0251  Val: 0.0235\n",
      "Epoch 9/50  Train: 0.0236  Val: 0.0222\n",
      "Epoch 10/50  Train: 0.0239  Val: 0.0209\n",
      "Epoch 11/50  Train: 0.0311  Val: 0.0198\n",
      "Epoch 12/50  Train: 0.0222  Val: 0.0220\n",
      "Epoch 13/50  Train: 0.0222  Val: 0.0219\n",
      "Epoch 14/50  Train: 0.0324  Val: 0.0233\n",
      "Epoch 15/50  Train: 0.0239  Val: 0.0218\n",
      "Epoch 16/50  Train: 0.0230  Val: 0.0226\n",
      "Epoch 17/50  Train: 0.0218  Val: 0.0216\n",
      "Epoch 18/50  Train: 0.0214  Val: 0.0233\n",
      "Epoch 19/50  Train: 0.0220  Val: 0.0265\n",
      "Epoch 20/50  Train: 0.0209  Val: 0.0252\n",
      "Epoch 21/50  Train: 0.0259  Val: 0.0271\n",
      "Epoch 22/50  Train: 0.0209  Val: 0.0212\n",
      "Epoch 23/50  Train: 0.0211  Val: 0.0208\n",
      "Epoch 24/50  Train: 0.0209  Val: 0.0358\n",
      "Epoch 25/50  Train: 0.0214  Val: 0.0211\n",
      "Epoch 26/50  Train: 0.0200  Val: 0.0252\n",
      "Epoch 27/50  Train: 0.0198  Val: 0.0209\n",
      "Epoch 28/50  Train: 0.0194  Val: 0.0237\n",
      "Epoch 29/50  Train: 0.0193  Val: 0.0212\n",
      "Epoch 30/50  Train: 0.0190  Val: 0.0242\n",
      "Epoch 31/50  Train: 0.0194  Val: 0.0327\n",
      "Epoch 32/50  Train: 0.0194  Val: 0.0239\n",
      "Epoch 33/50  Train: 0.0190  Val: 0.0201\n",
      "Epoch 34/50  Train: 0.0199  Val: 0.0220\n",
      "Epoch 35/50  Train: 0.0193  Val: 0.0306\n",
      "Epoch 36/50  Train: 0.0192  Val: 0.0194\n",
      "Epoch 37/50  Train: 0.0198  Val: 0.0191\n",
      "Epoch 38/50  Train: 0.0196  Val: 0.0249\n",
      "Epoch 39/50  Train: 0.0198  Val: 0.0247\n",
      "Epoch 40/50  Train: 0.0212  Val: 0.0215\n",
      "Epoch 41/50  Train: 0.0198  Val: 0.0219\n",
      "Epoch 42/50  Train: 0.0194  Val: 0.0216\n",
      "Epoch 43/50  Train: 0.0191  Val: 0.0214\n",
      "Epoch 44/50  Train: 0.0189  Val: 0.0430\n",
      "Epoch 45/50  Train: 0.0186  Val: 0.0237\n",
      "Epoch 46/50  Train: 0.0183  Val: 0.0202\n",
      "Epoch 47/50  Train: 0.0183  Val: 0.0205\n",
      "Epoch 48/50  Train: 0.0181  Val: 0.0197\n",
      "Epoch 49/50  Train: 0.0179  Val: 0.0200\n",
      "Epoch 50/50  Train: 0.0179  Val: 0.0195\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size=128\n",
    "lr=1e-3\n",
    "random_state = None\n",
    "\n",
    "train_list, val_list = train_test_split(all_data_list, test_size=0.2, random_state=random_state)\n",
    "vae_dnn, train_loss, eval_loss = train_EISVAEDNN(vae_dnn, train_list, val_list, num_epochs=num_epochs, batch_size=batch_size, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1211919",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4438dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.semilogy(train_loss, label=\"train\")\n",
    "# plt.semilogy(eval_loss, label=\"eval\")\n",
    "plt.semilogy(train_loss, label=\"train\")\n",
    "plt.semilogy(eval_loss, label=\"eval\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8e42d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_EISVAEDNN(vae_dnn, val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc014dde",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "19e8be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_latent(model, dataset, batch_size=64):\n",
    "    # x: [B,2,101]\n",
    "    ds = EISDataset_DNN(dataset)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    _len_data = ds.__len__()\n",
    "    _poi = 0\n",
    "\n",
    "    latent_space_inst = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            x = x.to(device)\n",
    "            mu, lv = model.encode(x)\n",
    "            latent_space_inst.append(mu.cpu().numpy())\n",
    "\n",
    "            _poi = _poi + x.size(0)\n",
    "            if _poi % 1000 == 0:\n",
    "                logger.info(f\"[{_poi}]/[{_len_data}]\")\n",
    "\n",
    "    latent_space_inst = np.concatenate(latent_space_inst, axis=0)  # [B,z_dim]\n",
    "\n",
    "    if latent_space_inst.shape[1] > 2:\n",
    "        _pca_inst = PCA(n_components=2)\n",
    "        latent_dd = _pca_inst.fit_transform(latent_space_inst)\n",
    "    else:\n",
    "        latent_dd = latent_space_inst\n",
    "\n",
    "    return latent_dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ec264a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-15 17:33:34.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[8000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[16000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[24000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[32000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[40000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[48000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[56000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[64000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[72000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[80000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[88000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[96000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[104000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:34.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[112000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[120000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[128000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[136000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[144000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[152000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[160000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[168000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[176000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[184000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[192000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[200000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[208000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[216000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[224000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[232000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[240000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[248000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[256000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[264000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[272000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:35.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[280000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:36.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[288000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:36.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[296000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:36.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[304000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:36.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[312000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:36.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[320000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-15 17:33:36.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[328000]/[333535]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "latent_expr = VAE_latent(vae_dnn, all_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "479f4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.scatter(latent_expr[:, 0], -latent_expr[:, 1], alpha=0.5, s = 0.001)\n",
    "\n",
    "# plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title(\"Latent Space\")\n",
    "plt.xlabel(\"Latent Dimension 1\")\n",
    "plt.ylabel(\"Latent Dimension 2\")\n",
    "# plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407362a",
   "metadata": {},
   "source": [
    "# EISVAE_CNN_Ver02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e1e6e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EISDataset_CNN(Dataset):\n",
    "    def __init__(self, data_list, id_list = None):\n",
    "        # data_list: n x m x k x l x 2 list\n",
    "        # n: number of electrodes\n",
    "        # m: number of channels\n",
    "        # k: number of timestamps\n",
    "        # l: number of freq as dimensions\n",
    "        # 2: real and imaginary parts after logrithm\n",
    "\n",
    "        _data, _id  = load_all2ch(data_list, id_list)\n",
    "        _data = [torch.tensor(x, dtype=torch.float32) for x in _data]\n",
    "\n",
    "        self.data = _data\n",
    "        self.id = _id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return [2,101] for Conv1D\n",
    "        return self.data[idx].permute(1,0)  # [2,101] [in_ch, in_dim]\n",
    "   \n",
    "class Curve2VecEncoder(nn.Module):\n",
    "    def __init__(self, in_ch, in_dim, hid_ch, \n",
    "                 z_dim, kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        _layers = []\n",
    "        poi_ch = in_ch\n",
    "        for _ch in hid_ch:\n",
    "            _layers.append(nn.Conv1d(poi_ch, _ch, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "            _layers.append(nn.BatchNorm1d(_ch))\n",
    "            _layers.append(nn.ReLU())\n",
    "            poi_ch = _ch\n",
    "\n",
    "        if len(hid_ch) > 0:\n",
    "            self.conv = nn.Sequential(*_layers)\n",
    "            self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        else:\n",
    "            self.conv = nn.Identity()\n",
    "            self.pool = nn.Flatten(start_dim=1)\n",
    "\n",
    "        self.fc_mu = nn.Linear(poi_ch, z_dim)\n",
    "        self.fc_lv = nn.Linear(poi_ch, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)                # [B,ch,in_dim]\n",
    "        h = self.pool(h).squeeze(-1)    # [B,ch]\n",
    "        return self.fc_mu(h), self.fc_lv(h) \n",
    "\n",
    "\n",
    "class Curve2VecDecoder(nn.Module):\n",
    "    def __init__(self, out_ch, out_dim, hid_ch, \n",
    "                 z_dim, kernel_size):\n",
    "        super().__init__()\n",
    "        self.hid_ch = hid_ch\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "\n",
    "        self.hid_ch.append(out_ch)\n",
    "        poi_ch = self.hid_ch[0]\n",
    "\n",
    "        self.fc_expand = nn.Linear(z_dim, poi_ch * out_dim)\n",
    "\n",
    "        _layers = []\n",
    "        for _ch in self.hid_ch[1:]:\n",
    "            _layers.append(nn.ConvTranspose1d(poi_ch, _ch, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "            # _layers.append(nn.BatchNorm1d(_ch))\n",
    "            # _layers.append(nn.ReLU())\n",
    "            poi_ch = _ch\n",
    "        \n",
    "        self.deconv = nn.Sequential(*_layers)\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.fc_expand(z)           # [B,ch*in_dim]\n",
    "        h = h.view(-1, self.hid_ch[0], self.out_dim)\n",
    "        h = self.deconv(h)               # [B,in_ch,in_dim]\n",
    "        return h                        # [B,in_ch,in_dim]\n",
    "\n",
    "class Curve2VecVAE(nn.Module):\n",
    "    def __init__(self, in_ch=2, in_dim=101, \n",
    "                 enc_hid_ch = [16,32],\n",
    "                 dec_hid_ch = [16],\n",
    "                 z_dim = 16, kernel_size = 5):\n",
    "        super().__init__()\n",
    "        self.encoder = Curve2VecEncoder(in_ch, in_dim, enc_hid_ch, z_dim, kernel_size)\n",
    "        self.decoder = Curve2VecDecoder(in_ch, in_dim, dec_hid_ch, z_dim, kernel_size)\n",
    "\n",
    "    def reparam(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, lv = self.encoder(x)\n",
    "        z = self.reparam(mu, lv)\n",
    "        x_rec = self.decoder(z)\n",
    "        return x_rec, mu, lv \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec2818",
   "metadata": {},
   "source": [
    "## Tran & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "02d9c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x_rec, x, mu, logvar, kld_weight=1e-3):\n",
    "    rec = F.mse_loss(x_rec, x)\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return rec + kld_weight * kld\n",
    "\n",
    "# ===== 训练函数 =====\n",
    "def train_EISVAECNN(model, train_list, val_list, num_epochs=20, batch_size=64, lr=1e-3):\n",
    "    train_ds = EISDataset_CNN(train_list)\n",
    "    val_ds   = EISDataset_CNN(val_list)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss_recorder = []\n",
    "    eval_loss_recorder = []\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x in train_loader:\n",
    "            x = x.to(device)\n",
    "\n",
    "            x_rec, mu, lv = model(x)\n",
    "            loss = vae_loss(x_rec, x, mu, lv)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x in val_loader:\n",
    "                x = x.to(device)\n",
    "\n",
    "                x_rec, mu, lv = model(x)\n",
    "                loss = vae_loss(x_rec, x, mu, lv)\n",
    "                # mu, lv = model.encode(x)\n",
    "                # x_rec = model.decode(mu)\n",
    "                # loss = vae_loss(x_rec, x, mu, lv)\n",
    "                \n",
    "                val_loss += loss.item() * x.size(0)\n",
    "\n",
    "        train_loss /= len(train_ds)\n",
    "        val_loss   /= len(val_ds)\n",
    "\n",
    "        train_loss_recorder.append(train_loss)\n",
    "        eval_loss_recorder.append(val_loss)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}  Train: {train_loss:.6f}  Val: {val_loss:.6f}\")\n",
    "\n",
    "    return model, train_loss_recorder, eval_loss_recorder\n",
    "\n",
    "\n",
    "# ===== 可视化重建 =====\n",
    "def visualize_EISVAECNN(model, data_list, num=5):\n",
    "    ds = EISDataset_CNN(data_list)\n",
    "    loader = DataLoader(ds, batch_size=num, shuffle=True)\n",
    "    x = next(iter(loader)).to(device)   # [num,2,101]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_rec, mu, lv = model(x)\n",
    "\n",
    "    x = x.cpu().numpy()\n",
    "    x_rec = x_rec.cpu().numpy()\n",
    "\n",
    "    for i in range(num):\n",
    "        plt.figure(figsize=(6,3))\n",
    "        # 实部\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x[i,0], label=\"orig\")\n",
    "        plt.plot(x_rec[i,0], '--', label=\"rec\")\n",
    "        plt.title(f\"Sample {i} Real\")\n",
    "        plt.legend()\n",
    "        # 虚部\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(x[i,1], label=\"orig\")\n",
    "        plt.plot(x_rec[i,1], '--', label=\"rec\")\n",
    "        plt.title(f\"Sample {i} Imag\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840116a",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1bf149f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114274\n"
     ]
    }
   ],
   "source": [
    "vae_cnn = Curve2VecVAE().to(device)\n",
    "print(count_parameters(vae_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "865361a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size=128\n",
    "lr=1e-3\n",
    "random_state = None\n",
    "\n",
    "train_list, val_list = train_test_split(all_data_list, test_size=0.2, random_state=random_state)\n",
    "len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "cdf85442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20  Train: 0.485089  Val: 0.048830\n",
      "Epoch 2/20  Train: 0.042080  Val: 0.039679\n",
      "Epoch 3/20  Train: 0.035384  Val: 0.044900\n",
      "Epoch 4/20  Train: 0.029256  Val: 0.028124\n",
      "Epoch 5/20  Train: 0.025810  Val: 0.026033\n",
      "Epoch 6/20  Train: 0.023547  Val: 0.070596\n",
      "Epoch 7/20  Train: 0.021427  Val: 0.023325\n",
      "Epoch 8/20  Train: 0.019186  Val: 0.022017\n",
      "Epoch 9/20  Train: 0.017826  Val: 0.026279\n",
      "Epoch 10/20  Train: 0.016813  Val: 0.026739\n",
      "Epoch 11/20  Train: 0.016373  Val: 0.022048\n",
      "Epoch 12/20  Train: 0.015846  Val: 0.020739\n",
      "Epoch 13/20  Train: 0.015374  Val: 0.018574\n",
      "Epoch 14/20  Train: 0.014692  Val: 0.022532\n",
      "Epoch 15/20  Train: 0.014402  Val: 0.020956\n",
      "Epoch 16/20  Train: 0.013980  Val: 0.026401\n",
      "Epoch 17/20  Train: 0.013617  Val: 0.015903\n",
      "Epoch 18/20  Train: 0.013200  Val: 0.014884\n",
      "Epoch 19/20  Train: 0.012993  Val: 0.013660\n",
      "Epoch 20/20  Train: 0.012549  Val: 0.018641\n"
     ]
    }
   ],
   "source": [
    "vae_cnn, train_loss, eval_loss = train_EISVAECNN(vae_cnn, train_list, val_list, num_epochs=num_epochs, batch_size=batch_size, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b621aba",
   "metadata": {},
   "source": [
    "### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5f19cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.semilogy(train_loss, label=\"train\")\n",
    "# plt.semilogy(eval_loss, label=\"eval\")\n",
    "plt.semilogy(train_loss, label=\"train\")\n",
    "plt.semilogy(eval_loss, label=\"eval\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e51197",
   "metadata": {},
   "source": [
    "### Plot Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "1398d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_EISVAECNN(vae_cnn, val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4efb09",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ac7a87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_latent(model, dataset, batch_size=64):\n",
    "    # x: [B,2,101]\n",
    "    ds = EISDataset_CNN(dataset)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    _len_data = ds.__len__()\n",
    "    _poi = 0\n",
    "\n",
    "    latent_space_inst = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            x = x.to(device)\n",
    "            mu, lv = model.encoder(x)\n",
    "            latent_space_inst.append(mu.cpu().numpy())\n",
    "\n",
    "            _poi = _poi + x.size(0)\n",
    "            if _poi % 1000 == 0:\n",
    "                logger.info(f\"[{_poi}]/[{_len_data}]\")\n",
    "\n",
    "    latent_space_inst = np.concatenate(latent_space_inst, axis=0)  # [B,z_dim]\n",
    "\n",
    "    if latent_space_inst.shape[1] > 2:\n",
    "        _pca_inst = PCA(n_components=2)\n",
    "        latent_dd = _pca_inst.fit_transform(latent_space_inst)\n",
    "    else:\n",
    "        latent_dd = latent_space_inst\n",
    "\n",
    "    return latent_dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "91dcd3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-17 10:40:04.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[8000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:04.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[16000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:04.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[24000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[32000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[40000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[48000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[56000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[64000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[72000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[80000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[88000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[96000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[104000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[112000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[120000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:05.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[128000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[136000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[144000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[152000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[160000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[168000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[176000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[184000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[192000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[200000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[208000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[216000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[224000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[232000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:06.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[240000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[248000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[256000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[264000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[272000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[280000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[288000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[296000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[304000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[312000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[320000]/[333535]\u001b[0m\n",
      "\u001b[32m2025-04-17 10:40:07.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mVAE_latent\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[328000]/[333535]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "latent_expr = VAE_latent(vae_cnn, all_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "2c1c4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.scatter(latent_expr[:, 0], -latent_expr[:, 1], alpha=0.5, s = 0.001)\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title(\"Latent Space\")\n",
    "plt.xlabel(\"Latent Dimension 1\")\n",
    "plt.ylabel(\"Latent Dimension 2\")\n",
    "# plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce4b2b",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4718b90",
   "metadata": {},
   "source": [
    "## CNN + DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8fe39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, in_ch, in_dim, conv_channels, dense_dims, z_dim, kernel_size=3):\n",
    "#         super().__init__()\n",
    "#         layers = []\n",
    "#         prev_ch = in_ch\n",
    "#         for ch in conv_channels:\n",
    "#             layers.append(nn.Conv1d(prev_ch, ch, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "#             layers.append(nn.BatchNorm1d(ch))\n",
    "#             layers.append(nn.ReLU())\n",
    "#             prev_ch = ch\n",
    "#         self.conv = nn.Sequential(*layers)\n",
    "#         self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "#         prev_dim = conv_channels[-1]\n",
    "#         dense_layers = []\n",
    "#         for dim in dense_dims:\n",
    "#             dense_layers.append(nn.Linear(prev_dim, dim))\n",
    "#             dense_layers.append(nn.ReLU())\n",
    "#             prev_dim = dim\n",
    "#         self.dense = nn.Sequential(*dense_layers)\n",
    "\n",
    "#         self.fc_mu = nn.Linear(prev_dim, z_dim)\n",
    "#         self.fc_lv = nn.Linear(prev_dim, z_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         h = self.conv(x)              # [B, ch, in_dim]\n",
    "#         h = self.pool(h).squeeze(-1)  # [B, ch]\n",
    "#         h = self.dense(h)             # [B, dense_dim]\n",
    "#         return self.fc_mu(h), self.fc_lv(h)\n",
    "\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, z_dim, out_ch, out_dim, dense_dims, conv_channels, kernel_size=3):\n",
    "#         super().__init__()\n",
    "#         prev_dim = z_dim\n",
    "#         dense_layers = []\n",
    "#         for dim in dense_dims:\n",
    "#             dense_layers.append(nn.Linear(prev_dim, dim))\n",
    "#             dense_layers.append(nn.ReLU())\n",
    "#             prev_dim = dim\n",
    "#         self.dense = nn.Sequential(*dense_layers)\n",
    "\n",
    "#         self.fc_expand = nn.Linear(prev_dim, conv_channels[0] * out_dim)\n",
    "\n",
    "#         layers = []\n",
    "#         prev_ch = conv_channels[0]\n",
    "#         for ch in conv_channels[1:]:\n",
    "#             layers.append(nn.Conv1d(prev_ch, ch, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "#             layers.append(nn.BatchNorm1d(ch))\n",
    "#             layers.append(nn.ReLU())\n",
    "#             prev_ch = ch\n",
    "#         layers.append(nn.Conv1d(prev_ch, out_ch, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "#         self.conv = nn.Sequential(*layers)\n",
    "\n",
    "#         self.out_dim = out_dim\n",
    "#         self.conv_channels = conv_channels\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         h = self.dense(z)\n",
    "#         h = self.fc_expand(h)                            # [B, ch * dim]\n",
    "#         h = h.view(-1, self.conv_channels[0], self.out_dim)\n",
    "#         return self.conv(h)\n",
    "\n",
    "\n",
    "# class EISVAE(nn.Module):\n",
    "#     def __init__(self, in_ch=2, in_dim=101,\n",
    "#                  enc_hid_ch=[16, 32], enc_hid_dim=[64], \n",
    "#                  dec_hid_dim=[64], dec_hid_ch=[32, 16],\n",
    "#                  z_dim=32, kernel_size=3):\n",
    "#         super().__init__()\n",
    "#         self.encoder = Encoder(in_ch, in_dim, enc_hid_ch, enc_hid_dim, z_dim, kernel_size)\n",
    "#         self.decoder = Decoder(z_dim, in_ch, in_dim, dec_hid_dim, dec_hid_ch, kernel_size)\n",
    "\n",
    "#     def reparam(self, mu, logvar):\n",
    "#         std = torch.exp(0.5 * logvar)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return mu + eps * std\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         mu, lv = self.encoder(x)\n",
    "#         z = self.reparam(mu, lv)\n",
    "#         x_rec = self.decoder(z)\n",
    "#         return x_rec, mu, lv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
