{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from HETSFileHelper import gatherCSV, readChannel, EIS_recal_ver02\n",
    "from Outlier import OutlierDetection\n",
    "from EISGPR import Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filesys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchELE(rootPath, ele_pattern = re.compile(r\"(.+?)_归档\")):\n",
    "    '''==================================================\n",
    "        Search all electrode directories in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            ele_pattern: electrode dir name patten\n",
    "        Returen:\n",
    "            ele_list: list of electrode directories\n",
    "        ==================================================\n",
    "    '''\n",
    "    ele_list = []\n",
    "    for i in os.listdir(rootPath):\n",
    "        _path = os.path.join(rootPath, i)\n",
    "        if os.path.isdir(_path):\n",
    "            match_ele = ele_pattern.match(i)\n",
    "            if match_ele:\n",
    "                ele_list.append([_path, match_ele.group(1)])\n",
    "            else:\n",
    "                ele_list.extend(SearchELE(_path, ele_pattern))\n",
    "\n",
    "    return ele_list\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(log_dir=\"./LOG\", log_filename=\"file.log\", file_level=\"WARNING\", console_level=\"WARNING\"):\n",
    "    # 创建目录\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_fd = os.path.join(log_dir, log_filename)\n",
    "\n",
    "    logger.remove()\n",
    "    # 如果已有日志文件，重命名添加时间戳\n",
    "    if os.path.exists(log_fd):\n",
    "        name, ext = os.path.splitext(log_filename)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        archived_name = f\"{name}_{timestamp}{ext}\"\n",
    "        archived_path = os.path.join(log_dir, archived_name)\n",
    "        os.rename(log_fd, archived_path)\n",
    "\n",
    "    # 添加终端输出\n",
    "    logger.add(sys.stdout, level=console_level, enqueue=True)\n",
    "\n",
    "    # 添加文件输出\n",
    "    logger.add(log_fd, level=file_level, encoding=\"utf-8\", enqueue=True)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if False:\n",
    "    setup_logger(log_dir=\"D:\\Baihm\\EISNN\\LOG\\Outlier_vitro_04\")\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"WARNING\")\n",
    "logger.add(\"./LOG/file.log\", rotation=\"10 MB\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-01 16:12:11.812\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[33m\u001b[1mSearch in D:/Baihm/EISNN/Monkey and find 000 electrodes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INVIVO_FLAG = False\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/\"\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive_New/\"\n",
    "# rootPath = \"D:/Baihm/EISNN/Dataset/\"\n",
    "# rootPath = \"D:/Baihm/EISNN/Invivo\"\n",
    "# rootPath = \"D:/Baihm/EISNN/Monkey\"\n",
    "# \n",
    "# ele_list = SearchELE(rootPath, ele_pattern=re.compile(r\"(.+?)_归档\"))\n",
    "ele_list = SearchELE(rootPath, ele_pattern=re.compile(r\"(.+?)_Ver02\"))\n",
    "n_ele = len(ele_list)\n",
    "logger.warning(f\"Search in {rootPath} and find {n_ele:03d} electrodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each Electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SUFFIX = \"Outlier_Ver04\"\n",
    "SAVE_FLAG = True\n",
    "FORCE_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list   = np.linspace(0,5000-1,101,dtype=int, endpoint=True)\n",
    "if INVIVO_FLAG:\n",
    "    weirdModel = None\n",
    "else:\n",
    "    # weirdModel  = joblib.load(\"./weirdSVMmodel.pkl\")\n",
    "    weirdModel  = joblib.load(\"./weirdSVMmodel_20250516_01.pkl\")\n",
    "    # weirdModel  = None\n",
    "openModel   = joblib.load(\"./openSVMmodel.pkl\")\n",
    "phz_calibration = np.loadtxt(\"./phz_Calib.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_ele):\n",
    "# for i in range(0,1):\n",
    "    elePath = ele_list[i][0]\n",
    "    ele_id = ele_list[i][1]\n",
    "    logger.warning(f\"ELE[{i+1}/{n_ele}]: \\t{elePath}\")\n",
    "    \n",
    "\n",
    "    # Storage Preparing\n",
    "    save_dir = f\"{elePath}/{DATASET_SUFFIX}/\"\n",
    "    pt_file_name = f\"{ele_id}_{DATASET_SUFFIX}.pt\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    if os.path.exists(os.path.join(save_dir, pt_file_name)):\n",
    "        logger.warning(f\"FileAlreadyExistsWarning: {ele_id} - {pt_file_name} already exists.\")\n",
    "        if SAVE_FLAG and not FORCE_RUN:\n",
    "            continue\n",
    "\n",
    "\n",
    "    # Load EIS data\n",
    "    EISDict = gatherCSV(elePath)\n",
    "    n_day   = len(EISDict)\n",
    "    if n_day < 5:\n",
    "        logger.warning(f\"IllegalInputError: {ele_id} only has {n_day} samples.\")\n",
    "        continue\n",
    "    try:\n",
    "        x_day_full = [datetime.strptime(date, '%Y%m%d') for date in EISDict.keys()]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"IllegalDateError: {ele_id} has wrong date format. Please check the saving file. Error Code: {e}\")\n",
    "        continue\n",
    "\n",
    "    _key    = next(iter(EISDict))\n",
    "    n_ch    = len(EISDict[_key])\n",
    "    \n",
    "    if n_ch != 128:\n",
    "        logger.warning(f\"ChannelNumberWarning: {ele_id} only has {n_ch} channels.\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "\n",
    "    # Iteration for each channel\n",
    "    data_group = {}\n",
    "    data_group['Channels']    = []\n",
    "    ch_few_error   = []\n",
    "    ch_open_error  = []\n",
    "    ch_nan_error   = []\n",
    "    ch_good        = []\n",
    "\n",
    "    for j in range(n_ch):\n",
    "        try:\n",
    "             \n",
    "    # for j in range(2):\n",
    "    #     if True:\n",
    "            logger.warning(f\"ELE[{i+1}/{n_ele}] - ch[{j+1}/{n_ch}]\")\n",
    "            chData_full = readChannel(j, EISDict)\n",
    "            if chData_full is None:\n",
    "                logger.warning(f\"OutlierDetectionWarning: {ele_id} - CHID[{j}] readChannel failed.\")\n",
    "                continue\n",
    "            ## Outlier Detection\n",
    "            eis_seq, eis_cluster, eis_anomaly, leaf_anomaly, seq_weird = OutlierDetection.OutlierDetection_Ver02(chData_full, weirdModel=weirdModel, mask_flag=False)\n",
    "            seq_open, seq_short = OutlierDetection.OpenShortDetection(chData_full, mask_flag = False)\n",
    "\n",
    "            ## Bad Electrode Detection\n",
    "            # Too few normal samples \n",
    "            if np.shape(eis_seq)[0] < 5:\n",
    "                ch_few_error.append(j)\n",
    "                logger.warning(f\"OutlierDetectionWarning: {ele_id} - CHID[{j}] only has {np.shape(eis_seq)[0]} valid samples.\")\n",
    "                continue\n",
    "            \n",
    "            # All normal samples is open / First normal sample is open\n",
    "            if np.isin(eis_seq[0],seq_open):\n",
    "                ch_open_error.append(j)\n",
    "                logger.warning(f\"OutlierDetectionWarning: {ele_id} - CHID[{j}] in Open state.\")\n",
    "                continue\n",
    "                \n",
    "\n",
    "            ## Calibration\n",
    "            if not INVIVO_FLAG:\n",
    "                for k in range(np.shape(chData_full)[0]):\n",
    "                    ch_eis = EIS_recal_ver02(chData_full[k,:,:], phz_calibration)\n",
    "                    chData_full[k,:,:] = ch_eis\n",
    "\n",
    "            # chData = chData_full[:,:,freq_list]\n",
    "            chData = chData_full[:,:,:]\n",
    "            if np.isnan(chData).any():\n",
    "                ch_nan_error.append(j)\n",
    "                logger.warning(f\"OutlierDetectionWarning: {ele_id} - CHID[{j}] chData Invalid\")\n",
    "                continue\n",
    "\n",
    "            ch_good.append(j)\n",
    "\n",
    "\n",
    "            ## Data Saving\n",
    "\n",
    "            channel_group = {}\n",
    "            channel_group['chData']         = chData\n",
    "            channel_group['eis_seq']        = eis_seq\n",
    "            channel_group['eis_cluster']    = eis_cluster\n",
    "            channel_group['eis_anomaly']    = eis_anomaly\n",
    "            channel_group['leaf_anomaly']   = leaf_anomaly\n",
    "            channel_group['seq_weird']      = seq_weird\n",
    "            channel_group['seq_open']       = seq_open\n",
    "            channel_group['seq_short']      = seq_short\n",
    "\n",
    "            data_group[j] = channel_group\n",
    "            data_group['Channels'].append(j)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ## Plot\n",
    "            fig = plt.figure(figsize=(16, 9), constrained_layout=True)\n",
    "            text_axis = OutlierDetection.OutlierDetectionPlot(fig, chData, eis_seq, eis_cluster, eis_anomaly, leaf_anomaly, seq_weird, seq_open, seq_short)\n",
    "            font_properties = {\n",
    "                'family': 'monospace',  \n",
    "                'size': 14,             \n",
    "                'weight': 'bold'        \n",
    "            }\n",
    "\n",
    "            text = f\"EIE  : {ele_id}\\nCHID : {j:03d}\\nFrom : {x_day_full[0].strftime('%Y-%m-%d')}\\nTo   : {x_day_full[-1].strftime('%Y-%m-%d')}\"\n",
    "            text_axis.text(0.2, 0.5, text, fontdict = font_properties, ha='left', va='center')\n",
    "\n",
    "            # # Save Fig\n",
    "            if SAVE_FLAG:\n",
    "                fig_name = f\"EISPure_{ele_id}_ch{j:03d}.png\"\n",
    "                \n",
    "                os.makedirs(save_dir, exist_ok=True) \n",
    "                path = os.path.join(save_dir, fig_name)\n",
    "\n",
    "                fig.savefig(path)\n",
    "                plt.close(fig) \n",
    "            # else:\n",
    "                # fig.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ELE[{i+1}/{n_ele}] - ch[{j+1}/{n_ch}] Run with error: {e}\")\n",
    "            continue\n",
    "     \n",
    "    # Storage Preparing\n",
    "    pt_store = {}\n",
    "    meta_group = {}\n",
    "    meta_group[\"ele_id\"]    = ele_id\n",
    "    meta_group[\"elePath\"]   = elePath\n",
    "    meta_group[\"TimeSpan\"]  = x_day_full\n",
    "    meta_group[\"n_day\"]     = n_day\n",
    "\n",
    "    meta_group[\"n_ch\"]          = n_ch\n",
    "    meta_group[\"ch_few_error\"]  = ch_few_error\n",
    "    meta_group[\"ch_open_error\"] = ch_open_error\n",
    "    meta_group[\"ch_nan_error\"]  = ch_nan_error\n",
    "    meta_group[\"ch_good\"]       = ch_good\n",
    "\n",
    "    meta_group[\"Creater\"]   = \"Ming\"\n",
    "    meta_group['Date']      = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    pt_store['meta_group'] = meta_group\n",
    "    pt_store['data_group'] = data_group\n",
    "    if SAVE_FLAG:\n",
    "        torch.save(pt_store, os.path.join(save_dir, pt_file_name))\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    pt_name = \"D:\\Baihm\\EISNN\\Dataset\\BatchRunTestDataset\\\\03018905_归档\\Outlier_Ver02\\\\03018905_Outlier_Ver02.pt\"\n",
    "    loaded = torch.load(pt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _meta_group = loaded[\"meta_group\"]\n",
    "# _data_group = loaded[\"data_group\"]\n",
    "# n_valid_ch  = len(_data_group[\"Channels\"])\n",
    "# # _data_group[\"Channels\"]\n",
    "# _ch_data = _data_group[0][\"chData\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MODEL_SUFFIX = \"Matern12_Ver01\"\n",
    "\n",
    "# all_data_list = []\n",
    "\n",
    "# for i in range(n_ele):\n",
    "# # for i in range(3):\n",
    "#     fd_pt = os.path.join(ele_list[i][0], MODEL_SUFFIX, f\"{ele_list[i][1]}_{MODEL_SUFFIX}.pt\")\n",
    "#     if not os.path.exists(fd_pt):\n",
    "#         # logger.warning(f\"{fd_pt} does not exist\")\n",
    "#         continue\n",
    "#     data_pt = torch.load(fd_pt, weights_only=False)\n",
    "#     _meta_group = data_pt[\"meta_group\"]\n",
    "#     _data_group = data_pt[\"data_group\"]\n",
    "\n",
    "#     n_day       = _meta_group[\"n_day\"]\n",
    "#     n_ch        = _meta_group[\"n_ch\"]\n",
    "#     n_valid_ch  = len(_data_group[\"Channels\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
