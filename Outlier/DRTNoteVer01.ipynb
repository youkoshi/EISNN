{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pyDRTtools from c:\\Users\\Baihm\\anaconda3\\envs\\EISNN\\Lib\\site-packages\n",
      "['c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN\\\\python311.zip', 'c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN\\\\DLLs', 'c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN\\\\Lib', 'c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN', '', 'c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\Baihm\\\\anaconda3\\\\envs\\\\EISNN\\\\Lib\\\\site-packages\\\\Pythonwin']\n",
      "Imported basics\n",
      "Imported BHT\n",
      "Imported cli\n",
      "Imported GUI\n",
      "Imported HMC\n",
      "Imported layout\n",
      "Imported nearest_PD\n",
      "Imported parameter_selection\n",
      "Imported peak_analysis\n",
      "Imported runs\n",
      "Contents of pyDRTtools package: ['basics', 'GUI', 'layout', 'parameter_selection', 'peak_analysis', 'HMC', 'runs', 'nearest_PD']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from cvxopt import matrix, solvers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import re\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib qt\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import pyDRTtools as drt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherCSV(rootPath, outsuffix = 'Tracking'):\n",
    "    '''==================================================\n",
    "        Collect all EIS.csv files in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            outsuffix: Saving path of EIS.csv files\n",
    "        Returen:\n",
    "            EISDict: a 2D-dict of EIS data\n",
    "            Storage Frame: EISDict[_sessionIndex][_channelIndex] = \"_filepath\"\n",
    "        ==================================================\n",
    "    '''\n",
    "    _filename       = None\n",
    "    _filepath       = None\n",
    "    _trackpath      = None\n",
    "    _csvpath        = None\n",
    "    _sessionIndex   = None\n",
    "    _channelIndex   = None\n",
    "    _processed      = None\n",
    "\n",
    "    EISDict = defaultdict(dict)\n",
    "\n",
    "    ## Iterate session\n",
    "    session_pattern = re.compile(r\"(.+?)_(\\d{8})_01\")\n",
    "    bank_pattern    = re.compile(r\"([1-4])\")\n",
    "    file_pattern    = re.compile(r\"EIS_ch(\\d{3})\\.csv\")\n",
    "\n",
    "    ## RootDir\n",
    "    for i in os.listdir(rootPath):\n",
    "        match_session = session_pattern.match(i)\n",
    "        ## SessionDir\n",
    "        if match_session:\n",
    "            logger.info(f\"Session Begin: {i}\")\n",
    "            _sessionIndex = match_session[2]\n",
    "            for j in os.listdir(f\"{rootPath}/{i}\"):\n",
    "                match_bank = bank_pattern.match(j)\n",
    "                ## BankDir\n",
    "                if match_bank:\n",
    "                    logger.info(f\"Bank Begin: {j}\")\n",
    "                    _trackpath = f\"{rootPath}/{i}/{j}/{outsuffix}\"\n",
    "                    if not os.path.exists(_trackpath):\n",
    "                        continue\n",
    "\n",
    "                    for k in os.listdir(f\"{rootPath}/{i}/{j}/{outsuffix}\"):\n",
    "                        match_file = file_pattern.match(k)\n",
    "                        ## File\n",
    "                        if match_file:\n",
    "                            _filename = k\n",
    "                            _filepath = f\"{rootPath}/{i}/{j}/{outsuffix}/{k}\"\n",
    "                            _channelIndex = (int(match_bank[1])-1)*32+int(match_file[1])\n",
    "                            \n",
    "                            EISDict[_sessionIndex][_channelIndex] = f\"{rootPath}/{i}/{j}/{outsuffix}/{k}\"\n",
    "                            \n",
    "    return EISDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Readout\n",
    "def readChannel(chID, fileDict):\n",
    "    '''==================================================\n",
    "        Read EIS.csv file by Channel\n",
    "        Parameter: \n",
    "            chID: channel index\n",
    "            fileDict: EISDict[_sessionIndex][_channelIndex] = \"_filepath\"\n",
    "        Returen:\n",
    "            freq: frequency\n",
    "            Zreal: real part of impedance\n",
    "            Zimag: imaginary part of impedance\n",
    "        ==================================================\n",
    "    '''\n",
    "    chData = []\n",
    "    for ssID in fileDict.keys():\n",
    "        _data   = np.loadtxt(fileDict[ssID][chID], delimiter=',')\n",
    "        _freq   = _data[:,0]\n",
    "        _Zreal  = _data[:,3]\n",
    "        _Zimag  = _data[:,4]\n",
    "        chData.append(np.stack((_freq, _Zreal, _Zimag),axis=0))\n",
    "\n",
    "    return np.stack(chData, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EIS_recal_ver02(data, _phz_0 = None):\n",
    "    f_poi = data[0,:]\n",
    "    # Z_poi = data[1,:] * np.exp(1j*np.deg2rad(data[2,:]))\n",
    "    Z_poi = data[1,:] + 1j*data[2,:]\n",
    "    Y_poi = 1/Z_poi\n",
    "\n",
    "    Rg0 = 1.611e13\n",
    "    Cp0 = 1.4e-9\n",
    "    \n",
    "    _Rg0_rescale = 1/Rg0*np.power(f_poi,1.583)\n",
    "    _Cp0_rescale = Cp0*np.power(f_poi,0.911)\n",
    "    Y_org = Y_poi - _Rg0_rescale + 1j*_Cp0_rescale\n",
    "    # Y_org = Y_poi - _Rg0_rescale \n",
    "    # Y_org = Y_poi + 1j*_Cp0_rescale\n",
    "    # Y_org = Y_poi\n",
    "    Z_org = 1/Y_org\n",
    "\n",
    "    # Phz Calibration\n",
    "    if _phz_0 is None:\n",
    "        _phz_0 = np.loadtxt(\"./phz_Calib.txt\")\n",
    "    \n",
    "    Z_ampC = np.abs(Z_org)\n",
    "    # Z_phzC = np.angle(Z_org) - _phz_0\n",
    "    Z_phzC = np.angle(Z_org) - _phz_0\n",
    "\n",
    "    Z_rec = Z_ampC * np.exp(1j*Z_phzC)\n",
    "\n",
    "    # C = 5e-10\n",
    "    Rs0 = 100\n",
    "    Z_rec = Z_rec - Rs0\n",
    "\n",
    "\n",
    "\n",
    "    Cp0 = 5e-10\n",
    "    _Cp0_rescale = Cp0 * f_poi\n",
    "    Z_rec = 1/(1/Z_rec - 1j * _Cp0_rescale)\n",
    "\n",
    "    \n",
    "\n",
    "    # Ls0 = 1.7e-4\n",
    "    Ls0 = 5e-4\n",
    "    _Ls0_rescale = Ls0 * f_poi\n",
    "    Z_rec = Z_rec - 1j * _Ls0_rescale\n",
    "\n",
    "    # C = 5e-10\n",
    "    Rs0 = 566\n",
    "    Z_rec = Z_rec - Rs0\n",
    "    \n",
    "    return np.stack([f_poi, np.real(Z_rec), np.imag(Z_rec)], axis=1).T\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRT Pipeline - Full Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRT(ch_eis, RLC_Flag=[True, True, True], custom_lambda = None):\n",
    "    '''==================================================\n",
    "        DRT Calculation for EIS Data\n",
    "        Parameter: \n",
    "            ch_eis: 3 x n_freq Matrix: [freq, Real, Imag]\n",
    "        Returen:\n",
    "            tau_vec: time domain vector\n",
    "            x: DRT result\n",
    "            n_extend: number of extend RLC parameters\n",
    "        ==================================================\n",
    "    '''\n",
    "    ## Freq domain data prepare\n",
    "    n_freq = ch_eis.shape[1]\n",
    "    freq_vec = np.flip(ch_eis[0,:])     # Flip for growing tau = 1/freq\n",
    "    Z_exp = np.flip(ch_eis[1,:] + 1j*ch_eis[2,:])\n",
    "    '''Hyper Parameters'''\n",
    "    # Time domain parameters\n",
    "    tau_min = 1/freq_vec[0]\n",
    "    tau_max = 1/freq_vec[-1]\n",
    "    n_tau = n_freq\n",
    "    tau_vec = 1/(2*np.pi*freq_vec)\n",
    "    # tau_vec = 1/(2*np.pi*100*freq_vec)\n",
    "    # tau_vec = np.logspace(-10, 2, n_tau, endpoint=True)\n",
    "\n",
    "    # log_tau = np.log(tau_vec)\n",
    "    # tau_vec = np.logspace(-6, 0, n_tau, endpoint=True)\n",
    "    # freq_vec = np.flip(np.logspace(0, 6, n_freq, endpoint=True))\n",
    "    \n",
    "\n",
    "\n",
    "    # Discretization matrices Parameters\n",
    "    # Use RBF Kernel to initialize the A matrix\n",
    "    RBF_shape_control = 'FWHM Coefficient' \n",
    "    RBF_coeff = 0.5\n",
    "    # RBF_type = 'Piecewise Linear'\n",
    "    RBF_type = 'Gaussian'\n",
    "    # RBF_type = 'C0 Matern'\n",
    "    # RBF_type = 'C2 Matern'\n",
    "    # RBF_type = 'C4 Matern'\n",
    "    # RBF_type = 'C6 Matern'\n",
    "    # RBF_type = 'Inverse Quadratic'\n",
    "\n",
    "    # Cross-validation Method for optimize lambda (Tikhonov regularization parameter) \n",
    "    # cv_type = 'GCV'     # Generalized Cross Validation\n",
    "    # cv_type = 'mGCV'    # Modified Generalized Cross Validation\n",
    "    cv_type = 'rGCV'    # Robust Generalized Cross Validation\n",
    "    # cv_type = 'LC'      # L-curve\n",
    "    # cv_type = 're-im'   # Real-Imaginary discrepancy\n",
    "    # cv_type = 'kf'      # k-fold cross-validation\n",
    "\n",
    "    '''Compute the RBF Shape Parameter Epsilon'''\n",
    "    epsilon = drt.basics.compute_epsilon(freq_vec, RBF_coeff, RBF_type, RBF_shape_control)\n",
    "\n",
    "    # logger.info(f\"{epsilon}\")\n",
    "    # return\n",
    "    '''Compute the discretization matrices'''\n",
    "    A_re = drt.basics.assemble_A_re(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    n_extend = np.sum(RLC_Flag)   \n",
    "    if RLC_Flag[2]:\n",
    "        A_re_C_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_C_0, A_re)) \n",
    "    if RLC_Flag[1]:\n",
    "        A_re_L_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_L_0, A_re))\n",
    "    if RLC_Flag[0]:\n",
    "        A_re_R_inf  = np.ones((n_freq, 1))\n",
    "        A_re        = np.hstack((A_re_R_inf, A_re))  \n",
    "\n",
    "    A_im = drt.basics.assemble_A_im(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    if RLC_Flag[2]:\n",
    "        A_im_C_0    = -1/(2*np.pi*freq_vec.reshape(-1,1))\n",
    "        A_im        = np.hstack((A_im_C_0, A_im))\n",
    "    if RLC_Flag[1]:\n",
    "        A_im_L_0    = 2*np.pi*freq_vec.reshape(-1,1)\n",
    "        A_im        = np.hstack((A_im_L_0, A_im))\n",
    "    if RLC_Flag[0]:\n",
    "        A_im_R_inf  = np.zeros((n_freq, 1)) \n",
    "        A_im        = np.hstack((A_im_R_inf, A_im))\n",
    "\n",
    "    A = np.vstack((A_re, A_im))\n",
    "\n",
    "\n",
    "    '''Compute the differentiation matrices for Tiknonov regularization'''\n",
    "    M2 = np.zeros((n_tau+n_extend, n_tau+n_extend))\n",
    "    M2[n_extend:,n_extend:] = drt.basics.assemble_M_2(tau_vec, epsilon, RBF_type)\n",
    "\n",
    "    '''Optimize lambda'''\n",
    "    if custom_lambda is None:\n",
    "        log_lambda_init = -7 # ln(lambda_init = 0.001)\n",
    "        lambda_opt = drt.basics.optimal_lambda(A_re, A_im, np.real(Z_exp), np.imag(Z_exp), M2, \"Combined Re-Im Data\", RLC_Flag[1], log_lambda_init, cv_type)\n",
    "    else: \n",
    "        lambda_opt = custom_lambda\n",
    "    logger.info(f\"Lambda: {lambda_opt}\")\n",
    "    '''Deconvolve The DRT from the EIS Data'''\n",
    "    # Set Bound Constraints\n",
    "    # lb = np.zeros([n_tau+n_extend])\n",
    "    # bound_mat = np.eye(lb.shape[0])\n",
    "    H_combined, c_combined = drt.basics.quad_format_combined(A_re, A_im, np.real(Z_exp), np.imag(Z_exp), M2, lambda_opt)\n",
    "    G = matrix(-np.identity(Z_exp.shape[0]+n_extend))\n",
    "    h = matrix(np.zeros(Z_exp.shape[0]+n_extend))\n",
    "    sol = solvers.qp(matrix(H_combined), matrix(c_combined), G, h)\n",
    "    \n",
    "\n",
    "    # logger.info(f\"H:{np.linalg.matrix_rank(H_combined)}, G:{np.linalg.matrix_rank(G)}\")\n",
    "    # logger.info(f\"H_combined: {H_combined},c_combined: {c_combined}\")\n",
    "    # Deconvolved DRT\n",
    "    x = np.array(sol['x'])\n",
    "    # R_inf_DRT, L_0_DRT, C_0_DRT, DRT = x[0], x[1], x[n_extend:]\n",
    "    \n",
    "    return [tau_vec, x, n_extend, lambda_opt]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'D:/Baihm/EISNN/Dataset/05087163_归档'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 45\u001b[0m\n\u001b[0;32m      8\u001b[0m ch_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# No outlier but in two Phases\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# ch_id = 55  # One outlier &wired end point\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# ch_id = 114 # Open Circuit with on outpler\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# freq_list = np.linspace(0,np.shape(chData)[2]-1,101,dtype=int)\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m EISDict \u001b[38;5;241m=\u001b[39m gatherCSV(rootPath)\n\u001b[0;32m     46\u001b[0m chData \u001b[38;5;241m=\u001b[39m readChannel(ch_id, EISDict)\n\u001b[0;32m     47\u001b[0m freq_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1000\u001b[39m,np\u001b[38;5;241m.\u001b[39mshape(chData)[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m101\u001b[39m,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m, endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[17], line 28\u001b[0m, in \u001b[0;36mgatherCSV\u001b[1;34m(rootPath, outsuffix)\u001b[0m\n\u001b[0;32m     25\u001b[0m file_pattern    \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEIS_ch(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m## RootDir\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(rootPath):\n\u001b[0;32m     29\u001b[0m     match_session \u001b[38;5;241m=\u001b[39m session_pattern\u001b[38;5;241m.\u001b[39mmatch(i)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m## SessionDir\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'D:/Baihm/EISNN/Dataset/05087163_归档'"
     ]
    }
   ],
   "source": [
    "# rootPath = \"D:/Baihm/EISNN/Dataset/01037160_归档\"\n",
    "# ch_id = 20  # Normal to Short, Same to GPR  \n",
    "# ch_id = 89  # Same to GPR  \n",
    "# ch_id = 7  # Normal Example\n",
    "\n",
    "rootPath = \"D:/Baihm/EISNN/Dataset/05087163_归档\"\n",
    "# ch_id = 7   # one outlier\n",
    "ch_id = 50  # No outlier but in two Phases\n",
    "# ch_id = 55  # One outlier &wired end point\n",
    "# ch_id = 114 # Open Circuit with on outpler\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/02067447_归档\"\n",
    "# ch_id = 68  # Short all the time\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/01067095_归档\"\n",
    "# ch_id = 19    # First Sample is outlier\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/09290511_归档\"\n",
    "# ch_id = 13    # Up & Down, 2 outliers\n",
    "# ch_id = 21    # Normal + 2 outlier\n",
    "# ch_id = 41    # Normal + 2 outlier - *(Hard To Tell)\n",
    "# ch_id = 79    # 3-class, What a mess\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/11057712_归档\"\n",
    "# ch_id = 106    # Very Good Electrode with 1 hidden outlier, and one phase shift\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/10057084_归档\"\n",
    "# ch_id = 16    # Totaly Mess\n",
    "# ch_id = 18    # Totaly Mess\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/11067223_归档\"\n",
    "# ch_id = 124     # Perfect with one outlier\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/06017758_归档\"\n",
    "# ch_id = 96     # Perfect of Perfect\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/15361101_归档\"\n",
    "# ch_id = 0     # Only One Sample - Run With Error\n",
    "\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/11207147_归档\"\n",
    "# ch_id = 0     # Only Three Sample - Run With Error\n",
    "\n",
    "# freq_list = np.linspace(0,np.shape(chData)[2]-1,101,dtype=int)\n",
    "EISDict = gatherCSV(rootPath)\n",
    "chData = readChannel(ch_id, EISDict)\n",
    "freq_list = np.linspace(1000,np.shape(chData)[2]-1,101,dtype=int, endpoint=True)\n",
    "\n",
    "if True:\n",
    "    phz_calibration = np.loadtxt(\"./phz_Calib.txt\")\n",
    "    for i in range(np.shape(chData)[0]):\n",
    "        ch_eis = EIS_recal_ver02(chData[i,:,:], phz_calibration)\n",
    "        chData[i,:,:] = ch_eis\n",
    "chData = chData[:,:,freq_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1db957ef390>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    fig, axis = plt.subplots(1,4,figsize=(15,6))\n",
    "    cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "    for i in range(np.shape(chData)[0]):\n",
    "    # for i in [0,4,2,11]:\n",
    "        ch_eis = chData[i,:,:]\n",
    "        # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "        _color = cmap(i/np.shape(chData)[0])\n",
    "        axis[0].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[1].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[2].plot(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        # axis[4].loglog(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    \n",
    "        # _poi_Z = np.log(np.abs(ch_eis[1,:]+1j*ch_eis[2,:]))\n",
    "        # _poi_P = np.angle(ch_eis[1,:]+1j*ch_eis[2,:])\n",
    "        # _poi_eis = _poi_Z * np.exp(1j*_poi_P)\n",
    "        # axis[3].plot(np.real(_poi_eis), -np.imag(_poi_eis), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        _poi_Z = np.log(ch_eis[1,:]+1j*ch_eis[2,:])\n",
    "        axis[3].plot(np.real(_poi_Z), -np.imag(_poi_Z), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        \n",
    "\n",
    "axis[0].legend(frameon=False, loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    chData = readChannel(ch_id, EISDict)\n",
    "    freq_list = np.linspace(0,np.shape(chData)[2]-1,101,dtype=int, endpoint=True)\n",
    "    \n",
    "    # for i in range(np.shape(chData)[0]):\n",
    "    for i in range(1):\n",
    "        _save_path = \"D:/Baihm/EISNN/Dataset/pyDRTExample/09290511_ch013_01\"\n",
    "        _poi_data = chData[i,:,freq_list]\n",
    "        # _poi_data = EIS_recal(chData[i,:,:])[:,freq_list].T\n",
    "        _poi_data[:,0] = np.flip(_poi_data[:,0])\n",
    "        _poi_data[:,1] = np.flip(_poi_data[:,1])\n",
    "        _poi_data[:,2] = np.flip(_poi_data[:,2])\n",
    "        # print(np.shape(np.logspace(0,6,101,endpoint=True).T))\n",
    "        # _poi_data[:,0] = np.logspace(0,6,101,endpoint=True)\n",
    "        with open(f\"{_save_path}/Day_{i:02d}.csv\", 'w') as f:\n",
    "            np.savetxt(f, _poi_data, delimiter=',', fmt='%.6f',comments='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Baihm\\anaconda3\\envs\\EISNN\\Lib\\site-packages\\pyDRTtools\\basics.py:59: IntegrationWarning: The integral is probably divergent, or slowly convergent.\n",
      "  out_val = integrate.quad(integrand_g_i, -50, 50, epsabs=1E-9, epsrel=1E-9)\n",
      "\u001b[32m2025-04-03 16:01:11.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 100494251.972294\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8671e+11 -7.2559e+11  2e+11  1e+05  7e-02\n",
      " 1: -7.0075e+11 -7.1688e+11  2e+10  8e+03  5e-03\n",
      " 2: -7.0170e+11 -7.0422e+11  3e+09  8e+02  5e-04\n",
      " 3: -7.0261e+11 -7.0314e+11  5e+08  9e-11  4e-16\n",
      " 4: -7.0287e+11 -7.0292e+11  6e+07  6e-11  3e-16\n",
      " 5: -7.0290e+11 -7.0290e+11  5e+06  6e-11  3e-16\n",
      " 6: -7.0290e+11 -7.0290e+11  5e+05  9e-11  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:11.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [1.e-07]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 10030359.267748075\n",
      "            Iterations: 2\n",
      "            Function evaluations: 4\n",
      "            Gradient evaluations: 2\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7233e+11 -6.0949e+11  1e+11  1e+05  7e-02\n",
      " 1: -6.1379e+11 -6.5986e+11  9e+10  3e+04  2e-02\n",
      " 2: -6.2105e+11 -6.3216e+11  1e+10  1e+03  7e-04\n",
      " 3: -6.2439e+11 -6.2683e+11  2e+09  1e+02  9e-05\n",
      " 4: -6.2536e+11 -6.2620e+11  8e+08  5e-10  3e-16\n",
      " 5: -6.2572e+11 -6.2581e+11  9e+07  1e-11  4e-16\n",
      " 6: -6.2576e+11 -6.2578e+11  2e+07  2e-10  3e-16\n",
      " 7: -6.2577e+11 -6.2578e+11  7e+06  2e-10  3e-16\n",
      " 8: -6.2578e+11 -6.2578e+11  1e+06  2e-10  3e-16\n",
      " 9: -6.2578e+11 -6.2578e+11  1e+05  2e-10  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:11.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 118490811.98639825\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.5200e+11 -6.8739e+11  2e+11  1e+05  7e-02\n",
      " 1: -6.6274e+11 -6.7800e+11  3e+10  1e+04  6e-03\n",
      " 2: -6.6194e+11 -6.6461e+11  3e+09  9e+02  4e-04\n",
      " 3: -6.6290e+11 -6.6349e+11  6e+08  7e-11  4e-16\n",
      " 4: -6.6319e+11 -6.6326e+11  7e+07  1e-10  3e-16\n",
      " 5: -6.6323e+11 -6.6324e+11  7e+06  6e-11  3e-16\n",
      " 6: -6.6323e+11 -6.6324e+11  7e+05  5e-11  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:12.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 101123027.22161092\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.9646e+11 -6.2910e+11  2e+11  1e+05  7e-02\n",
      " 1: -6.0673e+11 -6.2071e+11  2e+10  1e+04  6e-03\n",
      " 2: -6.0639e+11 -6.0876e+11  3e+09  9e+02  5e-04\n",
      " 3: -6.0723e+11 -6.0775e+11  5e+08  8e-11  3e-16\n",
      " 4: -6.0749e+11 -6.0755e+11  6e+07  8e-11  3e-16\n",
      " 5: -6.0752e+11 -6.0753e+11  6e+06  6e-11  3e-16\n",
      " 6: -6.0752e+11 -6.0753e+11  1e+06  8e-11  3e-16\n",
      " 7: -6.0753e+11 -6.0753e+11  4e+04  6e-11  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:12.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 84618160.57702214\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3764e+11 -5.6685e+11  1e+11  1e+05  6e-02\n",
      " 1: -5.4648e+11 -5.5890e+11  2e+10  1e+04  6e-03\n",
      " 2: -5.4630e+11 -5.4844e+11  3e+09  9e+02  5e-04\n",
      " 3: -5.4703e+11 -5.4749e+11  5e+08  1e-10  3e-16\n",
      " 4: -5.4726e+11 -5.4731e+11  5e+07  6e-11  3e-16\n",
      " 5: -5.4729e+11 -5.4729e+11  5e+06  8e-11  3e-16\n",
      " 6: -5.4729e+11 -5.4729e+11  7e+05  8e-11  3e-16\n",
      " 7: -5.4729e+11 -5.4729e+11  2e+04  6e-11  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:13.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 106537612.52161552\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.4299e+11 -5.7298e+11  2e+11  1e+05  7e-02\n",
      " 1: -5.5283e+11 -5.6633e+11  2e+10  1e+04  6e-03\n",
      " 2: -5.5244e+11 -5.5454e+11  2e+09  4e+02  2e-04\n",
      " 3: -5.5321e+11 -5.5369e+11  5e+08  6e-11  4e-16\n",
      " 4: -5.5343e+11 -5.5348e+11  5e+07  5e-11  3e-16\n",
      " 5: -5.5345e+11 -5.5346e+11  6e+06  9e-11  3e-16\n",
      " 6: -5.5346e+11 -5.5346e+11  5e+05  6e-11  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:13.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 75144130.80550317\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4926e+11 -4.7463e+11  1e+11  1e+05  7e-02\n",
      " 1: -4.5755e+11 -4.6923e+11  2e+10  9e+03  6e-03\n",
      " 2: -4.5784e+11 -4.5945e+11  2e+09  4e+02  2e-04\n",
      " 3: -4.5833e+11 -4.5864e+11  3e+08  7e-11  3e-16\n",
      " 4: -4.5844e+11 -4.5849e+11  4e+07  4e-11  3e-16\n",
      " 5: -4.5846e+11 -4.5847e+11  5e+06  7e-11  3e-16\n",
      " 6: -4.5846e+11 -4.5846e+11  2e+05  5e-11  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:13.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 88559868.28553101\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4462e+11 -4.6973e+11  1e+11  1e+05  7e-02\n",
      " 1: -4.5277e+11 -4.6453e+11  2e+10  1e+04  6e-03\n",
      " 2: -4.5276e+11 -4.5442e+11  2e+09  2e+02  1e-04\n",
      " 3: -4.5335e+11 -4.5369e+11  3e+08  7e-11  3e-16\n",
      " 4: -4.5347e+11 -4.5352e+11  5e+07  1e-10  3e-16\n",
      " 5: -4.5350e+11 -4.5350e+11  8e+06  8e-11  3e-16\n",
      " 6: -4.5350e+11 -4.5350e+11  8e+05  9e-11  4e-16\n",
      " 7: -4.5350e+11 -4.5350e+11  4e+04  5e-11  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:14.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 82912120.83672\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7809e+11 -5.0553e+11  1e+11  1e+05  7e-02\n",
      " 1: -4.8740e+11 -5.0028e+11  2e+10  9e+03  5e-03\n",
      " 2: -4.8793e+11 -4.8948e+11  2e+09  2e+02  1e-04\n",
      " 3: -4.8841e+11 -4.8866e+11  3e+08  7e-11  3e-16\n",
      " 4: -4.8849e+11 -4.8854e+11  4e+07  8e-11  3e-16\n",
      " 5: -4.8851e+11 -4.8852e+11  4e+06  7e-11  4e-16\n",
      " 6: -4.8852e+11 -4.8852e+11  2e+05  4e-11  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:14.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 68570746.4701032\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9068e+11 -4.1312e+11  1e+11  1e+05  7e-02\n",
      " 1: -3.9789e+11 -4.0846e+11  2e+10  8e+03  5e-03\n",
      " 2: -3.9836e+11 -3.9970e+11  1e+09  3e+02  2e-04\n",
      " 3: -3.9874e+11 -3.9895e+11  2e+08  5e-11  4e-16\n",
      " 4: -3.9882e+11 -3.9885e+11  3e+07  8e-11  4e-16\n",
      " 5: -3.9883e+11 -3.9884e+11  4e+06  5e-11  3e-16\n",
      " 6: -3.9883e+11 -3.9883e+11  3e+05  4e-11  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:14.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 57832304.55170775\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8837e+11 -3.0465e+11  9e+10  9e+04  7e-02\n",
      " 1: -2.9409e+11 -3.0170e+11  1e+10  7e+03  6e-03\n",
      " 2: -2.9432e+11 -2.9533e+11  1e+09  2e+02  1e-04\n",
      " 3: -2.9468e+11 -2.9489e+11  2e+08  3e-12  4e-16\n",
      " 4: -2.9476e+11 -2.9479e+11  3e+07  4e-11  4e-16\n",
      " 5: -2.9477e+11 -2.9477e+11  4e+06  4e-11  4e-16\n",
      " 6: -2.9477e+11 -2.9477e+11  2e+05  6e-11  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:15.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 51417780.180090755\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.5120e+11 -2.6550e+11  7e+10  9e+04  7e-02\n",
      " 1: -2.5626e+11 -2.6303e+11  1e+10  6e+03  5e-03\n",
      " 2: -2.5659e+11 -2.5748e+11  9e+08  2e+02  1e-04\n",
      " 3: -2.5689e+11 -2.5708e+11  2e+08  8e-11  4e-16\n",
      " 4: -2.5695e+11 -2.5698e+11  3e+07  6e-11  4e-16\n",
      " 5: -2.5697e+11 -2.5697e+11  4e+06  4e-11  4e-16\n",
      " 6: -2.5697e+11 -2.5697e+11  5e+05  3e-11  3e-16\n",
      " 7: -2.5697e+11 -2.5697e+11  5e+04  4e-11  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:15.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 46113690.845316745\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.3351e+11 -2.4707e+11  7e+10  8e+04  7e-02\n",
      " 1: -2.3841e+11 -2.4483e+11  9e+09  5e+03  5e-03\n",
      " 2: -2.3889e+11 -2.3970e+11  8e+08  2e+02  2e-04\n",
      " 3: -2.3914e+11 -2.3930e+11  2e+08  4e-11  4e-16\n",
      " 4: -2.3919e+11 -2.3921e+11  2e+07  6e-11  3e-16\n",
      " 5: -2.3919e+11 -2.3920e+11  4e+06  3e-11  3e-16\n",
      " 6: -2.3920e+11 -2.3920e+11  3e+05  4e-11  3e-16\n",
      " 7: -2.3920e+11 -2.3920e+11  2e+04  7e-11  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:16.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 37795127.81895417\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0608e+11 -2.1816e+11  6e+10  7e+04  7e-02\n",
      " 1: -2.1039e+11 -2.1611e+11  8e+09  4e+03  4e-03\n",
      " 2: -2.1089e+11 -2.1159e+11  7e+08  2e+02  2e-04\n",
      " 3: -2.1108e+11 -2.1121e+11  1e+08  3e-11  4e-16\n",
      " 4: -2.1111e+11 -2.1114e+11  2e+07  3e-11  4e-16\n",
      " 5: -2.1112e+11 -2.1113e+11  4e+06  6e-11  4e-16\n",
      " 6: -2.1113e+11 -2.1113e+11  2e+05  4e-11  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:16.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [0.00091188]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 42247780.61971105\n",
      "            Iterations: 5\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 1\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9631e+11 -2.0776e+11  6e+10  8e+04  8e-02\n",
      " 1: -2.0064e+11 -2.0618e+11  8e+09  5e+03  5e-03\n",
      " 2: -2.0110e+11 -2.0179e+11  7e+08  5e+01  6e-05\n",
      " 3: -2.0127e+11 -2.0137e+11  9e+07  2e+00  2e-06\n",
      " 4: -2.0130e+11 -2.0132e+11  2e+07  4e-01  4e-07\n",
      " 5: -2.0131e+11 -2.0131e+11  3e+06  1e-02  1e-08\n",
      " 6: -2.0131e+11 -2.0131e+11  2e+05  3e-04  3e-10\n",
      " 7: -2.0131e+11 -2.0131e+11  7e+03  9e-06  9e-12\n",
      " 8: -2.0131e+11 -2.0131e+11  2e+02  1e-07  1e-13\n",
      " 9: -2.0131e+11 -2.0131e+11  2e+00  1e-09  1e-15\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 16:01:16.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDRT\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mLambda: [1.e-07]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 4133857.414140644\n",
      "            Iterations: 2\n",
      "            Function evaluations: 4\n",
      "            Gradient evaluations: 2\n",
      "rGCV\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6359e+11 -1.7541e+11  5e+10  6e+04  9e-02\n",
      " 1: -1.7862e+11 -1.9350e+11  3e+10  2e+04  2e-02\n",
      " 2: -1.8117e+11 -1.8511e+11  4e+09  6e+02  8e-04\n",
      " 3: -1.8194e+11 -1.8233e+11  4e+08  4e+01  5e-05\n",
      " 4: -1.8208e+11 -1.8217e+11  9e+07  4e+00  6e-06\n",
      " 5: -1.8210e+11 -1.8216e+11  6e+07  2e+00  2e-06\n",
      " 6: -1.8213e+11 -1.8214e+11  1e+07  3e-01  5e-07\n",
      " 7: -1.8213e+11 -1.8213e+11  4e+06  5e-02  7e-08\n",
      " 8: -1.8213e+11 -1.8213e+11  8e+05  7e-03  1e-08\n",
      " 9: -1.8213e+11 -1.8213e+11  4e+05  2e-03  2e-09\n",
      "10: -1.8213e+11 -1.8213e+11  6e+04  2e-04  3e-10\n",
      "11: -1.8213e+11 -1.8213e+11  1e+04  1e-10  3e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# %skip\n",
    "\n",
    "# tau_vec, x_DRT = DRT(chData[0,:,freq_list].T)\n",
    "# np.shape(chData[0,:,freq_list].T)\n",
    "\n",
    "fig, axis = plt.subplots(1,3,figsize=(15,6))\n",
    "cmap = plt.get_cmap('RdYlBu')\n",
    "# cmap = plt.get_cmap('rainbow_r')\n",
    "RLC_flag = [False, False, False]\n",
    "custom_lambda = None\n",
    "# custom_lambda = 1e-4\n",
    "for i in range(np.shape(chData)[0]):\n",
    "# for i in [4,5,6]:\n",
    "    if True:\n",
    "        RLC_flag = [False, False, False]\n",
    "        ch_eis = chData[i,:,:]\n",
    "        # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "        # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "        tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag,custom_lambda)\n",
    "        \n",
    "        \n",
    "        _color = cmap(i/np.shape(chData)[0])\n",
    "        # if i == 5: _color = 'black'\n",
    "        axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        \n",
    "        axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "    \n",
    "    if False:\n",
    "        RLC_flag = [True, True, False]\n",
    "        ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "        # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "        # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "        tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag,custom_lambda)\n",
    "        \n",
    "        \n",
    "        _color = cmap(i/np.shape(chData)[0])\n",
    "        axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        \n",
    "        axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "    # plt.plot(np.log10(ch_eis[0,:]), np.log10(np.abs(ch_eis[1,:]+1j*ch_eis[2,:])), 'r')\n",
    "    # plt.plot(np.log10(ch_eis_rec[0,:]), np.log10(np.abs(ch_eis_rec[1,:]+1j*ch_eis_rec[2,:])), 'b')\n",
    "    # plt.plot(np.log10(ch_day[0,:]), np.rad2deg(np.angle(ch_day[1,:]+1j*ch_day[2,:])), 'r')\n",
    "    # plt.plot(np.log10(ch_day_rec[0,:]), np.rad2deg(np.angle(ch_day_rec[1,:]+1j*ch_day_rec[2,:])), 'b')\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRT Pipeline - Batch Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRTPrepare(ch_eis, _log_tau_min=-8, _log_tau_max=0):\n",
    "        freq_vec = ch_eis[0,:]\n",
    "        Z_real = ch_eis[1,:]\n",
    "        Z_imag = ch_eis[2,:]\n",
    "        if np.mean(np.diff(np.log(freq_vec))) > 0:\n",
    "            freq_vec = np.flip(freq_vec)\n",
    "            Z_real = np.flip(Z_real)\n",
    "            Z_imag = np.flip(Z_imag)\n",
    "        _tau_ext_scale = 0\n",
    "        # _log_tau_min = np.log10(1/(2*np.pi*freq_vec[0])) - _tau_ext_scale\n",
    "        # _log_tau_max = np.log10(1/(2*np.pi*freq_vec[-1])) + _tau_ext_scale\n",
    "        # _log_tau_min = np.log10(1/(freq_vec[0]))  - _tau_ext_scale\n",
    "        # _log_tau_max = np.log10(1/(freq_vec[-1])) + _tau_ext_scale\n",
    "        # tau_vec = 1/(2*np.pi*freq_vec)\n",
    "        # tau_vec = 1/freq_vec\n",
    "        tau_vec = np.logspace(_log_tau_min,_log_tau_max,np.shape(freq_vec)[0],endpoint=True)\n",
    "        # tau_vec = np.logspace(np.floor(_log_tau_min),np.ceil(_log_tau_max),np.shape(freq_vec)[0],endpoint=True)\n",
    "        return [freq_vec, tau_vec, Z_real, Z_imag]\n",
    "\n",
    "def DRTAssemble(freq_vec, tau_vec, RLC_Flag = [False, False, False], RBF_type = 'Gaussian'):\n",
    "    '''==================================================\n",
    "        Assemble A & M for Tikhonov Regularization\n",
    "        Parameter: \n",
    "            freq_vec: frequency vector\n",
    "            tau_vec: time domain vector\n",
    "            RLC_Flag: [R_inf, L_0, C_0]\n",
    "            RBF_type: RBF Kernel Type:\n",
    "                1. 'Piecewise Linear'\n",
    "                2. 'Gaussian'            (default)\n",
    "                3. 'C0 Matern'\n",
    "                4. 'C2 Matern'\n",
    "                5. 'C4 Matern'\n",
    "                6. 'C6 Matern'\n",
    "                7. 'Inverse Quadratic'\n",
    "        Returen:\n",
    "            A_re: Discretization Matrix for Real Part\n",
    "            A_im: Discretization Matrix for Imaginary Part\n",
    "            M2: Differentiation Matrixs\n",
    "        ==================================================\n",
    "    '''\n",
    "    ## Freq domain data prepare\n",
    "    n_freq  = freq_vec.shape[0]\n",
    "    n_tau   = tau_vec.shape[0]\n",
    "\n",
    "    # Validate freq in descending order & tau in ascending order\n",
    "    if np.mean(np.diff(np.log(freq_vec))) > 0:\n",
    "        logger.warning(\"Frequency is not in descending order\")\n",
    "        return None\n",
    "    if np.mean(np.diff(np.log(tau_vec))) < 0:\n",
    "        logger.warning(\"Relaxation time is not in ascending order\")\n",
    "        return None\n",
    "    # Discretization matrices Parameters\n",
    "    # Use RBF Kernel to initialize the A matrix\n",
    "    RBF_shape_control = 'FWHM Coefficient' \n",
    "    RBF_coeff = 0.5\n",
    "\n",
    "    '''Compute the RBF Shape Parameter Epsilon'''\n",
    "    epsilon = drt.basics.compute_epsilon(freq_vec, RBF_coeff, RBF_type, RBF_shape_control)\n",
    "    # logger.info(f\"epsilon: {epsilon}\")\n",
    "\n",
    "    '''Compute the discretization matrices'''\n",
    "    A_re = drt.basics.assemble_A_re(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    n_extend = np.sum(RLC_Flag)   \n",
    "    if RLC_Flag[2]:\n",
    "        A_re_C_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_C_0, A_re)) \n",
    "    if RLC_Flag[1]:\n",
    "        A_re_L_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_L_0, A_re))\n",
    "    if RLC_Flag[0]:\n",
    "        A_re_R_inf  = np.ones((n_freq, 1))\n",
    "        A_re        = np.hstack((A_re_R_inf, A_re))  \n",
    "\n",
    "    A_im = drt.basics.assemble_A_im(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    if RLC_Flag[2]:\n",
    "        A_im_C_0    = -1/(2*np.pi*freq_vec.reshape(-1,1))\n",
    "        A_im        = np.hstack((A_im_C_0, A_im))\n",
    "    if RLC_Flag[1]:\n",
    "        A_im_L_0    = 2*np.pi*freq_vec.reshape(-1,1)\n",
    "        A_im        = np.hstack((A_im_L_0, A_im))\n",
    "    if RLC_Flag[0]:\n",
    "        A_im_R_inf  = np.zeros((n_freq, 1)) \n",
    "        A_im        = np.hstack((A_im_R_inf, A_im))\n",
    "\n",
    "    # A = np.vstack((A_re, A_im))\n",
    "\n",
    "\n",
    "    '''Compute the differentiation matrices for Tiknonov regularization'''\n",
    "    M2 = np.zeros((n_tau+n_extend, n_tau+n_extend))\n",
    "    M2[n_extend:,n_extend:] = drt.basics.assemble_M_2(tau_vec, epsilon, RBF_type)\n",
    "\n",
    "    return [A_re, A_im, M2, n_extend]\n",
    "\n",
    "def DRTDeconvolve(Z_real, Z_imag, A_re, A_im, M2, n_extend, RLC_Flag = [False, False, False], custom_lambda = None, cv_type='mGCV'):\n",
    "    '''==================================================\n",
    "        Deconvolve DRT from EIS Data\n",
    "        Parameter: \n",
    "            freq_vec: frequency vector\n",
    "            tau_vec: time domain vector\n",
    "            Z_real: real part of impedance\n",
    "            Z_imag: imaginary part of impedance\n",
    "            custom_lambda: Tikhonov regularization parameter\n",
    "            cv_type: Cross-validation Method for optimize lambda\n",
    "                1. 'GCV'     \n",
    "                2. 'mGCV'    (default)\n",
    "                3. 'rGCV'    \n",
    "                4. 'LC'      \n",
    "                5. 're-im'   \n",
    "                6. 'kf'      \n",
    "        Returen:\n",
    "            x: DRT result\n",
    "            n_extend: number of extend RLC parameters\n",
    "            lambda_opt: optimized lambda\n",
    "            x_extend: extend RLC parameters\n",
    "        ==================================================\n",
    "    '''\n",
    "\n",
    "    '''Optimize lambda'''\n",
    "    if custom_lambda is None:\n",
    "        log_lambda_init = -7 # ln(lambda_init = 0.001)\n",
    "        lambda_opt = drt.basics.optimal_lambda(A_re, A_im, Z_real, Z_imag, M2, \"Combined Re-Im Data\", RLC_Flag[1], log_lambda_init, cv_type)\n",
    "    else: \n",
    "        lambda_opt = custom_lambda\n",
    "    # logger.info(f\"lambda_opt: {epsilon}\")\n",
    "    \n",
    "    '''Deconvolve The DRT from the EIS Data'''\n",
    "    H_combined, c_combined = drt.basics.quad_format_combined(A_re, A_im, Z_real, Z_imag, M2, lambda_opt)\n",
    "    G = matrix(-np.identity(Z_real.shape[0]+n_extend))\n",
    "    h = matrix(np.zeros(Z_real.shape[0]+n_extend))\n",
    "    sol = solvers.qp(matrix(H_combined), matrix(c_combined), G, h)\n",
    "    \n",
    "    # Deconvolved DRT\n",
    "    x = np.array(sol['x'])\n",
    "    \n",
    "    if n_extend > 0:\n",
    "        x_DRT = x[n_extend:]\n",
    "        x_extend = x[:n_extend]\n",
    "    else: \n",
    "        x_DRT = x\n",
    "        x_extend = None\n",
    "    return [x_DRT, lambda_opt, x_extend]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.4515e+04 -8.4968e+04  1e+03  1e+01  8e-08\n",
      " 1: -8.4520e+04 -8.4632e+04  1e+02  4e-01  3e-09\n",
      " 2: -8.4528e+04 -8.4548e+04  2e+01  5e-02  4e-10\n",
      " 3: -8.4532e+04 -8.4538e+04  6e+00  5e-04  3e-12\n",
      " 4: -8.4533e+04 -8.4534e+04  8e-01  2e-05  2e-13\n",
      " 5: -8.4534e+04 -8.4534e+04  1e-01  1e-06  8e-15\n",
      " 6: -8.4534e+04 -8.4534e+04  1e-02  5e-08  5e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "def DRT_Single(ch_eis, RLC_Flag=[True, True, True], custom_lambda = 0.01):\n",
    "    freq_vec, tau_vec, Z_real, Z_imag = DRTPrepare(ch_eis)\n",
    "    A_re, A_im, M2, n_extend = DRTAssemble(freq_vec, tau_vec, RLC_Flag)\n",
    "    x_DRT, lambda_opt, _ = DRTDeconvolve(Z_real, Z_imag, A_re, A_im, M2, n_extend, RLC_Flag, custom_lambda)\n",
    "\n",
    "    fig, axis = plt.subplots(1,3,figsize=(15,6))\n",
    "    axis[0].semilogx(tau_vec, x_DRT, linewidth=2, label=f\"Session {0}\")\n",
    "    axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), linewidth=2, label=f\"Session {0}\")\n",
    "    axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), linewidth=2, label=f\"Session {0}\")\n",
    "    \n",
    "    # fig.show()\n",
    "\n",
    "    # logger.info(f\"Lambda: {lambda_opt}\")    \n",
    "    # logger.info(f\"Freq: {freq_vec[0]:.2e} - {freq_vec[-1]:.2e}\")\n",
    "    # logger.info(f\"Tau: {tau_vec[0]:.2e} - {tau_vec[-1]:.2e}\")\n",
    "\n",
    "df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "DRT_Single(ch_eis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT_Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRT_Batch(ch_id, EISDict, freq_list, _log_tau_min=-8, _log_tau_max=0):\n",
    "    chData = readChannel(ch_id, EISDict)\n",
    "    if True:\n",
    "        phz_calibration = np.loadtxt(\"./phz_Calib.txt\")\n",
    "        for i in range(np.shape(chData)[0]):\n",
    "            ch_eis = EIS_recal_ver02(chData[i,:,:], phz_calibration)\n",
    "            chData[i,:,:] = ch_eis\n",
    "\n",
    "\n",
    "    if np.shape(chData)[0] < 3:\n",
    "        logger.warning(f\"Channel {ch_id} has less than 3 samples\")\n",
    "        return None\n",
    "    # Parameters\n",
    "    RLC_Flag=[True, True, True]\n",
    "    custom_lambda = 1e-5\n",
    "\n",
    "    # DRT A & M Matrix Assemble\n",
    "    freq_vec, tau_vec, _, _ = DRTPrepare(chData[0,:,freq_list].T, _log_tau_min, _log_tau_max)\n",
    "    A_re, A_im, M2, n_extend = DRTAssemble(freq_vec, tau_vec, RLC_Flag)\n",
    "    \n",
    "    # DRT Main\n",
    "    ch_DRT = []\n",
    "    for i in range(np.shape(chData)[0]):\n",
    "    # for i in [0,1,2,3,4,5,6,7,8]:\n",
    "        ch_eis = chData[i,:,freq_list].T\n",
    "        # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "        freq_vec, tau_vec, Z_real, Z_imag = DRTPrepare(ch_eis)\n",
    "        x_DRT, lambda_opt, x_extend = DRTDeconvolve(Z_real, Z_imag, A_re, A_im, M2, n_extend, RLC_Flag, custom_lambda)\n",
    "        ch_DRT.append(x_DRT.flatten())\n",
    "    return [np.array(ch_DRT), tau_vec]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-16 23:35:44.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20241120_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20241127_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20241204_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20241211_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20241218_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20241225_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20241230_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250106_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250113_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250120_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250126_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250207_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250212_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250219_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250226_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250313_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250319_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250331_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250408_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250414_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250421_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: S6006_20250427_01\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-05-16 23:35:44.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# rootPath = \"D:/Baihm/EISNN/Dataset/01037160_归档\"\n",
    "# ch_id = 20  # Normal to Short, Same to GPR  \n",
    "# ch_id = 89  # Same to GPR  \n",
    "# ch_id = 7  # Normal Example\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Dataset/05087163_归档\"\n",
    "# ch_id = 7   # one outlier\n",
    "# ch_id = 50  # Normal? \n",
    "# ch_id = 55  # One outlier &wired end point\n",
    "# ch_id = 114 # Open Circuit with on outpler\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/02067447_归档\"\n",
    "# ch_id = 68  # Short all the time\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/01067095_归档\"\n",
    "# ch_id = 19    # First Sample is outlier\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/09290511_归档\"\n",
    "# ch_id = 13    # Up & Down, 2 outliers\n",
    "# ch_id = 21    # Normal + 2 outlier\n",
    "# ch_id = 41    # Normal + 2 outlier - *(Hard To Tell)\n",
    "# ch_id = 79    # 3-class, What a mess\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/11057712_归档\"\n",
    "# ch_id = 106    # Very Good Electrode with 1 outlier\n",
    "\n",
    "## Invivo\n",
    "rootPath = \"D:/Baihm/EISNN/Invivo/S6006_Ver02\"\n",
    "ch_id = 7\n",
    "EISDict = gatherCSV(rootPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  49,   99,  149,  199,  249,  299,  349,  399,  449,  499,  549,\n",
       "        599,  649,  699,  749,  799,  849,  899,  949,  999, 1049, 1099,\n",
       "       1149, 1199, 1249, 1299, 1349, 1399, 1449, 1499, 1549, 1599, 1649,\n",
       "       1699, 1749, 1799, 1849, 1899, 1949, 1999, 2049, 2099, 2149, 2199,\n",
       "       2249, 2299, 2349, 2399, 2449, 2499, 2549, 2599, 2649, 2699, 2749,\n",
       "       2799, 2849, 2899, 2949, 2999, 3049, 3099, 3149, 3199, 3249, 3299,\n",
       "       3349, 3399, 3449, 3499, 3549, 3599, 3649, 3699, 3749, 3799, 3849,\n",
       "       3899, 3949, 3999, 4049, 4099, 4149, 4199, 4249, 4299, 4349, 4399,\n",
       "       4449, 4499, 4549, 4599, 4649, 4699, 4749, 4799, 4849, 4899, 4949,\n",
       "       4999])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freq_list = np.linspace(0,5000,100,dtype=int, endpoint=False)\n",
    "freq_list = np.linspace(5000-1,0,100,dtype=int, endpoint=False)\n",
    "freq_list = freq_list[::-1]\n",
    "freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.3880e+14 -1.0120e+15  1e+14  2e+06  5e-05\n",
      " 1: -9.8481e+14 -1.0537e+15  1e+14  1e+06  3e-05\n",
      " 2: -9.9671e+14 -1.0131e+15  2e+13  1e+04  3e-07\n",
      " 3: -9.9772e+14 -9.9995e+14  2e+12  1e+03  3e-08\n",
      " 4: -9.9804e+14 -9.9852e+14  5e+11  1e+01  3e-10\n",
      " 5: -9.9811e+14 -9.9818e+14  8e+10  1e+00  3e-11\n",
      " 6: -9.9812e+14 -9.9814e+14  1e+10  1e-02  3e-13\n",
      " 7: -9.9813e+14 -9.9813e+14  4e+09  3e-03  7e-14\n",
      " 8: -9.9812e+14 -9.9813e+14  8e+09  8e-09  3e-16\n",
      " 9: -9.9813e+14 -9.9813e+14  1e+09  8e-09  3e-16\n",
      "10: -9.9813e+14 -9.9813e+14  2e+08  1e-08  8e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.2643e+14 -9.9385e+14  1e+14  2e+06  5e-05\n",
      " 1: -9.6633e+14 -1.0289e+15  1e+14  1e+06  3e-05\n",
      " 2: -9.7838e+14 -9.9167e+14  1e+13  1e+04  3e-07\n",
      " 3: -9.7942e+14 -9.8122e+14  2e+12  1e+03  3e-08\n",
      " 4: -9.7979e+14 -9.8026e+14  5e+11  2e+01  6e-10\n",
      " 5: -9.7987e+14 -9.7995e+14  8e+10  3e+00  7e-11\n",
      " 6: -9.7989e+14 -9.7991e+14  1e+10  3e-02  8e-13\n",
      " 7: -9.7990e+14 -9.7990e+14  2e+09  3e-03  9e-14\n",
      " 8: -9.7990e+14 -9.7990e+14  3e+09  3e-09  4e-16\n",
      " 9: -9.7990e+14 -9.7990e+14  5e+08  8e-09  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.3380e+14 -9.0032e+14  1e+14  2e+06  5e-05\n",
      " 1: -8.6922e+14 -9.2977e+14  9e+13  9e+05  3e-05\n",
      " 2: -8.8263e+14 -8.9640e+14  1e+13  9e+03  3e-07\n",
      " 3: -8.8359e+14 -8.8551e+14  2e+12  1e+03  3e-08\n",
      " 4: -8.8397e+14 -8.8441e+14  4e+11  1e+01  3e-10\n",
      " 5: -8.8405e+14 -8.8413e+14  7e+10  1e+00  4e-11\n",
      " 6: -8.8408e+14 -8.8409e+14  1e+10  1e-02  5e-13\n",
      " 7: -8.8408e+14 -8.8408e+14  3e+09  3e-03  1e-13\n",
      " 8: -8.8408e+14 -8.8409e+14  1e+10  8e-09  8e-16\n",
      " 9: -8.8408e+14 -8.8408e+14  2e+09  8e-09  4e-16\n",
      "10: -8.8408e+14 -8.8408e+14  4e+08  8e-09  6e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.3624e+14 -8.0428e+14  1e+14  1e+06  6e-05\n",
      " 1: -7.6990e+14 -8.3058e+14  9e+13  8e+05  4e-05\n",
      " 2: -7.8642e+14 -8.0211e+14  2e+13  8e+03  4e-07\n",
      " 3: -7.8728e+14 -7.8901e+14  2e+12  7e+02  3e-08\n",
      " 4: -7.8750e+14 -7.8775e+14  3e+11  2e+01  9e-10\n",
      " 5: -7.8753e+14 -7.8756e+14  3e+10  1e+00  7e-11\n",
      " 6: -7.8753e+14 -7.8754e+14  5e+09  6e-02  3e-12\n",
      " 7: -7.8753e+14 -7.8754e+14  7e+08  5e-03  2e-13\n",
      " 8: -7.8753e+14 -7.8753e+14  5e+08  3e-03  1e-13\n",
      " 9: -7.8753e+14 -7.8754e+14  1e+09  8e-05  4e-15\n",
      "10: -7.8753e+14 -7.8753e+14  2e+08  2e-09  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.5748e+14 -7.1710e+14  9e+13  1e+06  6e-05\n",
      " 1: -6.8735e+14 -7.4062e+14  8e+13  7e+05  4e-05\n",
      " 2: -7.0158e+14 -7.1538e+14  1e+13  7e+03  4e-07\n",
      " 3: -7.0229e+14 -7.0383e+14  2e+12  7e+02  3e-08\n",
      " 4: -7.0246e+14 -7.0269e+14  2e+11  2e+01  1e-09\n",
      " 5: -7.0250e+14 -7.0253e+14  3e+10  2e+00  1e-10\n",
      " 6: -7.0250e+14 -7.0251e+14  5e+09  2e-02  1e-12\n",
      " 7: -7.0250e+14 -7.0250e+14  1e+09  3e-03  1e-13\n",
      " 8: -7.0250e+14 -7.0250e+14  2e+09  8e-09  2e-16\n",
      " 9: -7.0250e+14 -7.0250e+14  2e+08  8e-09  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8680e+14 -7.3916e+14  9e+13  1e+06  6e-05\n",
      " 1: -7.1638e+14 -7.6353e+14  7e+13  8e+05  3e-05\n",
      " 2: -7.2682e+14 -7.3714e+14  1e+13  8e+03  3e-07\n",
      " 3: -7.2755e+14 -7.2876e+14  1e+12  7e+02  3e-08\n",
      " 4: -7.2769e+14 -7.2788e+14  2e+11  6e+01  3e-09\n",
      " 5: -7.2771e+14 -7.2774e+14  2e+10  6e-01  3e-11\n",
      " 6: -7.2772e+14 -7.2772e+14  3e+09  4e-02  2e-12\n",
      " 7: -7.2772e+14 -7.2772e+14  3e+08  2e-03  1e-13\n",
      " 8: -7.2772e+14 -7.2772e+14  3e+08  1e-03  5e-14\n",
      " 9: -7.2772e+14 -7.2772e+14  5e+07  2e-09  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.0993e+14 -7.6024e+14  1e+14  2e+06  7e-05\n",
      " 1: -7.4262e+14 -7.8871e+14  8e+13  9e+05  4e-05\n",
      " 2: -7.5191e+14 -7.6197e+14  1e+13  1e+04  4e-07\n",
      " 3: -7.5290e+14 -7.5563e+14  3e+12  2e+03  8e-08\n",
      " 4: -7.5315e+14 -7.5366e+14  5e+11  2e+02  9e-09\n",
      " 5: -7.5321e+14 -7.5327e+14  6e+10  3e+00  1e-10\n",
      " 6: -7.5322e+14 -7.5323e+14  8e+09  3e-01  1e-11\n",
      " 7: -7.5322e+14 -7.5322e+14  8e+08  5e-03  2e-13\n",
      " 8: -7.5322e+14 -7.5322e+14  3e+08  2e-03  6e-14\n",
      " 9: -7.5322e+14 -7.5322e+14  6e+08  9e-04  3e-14\n",
      "10: -7.5322e+14 -7.5322e+14  1e+08  6e-09  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.5098e+14 -7.0306e+14  1e+14  2e+06  7e-05\n",
      " 1: -6.8511e+14 -7.3235e+14  8e+13  9e+05  4e-05\n",
      " 2: -6.9487e+14 -7.0585e+14  1e+13  9e+03  4e-07\n",
      " 3: -6.9566e+14 -6.9672e+14  1e+12  6e+02  2e-08\n",
      " 4: -6.9580e+14 -6.9599e+14  2e+11  6e+01  2e-09\n",
      " 5: -6.9583e+14 -6.9587e+14  4e+10  6e-01  2e-11\n",
      " 6: -6.9583e+14 -6.9584e+14  5e+09  3e-02  1e-12\n",
      " 7: -6.9583e+14 -6.9584e+14  6e+08  2e-03  1e-13\n",
      " 8: -6.9583e+14 -6.9583e+14  3e+08  1e-03  4e-14\n",
      " 9: -6.9583e+14 -6.9583e+14  1e+08  1e-09  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8696e+14 -7.4321e+14  1e+14  2e+06  8e-05\n",
      " 1: -7.2362e+14 -7.7492e+14  9e+13  1e+06  4e-05\n",
      " 2: -7.3403e+14 -7.4575e+14  1e+13  1e+04  4e-07\n",
      " 3: -7.3516e+14 -7.3747e+14  2e+12  1e+03  5e-08\n",
      " 4: -7.3539e+14 -7.3576e+14  4e+11  1e+02  5e-09\n",
      " 5: -7.3543e+14 -7.3552e+14  9e+10  1e+00  5e-11\n",
      " 6: -7.3544e+14 -7.3545e+14  1e+10  1e-01  6e-12\n",
      " 7: -7.3544e+14 -7.3544e+14  2e+09  1e-02  5e-13\n",
      " 8: -7.3544e+14 -7.3544e+14  3e+08  2e-03  7e-14\n",
      " 9: -7.3544e+14 -7.3544e+14  3e+08  3e-04  1e-14\n",
      "10: -7.3544e+14 -7.3544e+14  5e+07  3e-09  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8756e+14 -7.5709e+14  1e+14  2e+06  7e-05\n",
      " 1: -7.2679e+14 -7.8831e+14  9e+13  9e+05  4e-05\n",
      " 2: -7.4315e+14 -7.5902e+14  2e+13  9e+03  4e-07\n",
      " 3: -7.4411e+14 -7.4539e+14  1e+12  5e+02  2e-08\n",
      " 4: -7.4427e+14 -7.4443e+14  2e+11  5e+00  2e-10\n",
      " 5: -7.4429e+14 -7.4432e+14  2e+10  2e-01  1e-11\n",
      " 6: -7.4430e+14 -7.4430e+14  3e+09  2e-02  8e-13\n",
      " 7: -7.4430e+14 -7.4430e+14  5e+08  2e-03  1e-13\n",
      " 8: -7.4430e+14 -7.4430e+14  7e+08  1e-04  7e-15\n",
      " 9: -7.4430e+14 -7.4430e+14  2e+08  1e-09  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.7752e+14 -7.1935e+14  5e+13  6e+05  5e-05\n",
      " 1: -6.9411e+14 -7.3171e+14  5e+13  4e+05  4e-05\n",
      " 2: -7.0635e+14 -7.1563e+14  9e+12  4e+03  4e-07\n",
      " 3: -7.0715e+14 -7.0864e+14  1e+12  5e+02  4e-08\n",
      " 4: -7.0731e+14 -7.0764e+14  3e+11  6e+01  5e-09\n",
      " 5: -7.0734e+14 -7.0738e+14  4e+10  4e+00  4e-10\n",
      " 6: -7.0735e+14 -7.0735e+14  4e+09  2e-01  2e-11\n",
      " 7: -7.0735e+14 -7.0735e+14  5e+08  5e-03  4e-13\n",
      " 8: -7.0735e+14 -7.0735e+14  3e+08  3e-03  2e-13\n",
      " 9: -7.0735e+14 -7.0735e+14  9e+08  1e-03  9e-14\n",
      "10: -7.0735e+14 -7.0735e+14  2e+08  3e-09  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6691e+14 -7.3100e+14  1e+14  1e+06  7e-05\n",
      " 1: -7.0231e+14 -7.5934e+14  9e+13  8e+05  4e-05\n",
      " 2: -7.1727e+14 -7.3156e+14  1e+13  8e+03  4e-07\n",
      " 3: -7.1811e+14 -7.1997e+14  2e+12  9e+02  4e-08\n",
      " 4: -7.1836e+14 -7.1869e+14  3e+11  2e+01  1e-09\n",
      " 5: -7.1840e+14 -7.1845e+14  5e+10  2e+00  8e-11\n",
      " 6: -7.1840e+14 -7.1841e+14  6e+09  1e-01  5e-12\n",
      " 7: -7.1841e+14 -7.1841e+14  8e+08  4e-03  2e-13\n",
      " 8: -7.1841e+14 -7.1841e+14  6e+08  2e-03  1e-13\n",
      " 9: -7.1841e+14 -7.1841e+14  4e+08  4e-09  1e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6658e+14 -7.2795e+14  1e+14  2e+06  7e-05\n",
      " 1: -7.0592e+14 -7.6195e+14  9e+13  1e+06  3e-05\n",
      " 2: -7.1727e+14 -7.3113e+14  1e+13  1e+04  3e-07\n",
      " 3: -7.1805e+14 -7.1984e+14  2e+12  1e+03  4e-08\n",
      " 4: -7.1836e+14 -7.1865e+14  3e+11  5e+01  2e-09\n",
      " 5: -7.1844e+14 -7.1851e+14  7e+10  5e-01  2e-11\n",
      " 6: -7.1845e+14 -7.1846e+14  1e+10  5e-02  2e-12\n",
      " 7: -7.1845e+14 -7.1846e+14  1e+09  3e-03  1e-13\n",
      " 8: -7.1845e+14 -7.1845e+14  7e+08  2e-03  7e-14\n",
      " 9: -7.1845e+14 -7.1845e+14  5e+08  2e-08  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.4261e+14 -9.2369e+14  2e+14  2e+06  8e-05\n",
      " 1: -8.9801e+14 -9.7234e+14  1e+14  1e+06  4e-05\n",
      " 2: -9.1354e+14 -9.3179e+14  2e+13  1e+04  4e-07\n",
      " 3: -9.1540e+14 -9.1986e+14  4e+12  2e+03  5e-08\n",
      " 4: -9.1605e+14 -9.1701e+14  1e+12  2e+02  5e-09\n",
      " 5: -9.1625e+14 -9.1649e+14  2e+11  2e+00  5e-11\n",
      " 6: -9.1629e+14 -9.1632e+14  4e+10  2e-01  7e-12\n",
      " 7: -9.1629e+14 -9.1630e+14  4e+09  7e-03  2e-13\n",
      " 8: -9.1630e+14 -9.1630e+14  7e+08  8e-04  2e-14\n",
      " 9: -9.1629e+14 -9.1630e+14  6e+08  1e-05  3e-16\n",
      "10: -9.1630e+14 -9.1630e+14  2e+08  6e-09  3e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8935e+14 -7.4204e+14  1e+14  2e+06  6e-05\n",
      " 1: -7.1990e+14 -7.6782e+14  8e+13  9e+05  3e-05\n",
      " 2: -7.2968e+14 -7.4013e+14  1e+13  9e+03  3e-07\n",
      " 3: -7.3037e+14 -7.3134e+14  1e+12  5e+02  2e-08\n",
      " 4: -7.3049e+14 -7.3063e+14  1e+11  5e+01  2e-09\n",
      " 5: -7.3051e+14 -7.3053e+14  2e+10  4e-01  2e-11\n",
      " 6: -7.3052e+14 -7.3052e+14  3e+09  3e-02  1e-12\n",
      " 7: -7.3052e+14 -7.3052e+14  5e+08  3e-03  1e-13\n",
      " 8: -7.3052e+14 -7.3052e+14  4e+08  1e-08  3e-19\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.9553e+14 -7.6310e+14  1e+14  2e+06  7e-05\n",
      " 1: -7.3916e+14 -7.9970e+14  1e+14  1e+06  4e-05\n",
      " 2: -7.5336e+14 -7.6829e+14  2e+13  1e+04  4e-07\n",
      " 3: -7.5419e+14 -7.5656e+14  2e+12  1e+03  5e-08\n",
      " 4: -7.5444e+14 -7.5487e+14  4e+11  9e+01  3e-09\n",
      " 5: -7.5449e+14 -7.5455e+14  5e+10  1e+00  6e-11\n",
      " 6: -7.5450e+14 -7.5451e+14  7e+09  7e-02  3e-12\n",
      " 7: -7.5451e+14 -7.5451e+14  6e+08  2e-03  7e-14\n",
      " 8: -7.5451e+14 -7.5451e+14  4e+08  7e-04  3e-14\n",
      " 9: -7.5451e+14 -7.5451e+14  8e+07  5e-09  1e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.7074e+14 -7.2377e+14  7e+13  8e+05  6e-05\n",
      " 1: -6.9258e+14 -7.4004e+14  6e+13  5e+05  4e-05\n",
      " 2: -7.0720e+14 -7.2032e+14  1e+13  5e+03  4e-07\n",
      " 3: -7.0793e+14 -7.0899e+14  1e+12  3e+02  2e-08\n",
      " 4: -7.0806e+14 -7.0818e+14  1e+11  2e+01  1e-09\n",
      " 5: -7.0808e+14 -7.0810e+14  2e+10  2e-01  1e-11\n",
      " 6: -7.0808e+14 -7.0809e+14  3e+09  1e-02  7e-13\n",
      " 7: -7.0808e+14 -7.0808e+14  7e+08  2e-03  2e-13\n",
      " 8: -7.0808e+14 -7.0809e+14  2e+09  5e-04  4e-14\n",
      " 9: -7.0808e+14 -7.0808e+14  6e+08  8e-09  6e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.9528e+14 -7.6813e+14  1e+14  2e+06  8e-05\n",
      " 1: -7.4394e+14 -8.0921e+14  1e+14  1e+06  4e-05\n",
      " 2: -7.5941e+14 -7.7619e+14  2e+13  1e+04  4e-07\n",
      " 3: -7.6026e+14 -7.6212e+14  2e+12  1e+03  4e-08\n",
      " 4: -7.6045e+14 -7.6071e+14  3e+11  4e+01  2e-09\n",
      " 5: -7.6048e+14 -7.6051e+14  3e+10  2e+00  9e-11\n",
      " 6: -7.6048e+14 -7.6049e+14  5e+09  2e-01  7e-12\n",
      " 7: -7.6048e+14 -7.6048e+14  6e+08  9e-03  3e-13\n",
      " 8: -7.6048e+14 -7.6048e+14  1e+08  2e-03  6e-14\n",
      " 9: -7.6048e+14 -7.6048e+14  1e+08  4e-04  1e-14\n",
      "10: -7.6048e+14 -7.6048e+14  4e+07  8e-09  7e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.3383e+14 -7.8976e+14  8e+13  9e+05  6e-05\n",
      " 1: -7.5955e+14 -8.0938e+14  7e+13  6e+05  4e-05\n",
      " 2: -7.7439e+14 -7.8664e+14  1e+13  6e+03  4e-07\n",
      " 3: -7.7527e+14 -7.7734e+14  2e+12  8e+02  5e-08\n",
      " 4: -7.7551e+14 -7.7607e+14  6e+11  1e+02  8e-09\n",
      " 5: -7.7556e+14 -7.7564e+14  9e+10  1e+01  9e-10\n",
      " 6: -7.7557e+14 -7.7558e+14  9e+09  6e-01  4e-11\n",
      " 7: -7.7557e+14 -7.7557e+14  1e+09  2e-02  1e-12\n",
      " 8: -7.7557e+14 -7.7557e+14  2e+08  2e-03  2e-13\n",
      " 9: -7.7557e+14 -7.7557e+14  2e+08  5e-09  6e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.0906e+14 -7.6400e+14  1e+14  2e+06  7e-05\n",
      " 1: -7.4895e+14 -8.0023e+14  9e+13  1e+06  3e-05\n",
      " 2: -7.5895e+14 -7.7190e+14  1e+13  3e+04  9e-07\n",
      " 3: -7.6032e+14 -7.6491e+14  5e+12  7e+03  2e-07\n",
      " 4: -7.6078e+14 -7.6202e+14  1e+12  1e+03  4e-08\n",
      " 5: -7.6095e+14 -7.6116e+14  2e+11  1e+02  4e-09\n",
      " 6: -7.6099e+14 -7.6102e+14  3e+10  3e+00  1e-10\n",
      " 7: -7.6100e+14 -7.6100e+14  3e+09  3e-02  1e-12\n",
      " 8: -7.6100e+14 -7.6100e+14  4e+08  2e-03  6e-14\n",
      " 9: -7.6100e+14 -7.6100e+14  2e+08  7e-09  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.0298e+14 -7.5125e+14  1e+14  2e+06  7e-05\n",
      " 1: -7.4036e+14 -7.8635e+14  8e+13  1e+06  3e-05\n",
      " 2: -7.4903e+14 -7.6125e+14  1e+13  4e+04  1e-06\n",
      " 3: -7.5033e+14 -7.5381e+14  4e+12  7e+03  2e-07\n",
      " 4: -7.5067e+14 -7.5145e+14  8e+11  1e+03  3e-08\n",
      " 5: -7.5078e+14 -7.5094e+14  2e+11  1e+01  3e-10\n",
      " 6: -7.5081e+14 -7.5083e+14  2e+10  1e+00  3e-11\n",
      " 7: -7.5081e+14 -7.5082e+14  3e+09  2e-02  7e-13\n",
      " 8: -7.5081e+14 -7.5081e+14  5e+08  2e-03  6e-14\n",
      " 9: -7.5081e+14 -7.5081e+14  4e+08  5e-09  6e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.3008e+14 -6.7753e+14  9e+13  2e+06  6e-05\n",
      " 1: -6.5900e+14 -7.0224e+14  7e+13  8e+05  3e-05\n",
      " 2: -6.6805e+14 -6.7740e+14  9e+12  8e+03  3e-07\n",
      " 3: -6.6872e+14 -6.7002e+14  1e+12  8e+02  3e-08\n",
      " 4: -6.6886e+14 -6.6906e+14  2e+11  8e+01  3e-09\n",
      " 5: -6.6889e+14 -6.6892e+14  3e+10  8e-01  3e-11\n",
      " 6: -6.6889e+14 -6.6890e+14  4e+09  7e-02  3e-12\n",
      " 7: -6.6889e+14 -6.6889e+14  5e+08  4e-03  1e-13\n",
      " 8: -6.6889e+14 -6.6889e+14  4e+08  3e-03  1e-13\n",
      " 9: -6.6889e+14 -6.6889e+14  3e+08  1e-09  2e-15\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# freq_list = np.linspace(1000,5000-1,101,dtype=int, endpoint=True)\n",
    "\n",
    "# freq_list = np.linspace(0,5000,100,dtype=int, endpoint=False)\n",
    "\n",
    "ch_DRT, tau_vec = DRT_Batch(ch_id, EISDict, freq_list,_log_tau_min=-6, _log_tau_max=0)\n",
    "ch_DRT_cum = np.cumsum(ch_DRT,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chData = readChannel(ch_id, EISDict)\n",
    "fig, axis = plt.subplots(1,5,figsize=(15,6))\n",
    "cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "for i in range(np.shape(ch_DRT)[0]):\n",
    "# for i in [0,1,2]:\n",
    "    ch_eis = chData[i,:,freq_list].T\n",
    "    # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "    _color = cmap(i/np.shape(chData)[0])\n",
    "    axis[0].semilogx(tau_vec, np.power(ch_DRT[i],1), color = _color, linewidth=2, label=f\"Session {i}\", alpha = 0.5)\n",
    "    axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    axis[2].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    axis[3].plot(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    axis[4].loglog(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[4].semilogx(tau_vec, ch_DRT_cum[i], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[3].plot(chData[i,1,1000:], -chData[i,2,1000:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    " \n",
    " \n",
    "# axis[0].legend(frameon=False, loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "chData = readChannel(ch_id, EISDict)\n",
    "fig, axis = plt.subplots(2,1,figsize=(15,6))\n",
    "cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "for i in range(np.shape(ch_DRT)[0]):\n",
    "# for i in [0,-1]:\n",
    "    ch_eis = chData[i,:,freq_list].T\n",
    "    # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "    _color = cmap(i/np.shape(chData)[0])\n",
    "    axis[0].semilogx(tau_vec, np.power(ch_DRT[i],1), color = _color, linewidth=2, label=f\"Session {i}\", alpha = 0.5)\n",
    "    axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[2].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[3].plot(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[4].loglog(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[4].semilogx(tau_vec, ch_DRT_cum[i], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[3].plot(chData[i,1,1000:], -chData[i,2,1000:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    " \n",
    " \n",
    "# axis[0].legend(frameon=False, loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chData = readChannel(ch_id, EISDict)\n",
    "# fig, axis = plt.subplots(1,1,figsize=(15,6))\n",
    "# cmap = plt.get_cmap('rainbow_r')\n",
    "# for i in range(np.shape(ch_DRT)[0]):\n",
    "# # for i in [0,1,2,3,4,5,6,9,10,11,12]:\n",
    "#     ch_eis = chData[i,:,freq_list].T\n",
    "#     # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "#     _color = cmap(i/np.shape(chData)[0])\n",
    "#     axis.loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    \n",
    " \n",
    "# # axis[0].legend(frameon=False, loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3D Plot\n",
    "# fig = plt.figure()\n",
    "# ax0 = fig.add_subplot(121, projection='3d')\n",
    "# ax1 = fig.add_subplot(122, projection='3d')\n",
    "# init_elev = 21  # 仰角\n",
    "# init_azim = 55  # 方位角\n",
    "# ax0.view_init(elev=init_elev, azim=init_azim)\n",
    "# ax1.view_init(elev=init_elev, azim=init_azim)\n",
    "\n",
    "# # x = np.log10(tau_vec).flatten()\n",
    "# x = np.array(range(ch_DRT.shape[0]))\n",
    "# y = np.array(range(ch_DRT.shape[1]))\n",
    "# X,Y = np.meshgrid(x,y,indexing='ij')\n",
    "# ax0.plot_surface(X, Y, ch_DRT[:,:ch_DRT.shape[1]], cmap='viridis_r', alpha=0.8)\n",
    "\n",
    "\n",
    "# ch_Data_ds = np.abs(chData[:,1,:] + 1j*chData[:,2,:])\n",
    "# x = np.array(range(ch_Data_ds.shape[0]))\n",
    "# y = np.array(range(ch_Data_ds.shape[1]))\n",
    "# X,Y = np.meshgrid(x,y,indexing='ij')\n",
    "# ax1.plot_surface(X, Y, np.log10(ch_Data_ds), cmap='viridis_r', alpha=0.8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array(range(ch_DRT.shape[1]))\n",
    "# y = np.array(range(ch_DRT.shape[0]))\n",
    "\n",
    "# X,Y = np.meshgrid(x,y)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# gs = plt.GridSpec(1,1)\n",
    "# plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0.5)\n",
    "# ax = plt.subplot(gs[0,0])\n",
    "# cs = ax.contourf(X,Y,ch_DRT,cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT_dimentional deduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "# data = ch_DRT\n",
    "# data = np.log(ch_DRT_cum)\n",
    "data = np.log(ch_EIS)\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "emb_dist = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n",
    "    \n",
    "    _x = embedding[:,0].flatten()\n",
    "    _y = embedding[:,1].flatten()\n",
    "\n",
    "    emb_dist[name] = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                         (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(3,4,figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:,0].flatten()\n",
    "    _y = emb[:,1].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                         (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "    # _dist = emb_dist[name]\n",
    "\n",
    "    axis[np.int16(i/2),(i%2)*2].scatter(emb[:, 0], emb[:, 1], c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    axis[np.int16(i/2),(i%2)*2].set_title(name)\n",
    "\n",
    "    s = axis[np.int16(i/2),(i%2)*2+1].imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2),(i%2)*2+1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axis = plt.subplots(3, 4, figsize=(12, 6), subplot_kw={'projection': '3d'})  # 指定3D投影\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten()\n",
    "    _y = emb[:, 1].flatten()\n",
    "    _z = emb[:, 2].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data 添加顺序信息\n",
    "这里需要调整顺序信息在整个DRT数据中的权重，容易因为顺序信息过强导致异常值不显著"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "\n",
    "index_scale = np.max(ch_DRT) * 0.5\n",
    "index_vec = ((np.arange(np.shape(ch_DRT)[0])+1) * index_scale ).reshape(-1,1)\n",
    "ch_DRT_ext = np.hstack((ch_DRT, index_vec))\n",
    "\n",
    "\n",
    "# data = ch_DRT\n",
    "# data = np.log(ch_EIS)\n",
    "data =np.hstack((ch_DRT, index_vec))\n",
    "# data =np.hstack((ch_EIS, index_vec))\n",
    "\n",
    "\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(3,4,figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:,0].flatten()\n",
    "    _y = emb[:,1].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                         (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n",
    "\n",
    "    axis[np.int16(i/2),(i%2)*2].scatter(emb[:, 0], emb[:, 1], c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    axis[np.int16(i/2),(i%2)*2].set_title(name)\n",
    "\n",
    "    s = axis[np.int16(i/2),(i%2)*2+1].imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2),(i%2)*2+1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten()\n",
    "    _y = emb[:, 1].flatten()\n",
    "    _z = emb[:, 2].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA添加顺序信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "\n",
    "\n",
    "data = ch_DRT\n",
    "# data = np.log(ch_EIS)\n",
    "\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten() / np.max(emb[:, 0])\n",
    "    _y = emb[:, 1].flatten() / np.max(emb[:, 1])\n",
    "    _z = (np.arange(np.shape(emb)[0]) + 1).flatten() / np.shape(emb)[0] \n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EIS变化张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_dist_tensor(data_cpx):\n",
    "    n_sample = np.shape(data_cpx)[1]\n",
    "    dist_tensor = []\n",
    "    for i in range(n_sample):\n",
    "        _vec = data_cpx[:,i].reshape(-1,1)\n",
    "        dist_tensor.append(np.real(_vec - _vec.T))\n",
    "        dist_tensor.append(np.imag(_vec - _vec.T))\n",
    "    dist_tensor = np.array(dist_tensor).T\n",
    "    return dist_tensor.reshape(np.shape(dist_tensor)[0],-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "ch_EIS_cpx = chData[:,1,freq_list] + 1j*chData[:,2,freq_list]\n",
    "dist_tensor = assemble_dist_tensor(ch_EIS_cpx)\n",
    "data = dist_tensor\n",
    "# data = np.log(ch_DRT_cum)\n",
    "# data = np.log(ch_EIS)\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(3,4,figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:,0].flatten()\n",
    "    _y = emb[:,1].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n",
    "\n",
    "    axis[np.int16(i/2),(i%2)*2].scatter(emb[:, 0], emb[:, 1], c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    axis[np.int16(i/2),(i%2)*2].set_title(name)\n",
    "\n",
    "    s = axis[np.int16(i/2),(i%2)*2+1].imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2),(i%2)*2+1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten()\n",
    "    _y = emb[:, 1].flatten()\n",
    "    _z = emb[:, 2].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT or EIS based OD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM\n",
    "由于需要手动设置状态，无法很好的区分异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# 假设你的数据是一个 16x101 的矩阵，这里用随机数据模拟\n",
    "np.random.seed(42)\n",
    "# data = ch_DRT\n",
    "data = np.log(ch_EIS)\n",
    "\n",
    "# 如果需要，也可以对数据做预处理，例如归一化\n",
    "\n",
    "# 定义最大可能状态数，比如设为5\n",
    "max_states = 4\n",
    "\n",
    "# 初始化高斯隐马尔可夫模型\n",
    "# covariance_type 可以根据数据特性选择 'diag' 或 'full'\n",
    "model = hmm.GaussianHMM(n_components=max_states, covariance_type='diag', n_iter=100, random_state=42)\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(data)\n",
    "\n",
    "# 使用模型预测隐状态序列（返回长度为16的一维数组）\n",
    "hidden_states = model.predict(data)\n",
    "print(\"预测的隐状态序列:\", hidden_states)\n",
    "\n",
    "# 输出状态转移矩阵，观察哪些状态有较高的占用概率\n",
    "print(\"状态转移矩阵:\\n\", model.transmat_)\n",
    "\n",
    "# 可视化隐状态随时间的变化\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(hidden_states, marker='o', linestyle='-')\n",
    "plt.xlabel('Time Stamp')\n",
    "plt.ylabel('Hidden State')\n",
    "plt.title('HMM Hidden State Series')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Change Point Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import t  # 导入 Student-t 分布\n",
    "\n",
    "# ----------------------------\n",
    "# 1. 数据准备与降维\n",
    "# ----------------------------\n",
    "np.random.seed(42)\n",
    "data = ch_DRT\n",
    "# data = np.random.randn(16, 101)\n",
    "# data[8:] += 5  # 模拟状态转移\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "data_1d = pca.fit_transform(data).flatten()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. BOCPD实现（Univariate case）\n",
    "# ----------------------------\n",
    "T = len(data_1d)\n",
    "R = np.zeros((T + 1, T + 1))\n",
    "R[0, 0] = 1\n",
    "\n",
    "# Normal-Inverse-Gamma先验参数\n",
    "mu0 = 0.0\n",
    "kappa0 = 1.0\n",
    "alpha0 = 1.0\n",
    "beta0 = 1.0\n",
    "\n",
    "# 初始化足够统计量，使用字典存储，key为运行长度\n",
    "mu = {0: mu0}\n",
    "kappa = {0: kappa0}\n",
    "alpha = {0: alpha0}\n",
    "beta = {0: beta0}\n",
    "\n",
    "def predictive_pdf(x, mu_val, kappa_val, alpha_val, beta_val):\n",
    "    \"\"\"\n",
    "    预测分布为 Student-t 分布：\n",
    "      - 自由度: nu = 2 * alpha_val\n",
    "      - 位置: mu_val\n",
    "      - 尺度: sqrt( beta_val*(kappa_val+1) / (alpha_val*kappa_val) )\n",
    "    \"\"\"\n",
    "    nu = 2 * alpha_val\n",
    "    scale = np.sqrt(beta_val * (kappa_val + 1) / (alpha_val * kappa_val))\n",
    "    return t.pdf(x, df=nu, loc=mu_val, scale=scale)\n",
    "\n",
    "def constant_hazard(lam):\n",
    "    \"\"\"常数危险函数\"\"\"\n",
    "    return lambda r: np.full(r.shape, 1.0 / lam)\n",
    "\n",
    "hazard = constant_hazard(100)\n",
    "cp_probabilities = []\n",
    "\n",
    "for time_idx in range(1, T + 1):\n",
    "    x = data_1d[time_idx - 1]\n",
    "    pred_probs = np.zeros(time_idx)\n",
    "    for r in range(time_idx):\n",
    "        pred_probs[r] = predictive_pdf(x, mu[r], kappa[r], alpha[r], beta[r])\n",
    "    \n",
    "    growth_probs = R[time_idx - 1, :time_idx] * (1 - hazard(np.arange(1, time_idx + 1))) * pred_probs\n",
    "    cp_prob = np.sum(R[time_idx - 1, :time_idx] * hazard(np.arange(1, time_idx + 1)) * pred_probs)\n",
    "    \n",
    "    R[time_idx, 1:time_idx + 1] = growth_probs\n",
    "    R[time_idx, 0] = cp_prob\n",
    "    R[time_idx, :time_idx + 1] /= np.sum(R[time_idx, :time_idx + 1])\n",
    "    \n",
    "    cp_probabilities.append(R[time_idx, 0])\n",
    "    \n",
    "    new_mu = {}\n",
    "    new_kappa = {}\n",
    "    new_alpha = {}\n",
    "    new_beta = {}\n",
    "    \n",
    "    new_mu[0] = mu0\n",
    "    new_kappa[0] = kappa0\n",
    "    new_alpha[0] = alpha0\n",
    "    new_beta[0] = beta0\n",
    "    \n",
    "    for r in range(1, time_idx + 1):\n",
    "        new_mu[r] = (kappa[r - 1] * mu[r - 1] + x) / (kappa[r - 1] + 1)\n",
    "        new_kappa[r] = kappa[r - 1] + 1\n",
    "        new_alpha[r] = alpha[r - 1] + 0.5\n",
    "        new_beta[r] = beta[r - 1] + 0.5 * ((x - mu[r - 1]) ** 2 * kappa[r - 1] / (kappa[r - 1] + 1))\n",
    "    \n",
    "    mu = new_mu\n",
    "    kappa = new_kappa\n",
    "    alpha = new_alpha\n",
    "    beta = new_beta\n",
    "\n",
    "# ----------------------------\n",
    "# 3. 可视化\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stem(range(1, T + 1), cp_probabilities, basefmt=\" \")\n",
    "plt.xlabel('时间点')\n",
    "plt.ylabel('变点概率')\n",
    "plt.title('贝叶斯在线变点检测 - 变点概率')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, T + 1), data_1d, marker='o')\n",
    "plt.xlabel('时间点')\n",
    "plt.ylabel('PCA降维后数据')\n",
    "plt.title('1D降维数据及变点检测')\n",
    "plt.axvline(x=8, color='red', linestyle='--', label='模拟变点（时刻8）')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OD - IsoForest / LOF / SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "# from pyod.models.pca import PCA as PCA_OD\n",
    "\n",
    "# 生成示例数据\n",
    "# np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "# data = ch_DRT\n",
    "data = np.log(ch_EIS)\n",
    "\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "# 使用PCA将数据降维到2D，以便可视化\n",
    "data_2d = methods['PCA'].fit_transform(data)\n",
    "\n",
    "# 定义子图布局\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 1. 使用PCA进行异常检测\n",
    "# pca_od = PCA_OD(contamination=0.1)\n",
    "# pca_od.fit(data)\n",
    "# pca_scores = pca_od.decision_function(data)\n",
    "# pca_predictions = pca_od.predict(data)\n",
    "# axes[0].scatter(data_2d[:, 0], data_2d[:, 1], c=pca_predictions, cmap='coolwarm', edgecolor='k')\n",
    "# axes[0].set_title('PCA Anomaly Detection')\n",
    "\n",
    "# 2. 使用Isolation Forest进行异常检测\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=100)\n",
    "iso_forest.fit(data)\n",
    "iso_predictions = iso_forest.predict(data)\n",
    "iso_predictions = np.where(iso_predictions == 1, 0, 1)  # 转换为0表示正常，1表示异常\n",
    "axes[0].scatter(data_2d[:, 0], data_2d[:, 1], c=iso_predictions, cmap='coolwarm', edgecolor='k')\n",
    "axes[0].set_title('Isolation Forest Anomaly Detection')\n",
    "\n",
    "# 3. 使用LOF进行异常检测\n",
    "lof = LocalOutlierFactor(n_neighbors=4, contamination=0.2)\n",
    "lof_predictions = lof.fit_predict(data)\n",
    "lof_predictions = np.where(lof_predictions == 1, 0, 1)  # 转换为0表示正常，1表示异常\n",
    "axes[1].scatter(data_2d[:, 0], data_2d[:, 1], c=lof_predictions, cmap='coolwarm', edgecolor='k')\n",
    "axes[1].set_title('LOF Anomaly Detection')\n",
    "\n",
    "# 4. 使用One-Class SVM进行异常检测\n",
    "oc_svm = OneClassSVM(nu=0.1, kernel='rbf', gamma='auto')\n",
    "oc_svm.fit(data)\n",
    "oc_predictions = oc_svm.predict(data)\n",
    "oc_predictions = np.where(oc_predictions == 1, 0, 1)  # 转换为0表示正常，1表示异常\n",
    "axes[2].scatter(data_2d[:, 0], data_2d[:, 1], c=oc_predictions, cmap='coolwarm', edgecolor='k')\n",
    "axes[2].set_title('One-Class SVM Anomaly Detection')\n",
    "\n",
    "# 设置图形标题和布局\n",
    "plt.suptitle('Anomaly Detection Results Using Different Algorithms')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dist Based Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 生成模拟的 16x16 距离矩阵（对称矩阵，模拟样本间距离）\n",
    "np.random.seed(42)\n",
    "A = emb_dist['PCA']\n",
    "\n",
    "# PCA 降维用于可视化\n",
    "pca = PCA(n_components=2)\n",
    "X_2D = pca.fit_transform(A)\n",
    "\n",
    "# ==================== 层次聚类 ====================\n",
    "Z = linkage(A, method='average',optimal_ordering=True)  # 使用 Ward 方式进行层次聚类\n",
    "clusters_hierarchical = fcluster(Z, t=3, criterion='maxclust')\n",
    "\n",
    "# ==================== DBSCAN ====================\n",
    "dbscan = DBSCAN(metric='precomputed', eps=0.5, min_samples=2)\n",
    "clusters_dbscan = dbscan.fit_predict(A)\n",
    "\n",
    "# ==================== LOF ====================\n",
    "lof = LocalOutlierFactor(metric='precomputed', n_neighbors=5)\n",
    "lof_outlier_scores = lof.fit_predict(A)\n",
    "\n",
    "# 可视化函数\n",
    "def plot_results(title, labels):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(X_2D[:, 0], X_2D[:, 1], c=labels, cmap='coolwarm', edgecolors='k', s=100)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PCA 1\")\n",
    "    plt.ylabel(\"PCA 2\")\n",
    "    plt.show()\n",
    "\n",
    "# 绘制层次聚类结果\n",
    "plot_results(\"Hierarchical Clustering\", clusters_hierarchical)\n",
    "\n",
    "# 绘制 DBSCAN 结果\n",
    "plot_results(\"DBSCAN Clustering\", clusters_dbscan)\n",
    "\n",
    "# 绘制 LOF 结果（-1 为异常点）\n",
    "plot_results(\"Local Outlier Factor (LOF)\", lof_outlier_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dist Based series order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# 模拟 16x16 的相关性矩阵（对称，主对角线为1）\n",
    "np.random.seed(42)\n",
    "D = emb_dist['MDS']/np.max(emb_dist['MDS'])  # 16x16 距离矩阵\n",
    "# D = (pca_dist-np.mean(pca_dist))  # 16x16 距离矩阵\n",
    "\n",
    "# --- 方法1：修改距离矩阵 ---\n",
    "lambda_penalty = 0  # 调节因子，可根据需要调整\n",
    "n = D.shape[0]\n",
    "indices = np.arange(n)\n",
    "# 构造原始顺序差值矩阵 |i - j|\n",
    "diff_matrix = np.abs(indices.reshape(-1, 1) - indices.reshape(1, -1)) / n\n",
    "P = lambda_penalty * diff_matrix\n",
    "D_mod = D + P  # 修改后的距离矩阵\n",
    "\n",
    "# 转换为 condensed 距离向量供 linkage 使用\n",
    "condensed_D_mod = squareform(D_mod)\n",
    "# 使用平均链接法构造层次聚类树\n",
    "Z_mod = linkage(condensed_D_mod, method='average',optimal_ordering=True)\n",
    "# Z_mod = linkage(condensed_D_mod, method='ward',optimal_ordering=True)\n",
    "# 可选：利用 optimal_leaf_ordering 获得最优叶排序\n",
    "Z_mod_olo = optimal_leaf_ordering(Z_mod, condensed_D_mod)\n",
    "dendro1 = dendrogram(Z_mod_olo, no_plot=True)\n",
    "order1 = dendro1['leaves']\n",
    "# print(\"方法1排序结果：\", order1)\n",
    "\n",
    "# 可视化排序后矩阵\n",
    "sorted_A1 = D[np.ix_(order1, order1)]\n",
    "plt.figure(figsize=(6, 5))\n",
    "# sns.heatmap(sorted_A1, annot=False, cmap='coolwarm')\n",
    "sns.heatmap(D+P, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Ordered Matrix Based on Modified Distance\")\n",
    "plt.show()\n",
    "\n",
    "# 可视化层次聚类树\n",
    "plt.figure(figsize=(8, 4))\n",
    "# dendrogram(Z_mod_olo, labels=np.arange(n))\n",
    "dendrogram(Z_mod, labels=np.arange(n))\n",
    "plt.title(\"H\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Dist\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Optimal Leaf Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# 示例16x16距离矩阵\n",
    "np.random.seed(42)\n",
    "distance_matrix = emb_dist['PCA']/np.max(emb_dist['PCA'])  # 16x16 距离矩阵\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# 使用MDS将距离矩阵转换为坐标形式\n",
    "mds = MDS(n_components=2, dissimilarity='euclidean', random_state=42)\n",
    "coords = mds.fit_transform(ch_DRT)\n",
    "\n",
    "# 进行GMM聚类\n",
    "n_components = 3  # 假设分为4个高斯成分\n",
    "gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "gmm.fit(coords)\n",
    "labels = gmm.predict(coords)\n",
    "\n",
    "# 可视化GMM聚类结果\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c=labels, cmap='viridis', s=100, )\n",
    "plt.title(\"高斯混合模型 - MDS降维后的聚类结果\")\n",
    "plt.xlabel(\"MDS Dimension 1\")\n",
    "plt.ylabel(\"MDS Dimension 2\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRT_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import numpy as np\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # 假设你的数据是 16x101 的 numpy 数组\n",
    "# # freq_list = np.linspace(1000,5000-1,101,dtype=int, endpoint=True)\n",
    " \n",
    "# chData = readChannel(ch_id, EISDict)\n",
    "# ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "# # data = np.log(ch_EIS)\n",
    "# # data = ch_EIS\n",
    "\n",
    "# # data = np.log(ch_DRT+1)\n",
    "# data = ch_DRT_cum\n",
    "\n",
    "# # 1. 数据中心化（去均值）\n",
    "# mean = np.mean(data, axis=0)\n",
    "# data_centered = data - mean\n",
    "\n",
    "# # 2. 计算协方差矩阵\n",
    "# cov_matrix = np.cov(data_centered, rowvar=False)\n",
    "\n",
    "# # 3. 计算特征值和特征向量\n",
    "# eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "# # 4. 按特征值大小排序\n",
    "# idx = np.argsort(eigenvalues)[::-1]  # 从大到小排序\n",
    "# eigenvalues = eigenvalues[idx]\n",
    "# eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "# # 5. 选择前 k 个主成分（这里 k=2）\n",
    "# k = 2\n",
    "# top_eigenvectors = np.hstack((eigenvectors[:, 0].reshape(-1,1),eigenvectors[:, 1].reshape(-1,1)))\n",
    "\n",
    "# # 6. 投影数据到主成分空间\n",
    "# pca_data = np.dot(data_centered, top_eigenvectors)\n",
    "\n",
    "# # 7. 计算PCA下距离\n",
    "# _x = pca_data[:,0].flatten()\n",
    "# _y = pca_data[:,1].flatten()\n",
    "\n",
    "# pca_dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "#                          (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n",
    "# # pca_dist_Z = (pca_dist-np.mean(pca_dist))/np.std(pca_dist)\n",
    "\n",
    "\n",
    "# fig, axis = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "# # 7. 画出前两个主成分\n",
    "# axis[0].scatter(pca_data[:, 0], pca_data[:, 1],c=np.arange(len(pca_data)), cmap='rainbow_r')\n",
    "# axis[0].set_xlabel(\"Principal Component 1\")\n",
    "# axis[0].set_ylabel(\"Principal Component 2\")\n",
    "# axis[0].set_title(\"PCA Projection\")\n",
    "# # axis[0].set_aspect('equal')\n",
    "\n",
    "\n",
    "\n",
    "# # 绘制热图\n",
    "# # s = axis[1].imshow(pca_dist_Z, vmin=-1, vmax=1, cmap='coolwarm', interpolation='nearest')\n",
    "# s = axis[1].imshow(pca_dist, cmap='coolwarm', interpolation='nearest')\n",
    "# # s = axis[1].imshow(pca_dist, cmap='coolwarm', interpolation='nearest')\n",
    "# fig.colorbar(s, ax=axis[1])\n",
    "# axis[1].set_ylabel(\"Point Index\")\n",
    "# axis[1].set_title(\"Distance Matrix Heatmap\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discuss lambda\n",
    "if False:\n",
    "    chData = readChannel(ch_id, EISDict)\n",
    "    freq_list = np.linspace(500,np.shape(chData)[2]-1,101,dtype=int, endpoint=True)\n",
    "    # tau_vec, x_DRT = DRT(chData[0,:,freq_list].T)\n",
    "    # np.shape(chData[0,:,freq_list].T)\n",
    "\n",
    "    fig, axis = plt.subplots(1,3,figsize=(15,6))\n",
    "    cmap = plt.get_cmap('RdYlBu')\n",
    "    # cmap = plt.get_cmap('rainbow_r')\n",
    "    RLC_flag = [False, False, False]\n",
    "    # custom_lambda = None\n",
    "    custom_lambda_list = np.logspace(-6, 0, 7, endpoint=True)\n",
    "    # for i in range(np.shape(chData)[0]):\n",
    "    for i in range(7):\n",
    "        if True:\n",
    "            ch_eis = chData[0,:,freq_list].T\n",
    "            # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "            # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "            tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag,custom_lambda_list[i])\n",
    "            \n",
    "            \n",
    "            _color = cmap(i/np.shape(custom_lambda_list)[0])\n",
    "            # if i == 5: _color = 'black'\n",
    "            axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"$\\lambda$={custom_lambda_list[i]:.1e}\")\n",
    "            axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"$\\lambda$={custom_lambda_list[i]:.1e}\")\n",
    "            axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"$\\lambda$={custom_lambda_list[i]:.1e}\")\n",
    "            \n",
    "            axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "        \n",
    "        if False:\n",
    "            ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "            # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "            # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "            tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag)\n",
    "            \n",
    "            \n",
    "            _color = cmap(i/np.shape(chData)[0])\n",
    "            axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "            axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "            axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "            \n",
    "            axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "        # plt.plot(np.log10(ch_eis[0,:]), np.log10(np.abs(ch_eis[1,:]+1j*ch_eis[2,:])), 'r')\n",
    "        # plt.plot(np.log10(ch_eis_rec[0,:]), np.log10(np.abs(ch_eis_rec[1,:]+1j*ch_eis_rec[2,:])), 'b')\n",
    "        # plt.plot(np.log10(ch_day[0,:]), np.rad2deg(np.angle(ch_day[1,:]+1j*ch_day[2,:])), 'r')\n",
    "        # plt.plot(np.log10(ch_day_rec[0,:]), np.rad2deg(np.angle(ch_day_rec[1,:]+1j*ch_day_rec[2,:])), 'b')\n",
    "\n",
    "\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
