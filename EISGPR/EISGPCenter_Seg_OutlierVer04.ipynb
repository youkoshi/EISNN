{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "本文档基于分布计算得到的outlier detection数据库进行分段GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Outlier import OutlierDetection\n",
    "import Interpolation\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filesys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchELE(rootPath, ele_pattern = re.compile(r\"(.+?)_归档\")):\n",
    "    '''==================================================\n",
    "        Search all electrode directories in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            ele_pattern: electrode dir name patten\n",
    "        Returen:\n",
    "            ele_list: list of electrode directories\n",
    "        ==================================================\n",
    "    '''\n",
    "    ele_list = []\n",
    "    for i in os.listdir(rootPath):\n",
    "        _path = os.path.join(rootPath, i)\n",
    "        if os.path.isdir(_path):\n",
    "            match_ele = ele_pattern.match(i)\n",
    "            if match_ele:\n",
    "                ele_list.append([_path, match_ele.group(1)])\n",
    "            else:\n",
    "                ele_list.extend(SearchELE(_path, ele_pattern))\n",
    "\n",
    "    return ele_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(log_dir=\"./LOG\", log_filename=\"file.log\", file_level=\"WARNING\", console_level=\"WARNING\"):\n",
    "    # 创建目录\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_fd = os.path.join(log_dir, log_filename)\n",
    "\n",
    "    logger.remove()\n",
    "    # 如果已有日志文件，重命名添加时间戳\n",
    "    if os.path.exists(log_fd):\n",
    "        name, ext = os.path.splitext(log_filename)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        archived_name = f\"{name}_{timestamp}{ext}\"\n",
    "        archived_path = os.path.join(log_dir, archived_name)\n",
    "        os.rename(log_fd, archived_path)\n",
    "\n",
    "    # 添加终端输出\n",
    "    logger.add(sys.stdout, level=console_level, enqueue=True)\n",
    "\n",
    "    # 添加文件输出\n",
    "    logger.add(log_fd, level=file_level, encoding=\"utf-8\", enqueue=True)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    setup_logger(log_dir=\"D:\\Baihm\\EISNN\\LOG\\GPR_outlier_Ver04\")\n",
    "\n",
    "# logger.remove()\n",
    "# logger.add(sys.stdout, level=\"WARNING\")\n",
    "# logger.add(\"./LOG/file.log\", rotation=\"10 MB\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootPath = \"D:/Baihm/EISNN/Archive/\"\n",
    "# ele_list = SearchELE(rootPath)\n",
    "# DATASET_SUFFIX = \"Outlier_Ver03\"\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive_New/\"\n",
    "# ele_list = SearchELE(rootPath)\n",
    "# DATASET_SUFFIX = \"Outlier_Ver04\"\n",
    "\n",
    "rootPath = \"D:/Baihm/EISNN/Invivo/\"\n",
    "ele_list = SearchELE(rootPath, re.compile(r\"(.+?)_Ver02\"))\n",
    "DATASET_SUFFIX = \"Outlier_Ver04\"\n",
    "\n",
    "\n",
    "n_ele = len(ele_list)\n",
    "logger.info(f\"Search in {rootPath} and find {n_ele:03d} electrodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each Electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list = np.linspace(0,5000-1,101,dtype=int, endpoint=True)\n",
    "\n",
    "MODEL_SUFFIX = f\"{DATASET_SUFFIX}_Matern12_Ver01\"\n",
    "SAVE_FLAG = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(n_ele):\n",
    "# for i in range(0,3):\n",
    "    # logger.info(f\"ELE Begin: {ele_list[i][0]}\")\n",
    "    fd_pt = os.path.join(ele_list[i][0], DATASET_SUFFIX, f\"{ele_list[i][1]}_{DATASET_SUFFIX}.pt\")\n",
    "    if not os.path.exists(fd_pt):\n",
    "        logger.warning(f\"{fd_pt} does not exist\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    data_pt = torch.load(fd_pt)\n",
    "    _meta_group = data_pt[\"meta_group\"]\n",
    "    _data_group = data_pt[\"data_group\"]\n",
    "\n",
    "\n",
    "    ele_id  = _meta_group[\"ele_id\"]\n",
    "    elePath = _meta_group[\"elePath\"]\n",
    "    n_ch = _meta_group[\"n_ch\"]      \n",
    "    x_day_full = _meta_group[\"TimeSpan\"]\n",
    "\n",
    "\n",
    "    logger.warning(f\"ELE[{i+1}/{n_ele}]: \\t{ele_id} - {elePath}\")\n",
    "\n",
    "\n",
    "    # Storage path\n",
    "    save_dir = f\"{elePath}/{MODEL_SUFFIX}/\"\n",
    "    pt_file_name = f\"{ele_id}_{MODEL_SUFFIX}.pt\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    if os.path.exists(os.path.join(save_dir, pt_file_name)):\n",
    "        logger.warning(f\"FileAlreadyExistsWarning: {ele_id} - {pt_file_name} already exists.\")\n",
    "        if SAVE_FLAG:\n",
    "            continue\n",
    "\n",
    "\n",
    "    for j in _data_group['Channels']:\n",
    "        try:\n",
    "            logger.info(f\"ELE[{ele_id}] - ch[{j}] Begin\") \n",
    "            channel_group_raw = _data_group[j]\n",
    "\n",
    "            \n",
    "            chData      = channel_group_raw['chData']         \n",
    "            eis_seq     = channel_group_raw['eis_seq']        \n",
    "            eis_cluster = channel_group_raw['eis_cluster']    \n",
    "            eis_anomaly = channel_group_raw['eis_anomaly']    \n",
    "\n",
    "            if chData.shape[2] == 5000:\n",
    "                chData = chData[:, :, freq_list]\n",
    "\n",
    "\n",
    "            # Interpolation\n",
    "            x_train_full, y_train_full, x_eval_full, y_eval_full, y_eval_err_full, eis_cluster_eval = \\\n",
    "                Interpolation.PiecewiseGPR(x_day_full, chData, eis_seq, eis_cluster, SPEED_RATE = 2, training_iter = 200, lr = 0.05)\n",
    "\n",
    "            logger.info(f\"ELE[{ele_id}] - ch[{j}] Interpolation Finished\")\n",
    "\n",
    "            # Plot\n",
    "            fig = plt.figure(figsize=(16, 9), constrained_layout=True)\n",
    "            Interpolation.EISPreprocessPlot(fig, chData, x_train_full, y_train_full, x_eval_full, y_eval_full, y_eval_err_full, eis_seq, eis_cluster, eis_anomaly)\n",
    "                \n",
    "            axis = fig.add_subplot(3,4,12)\n",
    "            axis.axis('off')\n",
    "            font_properties = {\n",
    "                'family': 'monospace',  # 固定宽度字体\n",
    "                'size': 14,             # 字体大小\n",
    "                'weight': 'bold'        # 加粗\n",
    "            }\n",
    "\n",
    "            text = f\"EIE  : {ele_id}\\nCHID : {j:03d}\\nFrom : {x_day_full[0].strftime('%Y-%m-%d')}\\nTo   : {x_day_full[-1].strftime('%Y-%m-%d')}\"\n",
    "            axis.text(0.2, 0.5, text, fontdict = font_properties, ha='left', va='center')\n",
    "\n",
    "            # Save Fig\n",
    "            fig_name = f\"EISGPR_{ele_id}_ch{j:03d}.png\"\n",
    "            \n",
    "            os.makedirs(save_dir, exist_ok=True) \n",
    "            path = os.path.join(save_dir, fig_name)\n",
    "\n",
    "            fig.savefig(path)\n",
    "            plt.close(fig) \n",
    "\n",
    "            # Data Saving\n",
    "            channel_group_intp = {}\n",
    "            channel_group_intp['chData_intp_mean']  = y_eval_full\n",
    "            channel_group_intp['chData_intp_var']   = y_eval_err_full\n",
    "            channel_group_intp['x_train']           = x_train_full\n",
    "            channel_group_intp['x_eval']            = x_eval_full\n",
    "            channel_group_intp['x_eval_cluster']    = eis_cluster_eval\n",
    "\n",
    "            _data_group[j] = channel_group_intp\n",
    "            logger.info(f\"ELE[{ele_id}] - ch[{j}] Finished\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ELE[{ele_id}] - ch[{j}] Run with error: {e}\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "    pt_store = {}\n",
    "    pt_store[\"meta_group\"] = _meta_group\n",
    "    pt_store[\"data_group\"] = _data_group\n",
    "    if SAVE_FLAG:\n",
    "        torch.save(pt_store, os.path.join(save_dir, pt_file_name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    pt_name = \"D:\\Baihm\\EISNN\\Archive/01037160_归档\\Matern12_Ver01/01037160_Matern12_Ver01.pt\"\n",
    "    loaded = torch.load(pt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MODEL_SUFFIX = \"Matern12_Ver01\"\n",
    "\n",
    "# all_data_list = []\n",
    "\n",
    "# for i in range(n_ele):\n",
    "# # for i in range(3):\n",
    "#     fd_pt = os.path.join(ele_list[i][0], MODEL_SUFFIX, f\"{ele_list[i][1]}_{MODEL_SUFFIX}.pt\")\n",
    "#     if not os.path.exists(fd_pt):\n",
    "#         # logger.warning(f\"{fd_pt} does not exist\")\n",
    "#         continue\n",
    "#     data_pt = torch.load(fd_pt, weights_only=False)\n",
    "#     _meta_group = data_pt[\"meta_group\"]\n",
    "#     _data_group = data_pt[\"data_group\"]\n",
    "\n",
    "#     n_day       = _meta_group[\"n_day\"]\n",
    "#     n_ch        = _meta_group[\"n_ch\"]\n",
    "#     n_valid_ch  = len(_data_group[\"Channels\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
