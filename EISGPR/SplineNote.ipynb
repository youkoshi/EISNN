{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%gui qt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pyqtgraph as pg\n",
    "import pyqtgraph.opengl as gl\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import scipy.interpolate as interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherCSV(rootPath, outsuffix = 'Tracking'):\n",
    "    '''==================================================\n",
    "        Collect all EIS.csv files in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            outsuffix: Saving path of EIS.csv files\n",
    "        Returen:\n",
    "            EISDict: a 2D-dict of EIS data\n",
    "            Storage Frame: EISDict[_sessionIndex][_channelIndex] = \"_filepath\"\n",
    "        ==================================================\n",
    "    '''\n",
    "    _filename       = None\n",
    "    _filepath       = None\n",
    "    _trackpath      = None\n",
    "    _csvpath        = None\n",
    "    _sessionIndex   = None\n",
    "    _channelIndex   = None\n",
    "    _processed      = None\n",
    "\n",
    "    EISDict = defaultdict(dict)\n",
    "\n",
    "    ## Iterate session\n",
    "    session_pattern = re.compile(r\"(.+?)_(\\d{8})_01\")\n",
    "    bank_pattern    = re.compile(r\"([1-4])\")\n",
    "    file_pattern    = re.compile(r\"EIS_ch(\\d{3})\\.csv\")\n",
    "\n",
    "    ## RootDir\n",
    "    for i in os.listdir(rootPath):\n",
    "        match_session = session_pattern.match(i)\n",
    "        ## SessionDir\n",
    "        if match_session:\n",
    "            logger.info(f\"Session Begin: {i}\")\n",
    "            _sessionIndex = match_session[2]\n",
    "            for j in os.listdir(f\"{rootPath}/{i}\"):\n",
    "                match_bank = bank_pattern.match(j)\n",
    "                ## BankDir\n",
    "                if match_bank:\n",
    "                    logger.info(f\"Bank Begin: {j}\")\n",
    "                    _trackpath = f\"{rootPath}/{i}/{j}/{outsuffix}\"\n",
    "                    if not os.path.exists(_trackpath):\n",
    "                        continue\n",
    "\n",
    "                    for k in os.listdir(f\"{rootPath}/{i}/{j}/{outsuffix}\"):\n",
    "                        match_file = file_pattern.match(k)\n",
    "                        ## File\n",
    "                        if match_file:\n",
    "                            _filename = k\n",
    "                            _filepath = f\"{rootPath}/{i}/{j}/{outsuffix}/{k}\"\n",
    "                            _channelIndex = (int(match_bank[1])-1)*32+int(match_file[1])\n",
    "                            \n",
    "                            EISDict[_sessionIndex][_channelIndex] = f\"{rootPath}/{i}/{j}/{outsuffix}/{k}\"\n",
    "                            \n",
    "    return EISDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Readout\n",
    "def readChannel(chID, fileDict):\n",
    "    '''==================================================\n",
    "        Read EIS.csv file by Channel\n",
    "        Parameter: \n",
    "            chID: channel index\n",
    "            fileDict: EISDict[_sessionIndex][_channelIndex] = \"_filepath\"\n",
    "        Returen:\n",
    "            freq: frequency\n",
    "            Zreal: real part of impedance\n",
    "            Zimag: imaginary part of impedance\n",
    "        ==================================================\n",
    "    '''\n",
    "    chData = []\n",
    "    for ssID in fileDict.keys():\n",
    "        _data   = np.loadtxt(fileDict[ssID][chID], delimiter=',')\n",
    "        _freq   = _data[:,0]\n",
    "        _Zreal  = _data[:,1] * np.cos(np.deg2rad(_data[:,2])) \n",
    "        _Zimag  = _data[:,1] * np.sin(np.deg2rad(_data[:,2])) \n",
    "        chData.append(np.stack((_freq, _Zreal, _Zimag),axis=0))\n",
    "\n",
    "    return np.stack(chData, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def EIS_recal_ver02(data, _phz_0 = None):\n",
    "    f_poi = data[0,:]\n",
    "    # Z_poi = data[1,:] * np.exp(1j*np.deg2rad(data[2,:]))\n",
    "    Z_poi = data[1,:] + 1j*data[2,:]\n",
    "    Y_poi = 1/Z_poi\n",
    "\n",
    "    Rg0 = 1.611e13\n",
    "    Cp0 = 1.4e-9\n",
    "    \n",
    "    _Rg0_rescale = 1/Rg0*np.power(f_poi,1.583)\n",
    "    _Cp0_rescale = Cp0*np.power(f_poi,0.911)\n",
    "    Y_org = Y_poi - _Rg0_rescale + 1j*_Cp0_rescale\n",
    "    # Y_org = Y_poi - _Rg0_rescale \n",
    "    # Y_org = Y_poi + 1j*_Cp0_rescale\n",
    "    # Y_org = Y_poi\n",
    "    Z_org = 1/Y_org\n",
    "\n",
    "    # Phz Calibration\n",
    "    if _phz_0 is None:\n",
    "        _phz_0 = np.loadtxt(\"./phz_Calib.txt\")\n",
    "    \n",
    "    Z_ampC = np.abs(Z_org)\n",
    "    # Z_phzC = np.angle(Z_org) - _phz_0\n",
    "    Z_phzC = np.angle(Z_org) - _phz_0\n",
    "\n",
    "    Z_rec = Z_ampC * np.exp(1j*Z_phzC)\n",
    "\n",
    "    # C = 5e-10\n",
    "    Rs0 = 100\n",
    "    Z_rec = Z_rec - Rs0\n",
    "\n",
    "\n",
    "\n",
    "    Cp0 = 5e-10\n",
    "    _Cp0_rescale = Cp0 * f_poi\n",
    "    Z_rec = 1/(1/Z_rec - 1j * _Cp0_rescale)\n",
    "\n",
    "    \n",
    "\n",
    "    # Ls0 = 1.7e-4\n",
    "    Ls0 = 5e-4\n",
    "    _Ls0_rescale = Ls0 * f_poi\n",
    "    Z_rec = Z_rec - 1j * _Ls0_rescale\n",
    "\n",
    "    # C = 5e-10\n",
    "    Rs0 = 566\n",
    "    Z_rec = Z_rec - Rs0\n",
    "    \n",
    "    return np.stack([f_poi, np.real(Z_rec), np.imag(Z_rec)], axis=1).T\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 20:00:34.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241022_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241024_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241028_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241029_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241030_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241031_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241101_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241103_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241104_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241105_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241106_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241107_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mSession Begin: 09290511_20241109_01\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 1\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 2\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 3\u001b[0m\n",
      "\u001b[32m2025-04-03 20:00:34.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgatherCSV\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mBank Begin: 4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 3, 101)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rootPath = \"D:/Baihm/EISNN/Dataset/01037160_归档\"\n",
    "# ch_id = 20  # Normal to Short, Same to GPR  \n",
    "# ch_id = 89  # Same to GPR  \n",
    "# ch_id = 7  # Normal Example\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Dataset/05087163_归档\"\n",
    "# ch_id = 7   # one outlier\n",
    "# ch_id = 50  # No outlier but in two Phases\n",
    "# ch_id = 55  # One outlier &wired end point\n",
    "# ch_id = 114 # Open Circuit with on outpler\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/02067447_归档\"\n",
    "# ch_id = 68  # Short all the time\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/01067095_归档\"\n",
    "# ch_id = 19    # First Sample is outlier\n",
    "\n",
    "rootPath = \"D:/Baihm/EISNN/Archive/09290511_归档\"\n",
    "ch_id = 13    # Up & Down, 3 outliers\n",
    "# ch_id = 21    # Normal + 2 outlier\n",
    "# ch_id = 41    # Normal + 2 outlier - *(Hard To Tell)\n",
    "# ch_id = 79    # 3-class, What a mess\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/11057712_归档\"\n",
    "# ch_id = 106    # Very Good Electrode with 1 hidden outlier, and one phase shift\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/10057084_归档\"\n",
    "# ch_id = 16    # Totaly Mess\n",
    "# ch_id = 18    # Totaly Mess\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/11067223_归档\"\n",
    "# ch_id = 124     # Perfect with one outlier\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/06017758_归档\"\n",
    "# ch_id = 96     # Perfect of Perfect\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/15361101_归档\"\n",
    "# ch_id = 0     # Only One Sample - Run With Error\n",
    "\n",
    "\n",
    "# rootPath = \"D:\\Baihm\\EISNN\\Archive/11207147_归档\"\n",
    "# ch_id = 0     # Only Three Sample - Run With Error\n",
    "\n",
    "# freq_list = np.linspace(0,np.shape(chData)[2]-1,101,dtype=int)\n",
    "freq_list = np.linspace(0,5000-1,101,dtype=int, endpoint=True)\n",
    "EISDict = gatherCSV(rootPath)\n",
    "chData = readChannel(ch_id, EISDict)\n",
    "\n",
    "if True:\n",
    "    phz_calibration = np.loadtxt(\"./phz_Calib.txt\")\n",
    "    for i in range(np.shape(chData)[0]):\n",
    "        ch_eis = EIS_recal_ver02(chData[i,:,:], phz_calibration)\n",
    "        chData[i,:,:] = ch_eis\n",
    "chData = chData[:,:,freq_list]\n",
    "\n",
    "# chData = chData[:,:,91:100]\n",
    "\n",
    "\n",
    "np.shape(chData)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from  Outlier import OutlierDetection\n",
    "\n",
    "CLEAN_FLAG = True\n",
    "if CLEAN_FLAG:\n",
    "    eis_seq, eis_cluster, eis_anomaly, leaf_anomaly = OutlierDetection.OutlierDetection(chData)\n",
    "else: \n",
    "    eis_seq = np.arange(np.shape(chData)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    fig, axis = plt.subplots(1,4,figsize=(15,6))\n",
    "    cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "    for i in range(np.shape(chData)[0]):\n",
    "    # for i in [1]:\n",
    "        ch_eis = chData[i,:,:]\n",
    "        # ch_eis = EIS_recal(chData[i,:,:].T).T\n",
    "        # ch_eis = EIS_recal_ver02(chData[i,:,:], phz_calibration)\n",
    "        _color = cmap(i/np.shape(chData)[0])\n",
    "        axis[0].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[1].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[2].plot(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        # axis[4].loglog(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    \n",
    "        # _poi_Z = np.log(np.abs(ch_eis[1,:]+1j*ch_eis[2,:]))\n",
    "        # _poi_P = np.angle(ch_eis[1,:]+1j*ch_eis[2,:])\n",
    "        # _poi_eis = _poi_Z * np.exp(1j*_poi_P)\n",
    "        # axis[3].plot(np.real(_poi_eis), -np.imag(_poi_eis), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        _poi_Z = np.log(ch_eis[1,:]+1j*ch_eis[2,:])\n",
    "        axis[3].plot(np.real(_poi_Z), -np.imag(_poi_Z), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        \n",
    "\n",
    "# axis[0].legend(frameon=False, loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(15,8), constrained_layout=False)\n",
    "axis = [0] * 8\n",
    "axis[0] = fig.add_subplot(2,4,1, projection='3d')   \n",
    "axis[1] = fig.add_subplot(2,4,2)            \n",
    "axis[2] = fig.add_subplot(2,4,3)         \n",
    "axis[3] = fig.add_subplot(2,4,4)      \n",
    "axis[4] = fig.add_subplot(2,4,5, projection='3d')      \n",
    "axis[5] = fig.add_subplot(2,4,6)         \n",
    "axis[6] = fig.add_subplot(2,4,7)         \n",
    "axis[7] = fig.add_subplot(2,4,8)    \n",
    "\n",
    "init_elev = 21  # 仰角\n",
    "init_azim = 55  # 方位角\n",
    "axis[0].view_init(elev=init_elev, azim=init_azim)\n",
    "axis[4].view_init(elev=init_elev, azim=init_azim)\n",
    "\n",
    "\n",
    "num_samples = np.shape(chData)[0]\n",
    "\n",
    "_x = np.arange(num_samples)[eis_seq]\n",
    "_y = np.log10(chData[0,0,:]).flatten()\n",
    "X, Y = np.meshgrid(_x, _y, indexing='ij')\n",
    "axis[0].plot_surface(X, Y, np.log10(np.abs(chData[eis_seq,1,:]+1j*chData[eis_seq,2,:])), cmap='viridis_r', alpha=0.8)\n",
    "axis[4].plot_surface(X, Y, np.rad2deg(np.angle(chData[eis_seq,1,:]+1j*chData[eis_seq,2,:])), cmap='viridis_r', alpha=0.8)\n",
    "\n",
    "\n",
    "\n",
    "cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "for i in range(len(eis_seq)):\n",
    "    _x = eis_seq[i]\n",
    "    ch_eis = chData[_x,:,:]\n",
    "    _color = cmap(_x/num_samples)\n",
    "    axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"S{i:02d}\")\n",
    "    axis[5].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"S{i:02d}\")\n",
    "\n",
    "\n",
    "cmap = plt.colormaps.get_cmap('Set1')\n",
    "for i in range(len(eis_seq)):\n",
    "    _x = eis_seq[i]\n",
    "    ch_eis = chData[_x,:,:]\n",
    "    _color = cmap(eis_cluster[i])\n",
    "    axis[2].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"{chr(ord('A')+eis_cluster[i])}\")\n",
    "    axis[6].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"{chr(ord('A')+eis_cluster[i])}\")\n",
    "\n",
    "_legend_handle = []\n",
    "for i in range(len(np.unique(eis_cluster))):\n",
    "    _legend_handle.append(mpatches.Patch(color = cmap(i), label = f\"{chr(ord('A')+i)}:{len(eis_cluster[eis_cluster==i])}\"))\n",
    "axis[2].legend(handles=_legend_handle)\n",
    "\n",
    "axis[2].sharex(axis[1])\n",
    "axis[6].sharex(axis[5])\n",
    "\n",
    "\n",
    "cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "for i in range(len(eis_anomaly)):\n",
    "    _x = eis_anomaly[i]\n",
    "    ch_eis = chData[_x,:,:]\n",
    "    _color = cmap(_x/num_samples)\n",
    "    axis[3].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"S{_x:02d}\")\n",
    "    axis[7].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"S{_x:02d}\")\n",
    "axis[3].legend()\n",
    "axis[3].sharex(axis[1])\n",
    "axis[7].sharex(axis[5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(chData, eis_seq, eis_cluster, SPEED_RATE = 1):\n",
    "    # Speed Rate = 10 means 1 day = 10 points\n",
    "    x_day = [datetime.strptime(date, '%Y%m%d') for date in EISDict.keys()]\n",
    "    x_day = [x_day[i] for i in eis_seq]\n",
    "\n",
    "    x_train = np.array([(poi - x_day[0]).days for poi in x_day])\n",
    "    x_eval = np.linspace(0,max(x_train),max(x_train)*SPEED_RATE+1)\n",
    "\n",
    "    # chData_log = np.log(chData[eis_seq,1,:] + 1j*chData[eis_seq,2,:])\n",
    "    # y_train = np.stack([chData_log.real.T,chData_log.imag.T], axis=2)\n",
    "    chData_lin = chData[eis_seq,1,:] + 1j*chData[eis_seq,2,:]\n",
    "    y_train = np.stack([chData_lin.real.T,chData_lin.imag.T], axis=2)\n",
    "\n",
    "\n",
    "    logger.info(f\"\\nx: {np.shape(x_train)} \\ny: {np.shape(y_train)} \\nx_pred{np.shape(x_eval)}\")\n",
    "\n",
    "    return x_train, y_train, x_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "def weighted_piecewise_interp(x, y, x_new, states = None):\n",
    "    if states is None:\n",
    "        states = np.zeros_like(x)\n",
    "    unique_states = np.unique(states)\n",
    "    y_new = np.zeros((np.shape(x_new)[0], np.shape(y)[1]))\n",
    "\n",
    "    for i in range(len(unique_states) - 1):\n",
    "        # 取当前状态和下一个状态的数据\n",
    "        state_mask = (states == unique_states[i])\n",
    "        next_state_mask = (states == unique_states[i + 1])\n",
    "        \n",
    "        x_state = x[state_mask]\n",
    "        y_state = y[state_mask]\n",
    "        x_next_state = x[next_state_mask]\n",
    "        y_next_state = y[next_state_mask]\n",
    "        # 计算当前 state 的插值\n",
    "        cs = CubicSpline(x_state, y_state, bc_type='clamped')\n",
    "\n",
    "        # 对新插值点进行计算\n",
    "        mask_new = (x_new >= x_state.min()) & (x_new <= x_state.max())\n",
    "        y_new[mask_new] = cs(x_new[mask_new])\n",
    "\n",
    "        # 处理状态之间的插值\n",
    "        trans_mask = (x_new > x_state.max()) & (x_new < x_next_state.min())\n",
    "        if np.any(trans_mask):\n",
    "            # 计算过渡区的线性权重\n",
    "            alpha = (x_new[trans_mask] - x_state.max()) / (x_next_state.min() - x_state.max())\n",
    "            y_new[trans_mask] = (1 - alpha) * cs(x_state.max()) + alpha * y_next_state[0]\n",
    "\n",
    "    return y_new\n",
    "\n",
    "# # 示例数据\n",
    "# x_train = np.array([0, 1, 2, 4, 5, 7, 8, 10])\n",
    "# x_eval = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# # 计算 y_train，其中每一列代表一个不同的相位（phi）\n",
    "# # phis = np.array([0, np.pi/6, np.pi/3, np.pi/2])\n",
    "# phis = np.array([np.pi * i/8 for i in range(8)])\n",
    "# y_train = np.array([[np.sin(2 * np.pi * (x / 10) + phi) for phi in phis] for x in x_train])\n",
    "\n",
    "# y_train[5:] = y_train[5:]/3\n",
    "\n",
    "# # 初始化 y_eval，形状为 (len(x_eval), len(phis))\n",
    "# y_eval = np.zeros((len(x_eval), len(phis)))\n",
    "\n",
    "# cs = CubicSpline(x_train, y_train, bc_type='natural')\n",
    "# y_eval = cs(x_eval)\n",
    "\n",
    "# fig = plt.figure(figsize=(8,8))\n",
    "# axis1 = fig.add_subplot(1,1,1, projection = '3d')\n",
    "\n",
    "# _x = np.arange(np.shape(x_eval)[0])\n",
    "# _y = np.arange(np.shape(phis)[0])\n",
    "# X, Y = np.meshgrid(_x, _y, indexing='ij')\n",
    "# axis1.plot_surface(X, Y, y_eval, cmap='viridis_r', alpha=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 20:36:29.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mDataLoader\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1m\n",
      "x: (11,) \n",
      "y: (101, 11, 2) \n",
      "x_pred(19,)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # not-a-knot\n",
    "    # clamped\n",
    "    x_train, y_train, x_eval = DataLoader(chData, eis_seq, eis_cluster, SPEED_RATE=1)\n",
    "    y_real_cs = CubicSpline(x_train, y_train[:,:,0].T, bc_type='not-a-knot')\n",
    "    y_imag_cs = CubicSpline(x_train, y_train[:,:,1].T, bc_type='not-a-knot')\n",
    "    y_eval = np.stack((y_real_cs(x_eval).T, y_imag_cs(x_eval).T), axis=2)\n",
    "    y_EIS = y_eval[:,:,0] + 1j*y_eval[:,:,1]\n",
    "    y_org = y_train[:,:,0] + 1j*y_train[:,:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weighted_piecewise_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train, x_eval = DataLoader(chData, eis_seq, eis_cluster, SPEED_RATE=1)\n",
    "# y_eval_real = weighted_piecewise_interp(x_train, y_train[:,:,0].T, x_eval, eis_cluster).T\n",
    "# y_eval_imag = weighted_piecewise_interp(x_train, y_train[:,:,1].T, x_eval, eis_cluster).T\n",
    "# y_eval = np.stack((y_eval_real, y_eval_imag),axis=2)\n",
    "# y_EIS = y_eval[:,:,0] + 1j*y_eval[:,:,1]\n",
    "# y_org = y_train[:,:,0] + 1j*y_train[:,:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 19, 2)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(15,8), constrained_layout=False)\n",
    "axis = [0] * 8\n",
    "axis[0] = fig.add_subplot(2,3,1, projection='3d')   \n",
    "axis[1] = fig.add_subplot(2,3,2)            \n",
    "axis[2] = fig.add_subplot(2,3,3)      \n",
    "axis[3] = fig.add_subplot(2,3,4, projection='3d')      \n",
    "axis[4] = fig.add_subplot(2,3,5)         \n",
    "axis[5] = fig.add_subplot(2,3,6)    \n",
    "\n",
    "init_elev = 21  # 仰角\n",
    "init_azim = 55  # 方位角\n",
    "axis[0].view_init(elev=init_elev, azim=init_azim)\n",
    "axis[3].view_init(elev=init_elev, azim=init_azim)\n",
    "\n",
    "\n",
    "\n",
    "_y = np.arange(np.shape(x_eval)[0])\n",
    "_x = np.log10(chData[0,0,:]).flatten()\n",
    "X, Y = np.meshgrid(_x, _y, indexing='ij')\n",
    "axis[0].plot_surface(X, Y, np.log10(np.abs(y_EIS)), cmap='viridis_r', alpha=0.8)\n",
    "axis[3].plot_surface(X, Y, np.rad2deg(np.angle(y_EIS)), cmap='viridis_r', alpha=0.8)\n",
    "\n",
    "\n",
    "cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "for i in range(np.shape(y_EIS)[1]):\n",
    "    _color = cmap(i/np.shape(x_eval)[0])\n",
    "    axis[1].loglog(ch_eis[0,:], np.abs(y_EIS[:,i]), color = _color, linewidth=2, label=f\"S{i:02d}\")\n",
    "    axis[4].semilogx(ch_eis[0,:], np.rad2deg(np.angle(y_EIS[:,i])), color = _color, linewidth=2, label=f\"S{i:02d}\")\n",
    "\n",
    "\n",
    "# cmap = plt.colormaps.get_cmap('viridis_r')\n",
    "# for i in range(np.shape(y_EIS)[0]):\n",
    "#     _color = cmap(i/np.shape(x_eval)[0])\n",
    "#     axis[2].plot(x_eval, np.abs(y_EIS[i,:]), color = _color, linewidth=2, label=f\"S{i:03d}\")\n",
    "#     axis[2].plot(x_train, np.abs(y_org[i,:]), 'r.')\n",
    "#     axis[5].plot(x_eval, np.rad2deg(np.angle(y_EIS[i,:])), color = _color, linewidth=2, label=f\"S{i:03d}\")\n",
    "#     axis[5].plot(x_train, np.rad2deg(np.angle(y_org[i,:])), 'r.')\n",
    "# axis[5].set_ylim([-90,20])\n",
    "\n",
    "cmap = plt.colormaps.get_cmap('viridis_r')\n",
    "for i in range(np.shape(y_EIS)[0]):\n",
    "# for i in range(40,50):\n",
    "    _color = cmap(i/np.shape(x_eval)[0])\n",
    "    axis[2].semilogy(x_eval, np.real(y_EIS[i,:]), color = _color, linewidth=2, label=f\"S{i:03d}\")\n",
    "    axis[2].semilogy(x_train, np.real(y_org[i,:]), 'r.')\n",
    "    axis[5].semilogy(x_eval, -np.imag(y_EIS[i,:]), color = _color, linewidth=2, label=f\"S{i:03d}\")\n",
    "    axis[5].semilogy(x_train, -np.imag(y_org[i,:]), 'r.')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
