{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b6526a",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b41be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from HETSFileHelper import gatherCSV, readChannel, EIS_recal_ver02\n",
    "from Outlier import OutlierDetection\n",
    "from EISGPR import Interpolation\n",
    "\n",
    "\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f00da0",
   "metadata": {},
   "source": [
    "# Filesys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89136f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchELE(rootPath, ele_pattern = re.compile(r\"(.+?)_归档\")):\n",
    "    '''==================================================\n",
    "        Search all electrode directories in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            ele_pattern: electrode dir name patten\n",
    "        Returen:\n",
    "            ele_list: list of electrode directories\n",
    "        ==================================================\n",
    "    '''\n",
    "    ele_list = []\n",
    "    for i in os.listdir(rootPath):\n",
    "        match_ele = ele_pattern.match(i)\n",
    "        if match_ele:\n",
    "            ele_list.append([os.path.join(rootPath, i),match_ele.group(1)])\n",
    "    return ele_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a277ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-11 11:34:15.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mSearch in D:/Baihm/EISNN/Invivo/ and find 005 electrodes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# rootPath = \"D:/Baihm/EISNN/Archive/\"\n",
    "# ele_list = SearchELE(rootPath)\n",
    "\n",
    "rootPath = \"D:/Baihm/EISNN/Invivo/\"\n",
    "ele_list = SearchELE(rootPath, re.compile(r\"(.+?)_Ver01\"))\n",
    "\n",
    "n_ele = len(ele_list)\n",
    "logger.info(f\"Search in {rootPath} and find {n_ele:03d} electrodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d4da2",
   "metadata": {},
   "source": [
    "# Error Processed Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876e586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\1\\ipykernel_2212\\2298384240.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_pt = torch.load(fd_pt)\n",
      "\u001b[32m2025-04-11 11:34:16.070\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[33m\u001b[1mS5877[000]: 58/128 [8]\u001b[0m\n",
      "\u001b[32m2025-04-11 11:34:16.101\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[33m\u001b[1mS6005[001]: 21/128 [9]\u001b[0m\n",
      "\u001b[32m2025-04-11 11:34:16.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mS6006[002]: 127/128 [11]\u001b[0m\n",
      "\u001b[32m2025-04-11 11:34:16.609\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mS6072[003]: 126/128 [9]\u001b[0m\n",
      "\u001b[32m2025-04-11 11:34:16.772\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mS6106[004]: 126/128 [9]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 我们观察到，由于我们在最后聚类的时候使用了AP + silhouette_score\n",
    "# 而silhouette_score 对最低样本数有要求\n",
    "# 这使得我们会遇到大量报错，之前用try exception跳过了，但是这个可能会导致我们把正常电极误判\n",
    "# 这里我们打印每个pt文件中，有效电极数和追踪天数\n",
    "# 如果有效电极数 < 128 - 10 且追踪天数比较多，就认为有问题\n",
    "\n",
    "MODEL_SUFFIX = \"Matern12_Ver01\"\n",
    "\n",
    "n_miss = 0\n",
    "n_perfect = 0\n",
    "n_good = 0\n",
    "n_bad = 0\n",
    "n_terrible = 0\n",
    "n_error = 0\n",
    "\n",
    "n_perfect_ch  = 0\n",
    "n_good_ch = 0\n",
    "n_bad_ch = 0\n",
    "n_terrible_ch = 0\n",
    "n_error_ch = 0\n",
    "\n",
    "n_eval_day_sum = 0\n",
    "n_eval_times_sum = 0\n",
    "\n",
    "for i in range(n_ele):\n",
    "# for i in range(3):\n",
    "    # logger.info(f\"ELE Begin: {ele_list[i][0]}\")\n",
    "    fd_pt = os.path.join(ele_list[i][0], MODEL_SUFFIX, f\"{ele_list[i][1]}_{MODEL_SUFFIX}.pt\")\n",
    "    if not os.path.exists(fd_pt):\n",
    "        n_miss = n_miss + 1\n",
    "        logger.warning(f\"{fd_pt} does not exist\")\n",
    "        continue\n",
    "    data_pt = torch.load(fd_pt)\n",
    "    _meta_group = data_pt[\"meta_group\"]\n",
    "    _data_group = data_pt[\"data_group\"]\n",
    "\n",
    "    n_day       = _meta_group[\"n_day\"]\n",
    "    n_ch        = _meta_group[\"n_ch\"]\n",
    "    n_valid_ch  = len(_data_group[\"Channels\"])\n",
    "\n",
    "    # n_eval_day = _data_group['ch_000']['x_eval'].max()\n",
    "    # print(n_eval_day)\n",
    "\n",
    "    if n_ch != 128:\n",
    "        n_error = n_error + 1\n",
    "        logger.critical(f\"{ele_list[i][1]}[{i:03d}]: {n_valid_ch}/{n_ch} [{n_day}]\")\n",
    "    elif n_valid_ch != n_ch:\n",
    "        if n_day > 4 and n_valid_ch>100:\n",
    "            n_good = n_good + 1\n",
    "            n_good_ch = n_good_ch + n_valid_ch\n",
    "            n_eval_day_sum = n_eval_day_sum + _data_group[_data_group[\"Channels\"][0]]['x_eval'].max() * n_valid_ch\n",
    "            n_eval_times_sum = n_eval_times_sum + n_day * n_valid_ch\n",
    "\n",
    "\n",
    "            logger.debug(f\"{ele_list[i][1]}[{i:03d}]: {n_valid_ch}/{n_ch} [{n_day}]\")\n",
    "        else:\n",
    "            if n_day > 4:\n",
    "                n_bad = n_bad + 1\n",
    "                n_bad_ch = n_bad_ch + n_valid_ch\n",
    "                logger.warning(f\"{ele_list[i][1]}[{i:03d}]: {n_valid_ch}/{n_ch} [{n_day}]\")\n",
    "            else:\n",
    "                n_terrible = n_terrible + 1\n",
    "                n_terrible_ch = n_terrible_ch + n_valid_ch\n",
    "                logger.error(f\"{ele_list[i][1]}[{i:03d}]: {n_valid_ch}/{n_ch} [{n_day}]\")\n",
    "    else:\n",
    "        n_perfect = n_perfect + 1\n",
    "        n_perfect_ch = n_perfect_ch + 128\n",
    "        n_eval_day_sum = n_eval_day_sum + _data_group[_data_group[\"Channels\"][0]]['x_eval'].max() * n_valid_ch\n",
    "        n_eval_times_sum = n_eval_times_sum + n_day * n_valid_ch\n",
    "\n",
    "        logger.info(f\"{ele_list[i][1]}[{i:03d}]: {n_valid_ch}/{n_ch} [{n_day}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e85f389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-11 11:34:16.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1m\n",
      "n_miss:0\n",
      "n_perfect:0\n",
      "n_good:3\n",
      "n_bad:2\n",
      "n_error:0\n",
      "n_terrible:0\n",
      "5\u001b[0m\n",
      "\u001b[32m2025-04-11 11:34:16.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1m\n",
      "n_perfect_ch:0\n",
      "n_good_ch:379            \n",
      "n_bad_ch:79\n",
      "n_terrible_ch:0            \n",
      "n_eval_day_sum:27077.0\n",
      "n_eval_day_avg:71.44327176781003            \n",
      "n_eval_times_sum:3665\n",
      "n_eval_times_avg:9.67018469656992            \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.info(f\"\\nn_miss:{n_miss}\\nn_perfect:{n_perfect}\\nn_good:{n_good}\\nn_bad:{n_bad}\\nn_error:{n_error}\\nn_terrible:{n_terrible}\\n{n_miss+n_perfect+n_good+n_bad+n_terrible+n_error}\")\n",
    "logger.info(f\"\\nn_perfect_ch:{n_perfect_ch}\\nn_good_ch:{n_good_ch}\\\n",
    "            \\nn_bad_ch:{n_bad_ch}\\nn_terrible_ch:{n_terrible_ch}\\\n",
    "            \\nn_eval_day_sum:{n_eval_day_sum}\\nn_eval_day_avg:{n_eval_day_sum/(n_perfect_ch+n_good_ch)}\\\n",
    "            \\nn_eval_times_sum:{n_eval_times_sum}\\nn_eval_times_avg:{n_eval_times_sum/(n_perfect_ch+n_good_ch)}\\\n",
    "            \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
