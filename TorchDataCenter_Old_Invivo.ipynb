{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HETSFileHelper import gatherCSV, readChannel, EIS_recal_ver02\n",
    "from Outlier import OutlierDetection\n",
    "from EISGPR import Interpolation\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filesys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchELE(rootPath, ele_pattern = re.compile(r\"(.+?)_归档\")):\n",
    "    '''==================================================\n",
    "        Search all electrode directories in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            ele_pattern: electrode dir name patten\n",
    "        Returen:\n",
    "            ele_list: list of electrode directories\n",
    "        ==================================================\n",
    "    '''\n",
    "    ele_list = []\n",
    "    for i in os.listdir(rootPath):\n",
    "        match_ele = ele_pattern.match(i)\n",
    "        if match_ele:\n",
    "            ele_list.append([os.path.join(rootPath, i),match_ele.group(1)])\n",
    "    return ele_list\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(log_dir=\"./LOG_invivo\", log_filename=\"file.log\", file_level=\"WARNING\", console_level=\"WARNING\"):\n",
    "    # 创建目录\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_fd = os.path.join(log_dir, log_filename)\n",
    "\n",
    "    logger.remove()\n",
    "    # 如果已有日志文件，重命名添加时间戳\n",
    "    if os.path.exists(log_fd):\n",
    "        name, ext = os.path.splitext(log_filename)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        archived_name = f\"{name}_{timestamp}{ext}\"\n",
    "        archived_path = os.path.join(log_dir, archived_name)\n",
    "        os.rename(log_fd, archived_path)\n",
    "\n",
    "    # 添加终端输出\n",
    "    logger.add(sys.stdout, level=console_level, enqueue=True)\n",
    "\n",
    "    # 添加文件输出\n",
    "    logger.add(log_fd, level=file_level, encoding=\"utf-8\", enqueue=True)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logger()\n",
    "# logger.remove()\n",
    "# logger.add(sys.stdout, level=\"WARNING\")\n",
    "# logger.add(\"./LOG/file.log\", rotation=\"10 MB\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = \"D:/Baihm/EISNN/Invivo/\"\n",
    "ele_list = SearchELE(rootPath, ele_pattern=re.compile(r\"(.+?)_Ver01\"))\n",
    "n_ele = len(ele_list)\n",
    "logger.warning(f\"Search in {rootPath} and find {n_ele:03d} electrodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each Electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list = np.linspace(0,5000-1,101,dtype=int, endpoint=True)\n",
    "freq_list_DTW = np.linspace(1000,5000-1,101,dtype=int, endpoint=True)\n",
    "\n",
    "MODEL_SUFFIX = \"Matern12_Ver01\"\n",
    "SAVE_FLAG = True\n",
    "\n",
    "# for i in range(n_ele):\n",
    "for i in range(0,1):\n",
    "    elePath = ele_list[i][0]\n",
    "    ele_id = ele_list[i][1]\n",
    "    logger.warning(f\"ELE[{i+1}/{n_ele}]: \\t{elePath}\")\n",
    "    \n",
    "\n",
    "    # Storage Preparing\n",
    "    save_dir = f\"{elePath}/{MODEL_SUFFIX}/\"\n",
    "    pt_file_name = f\"{ele_id}_{MODEL_SUFFIX}.pt\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    if os.path.exists(os.path.join(save_dir, pt_file_name)):\n",
    "        logger.warning(f\"FileAlreadyExistsWarning: {ele_id} - {pt_file_name} already exists.\")\n",
    "        if SAVE_FLAG:\n",
    "            continue\n",
    "\n",
    "\n",
    "    # Load EIS data\n",
    "    EISDict = gatherCSV(elePath)\n",
    "    n_day   = len(EISDict)\n",
    "    if n_day < 3:\n",
    "        logger.warning(f\"IllegalInputError: {ele_id} only has {n_day} samples.\")\n",
    "        continue\n",
    "    try:\n",
    "        x_day_full = [datetime.strptime(date, '%Y%m%d') for date in EISDict.keys()]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"IllegalDateError: {ele_id} has wrong date format. Please check the saving file. Error Code: {e}\")\n",
    "        continue\n",
    "\n",
    "    _key    = next(iter(EISDict))\n",
    "    n_ch    = len(EISDict[_key])\n",
    "    \n",
    "    if n_ch != 128:\n",
    "        logger.warning(f\"ChannelNumberWarning: {ele_id} only has {n_ch} channels.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # Iteration for each channel\n",
    "    data_group = {}\n",
    "    data_group['Channels']    = []\n",
    "    for j in range(n_ch):\n",
    "    # for j in [0]:\n",
    "        try:\n",
    "            # logger.warning(f\"ELE[{i+1}/{n_ele}] - ch[{j+1}/{n_ch}]\")\n",
    "            # logger.info(f\"{EISDict}\")\n",
    "            chData = readChannel(j, EISDict)\n",
    "            chData_DTW = chData[:,:,freq_list_DTW]\n",
    "            # Outlier Detection\n",
    "            eis_seq, eis_cluster, eis_anomaly, leaf_anomaly = OutlierDetection.OutlierDetection(chData_DTW)\n",
    "            if np.shape(eis_seq)[0] < 3:\n",
    "                logger.warning(f\"OutlierDetectionWarning: {ele_id} - CHID[{j}] only has {np.shape(eis_seq)[0]} valid samples.\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Interpolation\n",
    "            phz_calibration = np.loadtxt(\"./EISGPR/phz_Calib.txt\")\n",
    "            for k in range(np.shape(chData)[0]):\n",
    "                ch_eis = EIS_recal_ver02(chData[k,:,:], phz_calibration)\n",
    "                chData[k,:,:] = ch_eis\n",
    "\n",
    "            chData = chData[:,:,freq_list]\n",
    "            if np.isnan(chData).any():\n",
    "                logger.warning(f\"OutlierDetectionWarning: {ele_id} - CHID[{j}] chData Invalid\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        \n",
    "            x_train_full, y_train_full, x_eval_full, y_eval_full, y_eval_err_full, eis_cluster_eval = \\\n",
    "                Interpolation.PiecewiseGPR(x_day_full, chData, eis_seq, eis_cluster, SPEED_RATE = 2, training_iter = 200, lr = 0.05)\n",
    "\n",
    "            # Plot\n",
    "            fig = plt.figure(figsize=(16, 9), constrained_layout=True)\n",
    "            Interpolation.EISPreprocessPlot(fig, chData, x_train_full, y_train_full, x_eval_full, y_eval_full, y_eval_err_full, eis_seq, eis_cluster, eis_anomaly)\n",
    "                \n",
    "            axis = fig.add_subplot(3,4,12)\n",
    "            axis.axis('off')\n",
    "            font_properties = {\n",
    "                'family': 'monospace',  # 固定宽度字体\n",
    "                'size': 14,             # 字体大小\n",
    "                'weight': 'bold'        # 加粗\n",
    "            }\n",
    "\n",
    "            text = f\"EIE  : {ele_id}\\nCHID : {j:03d}\\nFrom : {x_day_full[0].strftime('%Y-%m-%d')}\\nTo   : {x_day_full[-1].strftime('%Y-%m-%d')}\"\n",
    "            axis.text(0.2, 0.5, text, fontdict = font_properties, ha='left', va='center')\n",
    "\n",
    "            # Save Fig\n",
    "            fig_name = f\"EISGPR_{ele_id}_ch{j:03d}.png\"\n",
    "            \n",
    "            os.makedirs(save_dir, exist_ok=True) \n",
    "            path = os.path.join(save_dir, fig_name)\n",
    "\n",
    "            fig.savefig(path)\n",
    "            plt.close(fig) \n",
    "\n",
    "            # Data Saving\n",
    "            channel_group = {}\n",
    "            channel_group['x_train']    = x_train_full\n",
    "            channel_group['y_train']    = y_train_full\n",
    "            channel_group['x_eval']     = x_eval_full\n",
    "            channel_group['y_eval']     = y_eval_full\n",
    "            channel_group['y_eval_err'] = y_eval_err_full\n",
    "            channel_group['eis_cluster_eval'] = eis_cluster_eval\n",
    "\n",
    "            data_group[f\"ch_{j:03d}\"] = channel_group\n",
    "            data_group['Channels'].append(f\"ch_{j:03d}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ELE[{i+1}/{n_ele}] - ch[{j+1}/{n_ch}] Run with error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Storage Preparing\n",
    "    pt_store = {}\n",
    "    meta_group = {}\n",
    "    meta_group[\"ele_id\"]    = ele_id\n",
    "    meta_group[\"elePath\"]   = elePath\n",
    "    meta_group[\"TimeSpan\"]  = x_day_full\n",
    "    meta_group[\"n_day\"]     = n_day\n",
    "    meta_group[\"n_ch\"]      = n_ch\n",
    "    meta_group[\"Model\"]     = MODEL_SUFFIX\n",
    "    meta_group[\"Creater\"]   = \"Ming\"\n",
    "    meta_group['Date']      = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    pt_store['meta_group'] = meta_group\n",
    "    pt_store['data_group'] = data_group\n",
    "    if SAVE_FLAG:\n",
    "        torch.save(pt_store, os.path.join(save_dir, pt_file_name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    pt_name = \"D:\\Baihm\\EISNN\\Archive/01037160_归档\\Matern12_Ver01/01037160_Matern12_Ver01.pt\"\n",
    "    loaded = torch.load(pt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MODEL_SUFFIX = \"Matern12_Ver01\"\n",
    "\n",
    "# all_data_list = []\n",
    "\n",
    "# for i in range(n_ele):\n",
    "# # for i in range(3):\n",
    "#     fd_pt = os.path.join(ele_list[i][0], MODEL_SUFFIX, f\"{ele_list[i][1]}_{MODEL_SUFFIX}.pt\")\n",
    "#     if not os.path.exists(fd_pt):\n",
    "#         # logger.warning(f\"{fd_pt} does not exist\")\n",
    "#         continue\n",
    "#     data_pt = torch.load(fd_pt, weights_only=False)\n",
    "#     _meta_group = data_pt[\"meta_group\"]\n",
    "#     _data_group = data_pt[\"data_group\"]\n",
    "\n",
    "#     n_day       = _meta_group[\"n_day\"]\n",
    "#     n_ch        = _meta_group[\"n_ch\"]\n",
    "#     n_valid_ch  = len(_data_group[\"Channels\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
