{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from cvxopt import matrix, solvers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import re\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib qt\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import pyDRTtools as drt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchELE(rootPath, ele_pattern = re.compile(r\"(.+?)_归档\")):\n",
    "    '''==================================================\n",
    "        Search all electrode directories in the rootPath\n",
    "        Parameter: \n",
    "            rootPath: current search path\n",
    "            ele_pattern: electrode dir name patten\n",
    "        Returen:\n",
    "            ele_list: list of electrode directories\n",
    "        ==================================================\n",
    "    '''\n",
    "    ele_list = []\n",
    "    for i in os.listdir(rootPath):\n",
    "        _path = os.path.join(rootPath, i)\n",
    "        if os.path.isdir(_path):\n",
    "            match_ele = ele_pattern.match(i)\n",
    "            if match_ele:\n",
    "                ele_list.append([_path, match_ele.group(1)])\n",
    "            else:\n",
    "                ele_list.extend(SearchELE(_path, ele_pattern))\n",
    "\n",
    "    return ele_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = \"D:/Baihm/EISNN/Archive/\"\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive_New/\"\n",
    "ele_list = SearchELE(rootPath)\n",
    "n_ele = len(ele_list)\n",
    "logger.info(f\"Search in {rootPath} and find {n_ele:03d} electrodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先我们把128/128看似完全没问题的这部分电极拿出来做聚类看看\n",
    "# 数据量也比较小，跑起来应该会更快\n",
    "\n",
    "DATASET_SUFFIX = \"Outlier_Ver03\"\n",
    "\n",
    "almost_start_list = []\n",
    "almost_start_id_list = []\n",
    "almost_data_list = []\n",
    "almost_id_list = []\n",
    "\n",
    "n_avaliable = 0\n",
    "\n",
    "for i in range(n_ele):\n",
    "# for i in range(3):\n",
    "    fd_pt = os.path.join(ele_list[i][0], DATASET_SUFFIX, f\"{ele_list[i][1]}_{DATASET_SUFFIX}.pt\")\n",
    "    if not os.path.exists(fd_pt):\n",
    "        # logger.warning(f\"{fd_pt} does not exist\")\n",
    "        continue\n",
    "    data_pt = torch.load(fd_pt, weights_only=False)\n",
    "    _meta_group = data_pt[\"meta_group\"]\n",
    "    _data_group = data_pt[\"data_group\"]\n",
    "\n",
    "    n_day       = _meta_group[\"n_day\"]\n",
    "    n_ch        = _meta_group[\"n_ch\"]\n",
    "    n_valid_ch  = len(_data_group[\"Channels\"])\n",
    "\n",
    "\n",
    "    logger.info(f\"ELE [{i}/{n_ele}]: {ele_list[i][0]}\")\n",
    "\n",
    "    n_avaliable = n_avaliable + 1\n",
    "\n",
    "    # Iteration by channel\n",
    "    for j in _data_group['Channels']:\n",
    "        _ch_data = _data_group[j][\"chData\"]\n",
    "        _ch_data_log = np.log(_ch_data[:,1,:] + 1j*_ch_data[:,2,:])\n",
    "        _ch_data[:,1,:] = np.real(_ch_data_log)\n",
    "        _ch_data[:,2,:] = np.imag(_ch_data_log)\n",
    "        _ch_data = np.hstack((_ch_data[:,1,:],_ch_data[:,2,:]))\n",
    "        almost_data_list.append(_ch_data)\n",
    "        almost_start_list.append(_ch_data[0,:])\n",
    "\n",
    "\n",
    "        _ch_id = j\n",
    "\n",
    "        _id = [i, _ch_id] * np.shape(_ch_data)[0]\n",
    "        _id = np.array(_id).reshape(-1,2)\n",
    "        almost_id_list.append(_id)\n",
    "        almost_start_id_list.append(_id[0,:])\n",
    "\n",
    "almost_data_list = np.vstack(almost_data_list)\n",
    "almost_id_list = np.vstack(almost_id_list)\n",
    "almost_start_list = np.vstack(almost_start_list)\n",
    "almost_start_id_list = np.vstack(almost_start_id_list)\n",
    "\n",
    "logger.info(f\"Total {almost_data_list.shape[0]} data points from {n_avaliable} electrodes\")\n",
    "\n",
    "del data_pt, _meta_group, _data_group, _ch_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRT Pipeline - Full Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRT(ch_eis, RLC_Flag=[True, True, True], custom_lambda = None):\n",
    "    '''==================================================\n",
    "        DRT Calculation for EIS Data\n",
    "        Parameter: \n",
    "            ch_eis: 3 x n_freq Matrix: [freq, Real, Imag]\n",
    "        Returen:\n",
    "            tau_vec: time domain vector\n",
    "            x: DRT result\n",
    "            n_extend: number of extend RLC parameters\n",
    "        ==================================================\n",
    "    '''\n",
    "    ## Freq domain data prepare\n",
    "    n_freq = ch_eis.shape[1]\n",
    "    freq_vec = np.flip(ch_eis[0,:])     # Flip for growing tau = 1/freq\n",
    "    Z_exp = np.flip(ch_eis[1,:] + 1j*ch_eis[2,:])\n",
    "    '''Hyper Parameters'''\n",
    "    # Time domain parameters\n",
    "    tau_min = 1/freq_vec[0]\n",
    "    tau_max = 1/freq_vec[-1]\n",
    "    n_tau = n_freq\n",
    "    tau_vec = 1/(2*np.pi*freq_vec)\n",
    "    # tau_vec = 1/(2*np.pi*100*freq_vec)\n",
    "    # tau_vec = np.logspace(-10, 2, n_tau, endpoint=True)\n",
    "\n",
    "    # log_tau = np.log(tau_vec)\n",
    "    # tau_vec = np.logspace(-6, 0, n_tau, endpoint=True)\n",
    "    # freq_vec = np.flip(np.logspace(0, 6, n_freq, endpoint=True))\n",
    "    \n",
    "\n",
    "\n",
    "    # Discretization matrices Parameters\n",
    "    # Use RBF Kernel to initialize the A matrix\n",
    "    RBF_shape_control = 'FWHM Coefficient' \n",
    "    RBF_coeff = 0.5\n",
    "    # RBF_type = 'Piecewise Linear'\n",
    "    RBF_type = 'Gaussian'\n",
    "    # RBF_type = 'C0 Matern'\n",
    "    # RBF_type = 'C2 Matern'\n",
    "    # RBF_type = 'C4 Matern'\n",
    "    # RBF_type = 'C6 Matern'\n",
    "    # RBF_type = 'Inverse Quadratic'\n",
    "\n",
    "    # Cross-validation Method for optimize lambda (Tikhonov regularization parameter) \n",
    "    # cv_type = 'GCV'     # Generalized Cross Validation\n",
    "    # cv_type = 'mGCV'    # Modified Generalized Cross Validation\n",
    "    cv_type = 'rGCV'    # Robust Generalized Cross Validation\n",
    "    # cv_type = 'LC'      # L-curve\n",
    "    # cv_type = 're-im'   # Real-Imaginary discrepancy\n",
    "    # cv_type = 'kf'      # k-fold cross-validation\n",
    "\n",
    "    '''Compute the RBF Shape Parameter Epsilon'''\n",
    "    epsilon = drt.basics.compute_epsilon(freq_vec, RBF_coeff, RBF_type, RBF_shape_control)\n",
    "\n",
    "    # logger.info(f\"{epsilon}\")\n",
    "    # return\n",
    "    '''Compute the discretization matrices'''\n",
    "    A_re = drt.basics.assemble_A_re(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    n_extend = np.sum(RLC_Flag)   \n",
    "    if RLC_Flag[2]:\n",
    "        A_re_C_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_C_0, A_re)) \n",
    "    if RLC_Flag[1]:\n",
    "        A_re_L_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_L_0, A_re))\n",
    "    if RLC_Flag[0]:\n",
    "        A_re_R_inf  = np.ones((n_freq, 1))\n",
    "        A_re        = np.hstack((A_re_R_inf, A_re))  \n",
    "\n",
    "    A_im = drt.basics.assemble_A_im(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    if RLC_Flag[2]:\n",
    "        A_im_C_0    = -1/(2*np.pi*freq_vec.reshape(-1,1))\n",
    "        A_im        = np.hstack((A_im_C_0, A_im))\n",
    "    if RLC_Flag[1]:\n",
    "        A_im_L_0    = 2*np.pi*freq_vec.reshape(-1,1)\n",
    "        A_im        = np.hstack((A_im_L_0, A_im))\n",
    "    if RLC_Flag[0]:\n",
    "        A_im_R_inf  = np.zeros((n_freq, 1)) \n",
    "        A_im        = np.hstack((A_im_R_inf, A_im))\n",
    "\n",
    "    A = np.vstack((A_re, A_im))\n",
    "\n",
    "\n",
    "    '''Compute the differentiation matrices for Tiknonov regularization'''\n",
    "    M2 = np.zeros((n_tau+n_extend, n_tau+n_extend))\n",
    "    M2[n_extend:,n_extend:] = drt.basics.assemble_M_2(tau_vec, epsilon, RBF_type)\n",
    "\n",
    "    '''Optimize lambda'''\n",
    "    if custom_lambda is None:\n",
    "        log_lambda_init = -7 # ln(lambda_init = 0.001)\n",
    "        lambda_opt = drt.basics.optimal_lambda(A_re, A_im, np.real(Z_exp), np.imag(Z_exp), M2, \"Combined Re-Im Data\", RLC_Flag[1], log_lambda_init, cv_type)\n",
    "    else: \n",
    "        lambda_opt = custom_lambda\n",
    "    logger.info(f\"Lambda: {lambda_opt}\")\n",
    "    '''Deconvolve The DRT from the EIS Data'''\n",
    "    # Set Bound Constraints\n",
    "    # lb = np.zeros([n_tau+n_extend])\n",
    "    # bound_mat = np.eye(lb.shape[0])\n",
    "    H_combined, c_combined = drt.basics.quad_format_combined(A_re, A_im, np.real(Z_exp), np.imag(Z_exp), M2, lambda_opt)\n",
    "    G = matrix(-np.identity(Z_exp.shape[0]+n_extend))\n",
    "    h = matrix(np.zeros(Z_exp.shape[0]+n_extend))\n",
    "    sol = solvers.qp(matrix(H_combined), matrix(c_combined), G, h)\n",
    "    \n",
    "\n",
    "    # logger.info(f\"H:{np.linalg.matrix_rank(H_combined)}, G:{np.linalg.matrix_rank(G)}\")\n",
    "    # logger.info(f\"H_combined: {H_combined},c_combined: {c_combined}\")\n",
    "    # Deconvolved DRT\n",
    "    x = np.array(sol['x'])\n",
    "    # R_inf_DRT, L_0_DRT, C_0_DRT, DRT = x[0], x[1], x[n_extend:]\n",
    "    \n",
    "    return [tau_vec, x, n_extend, lambda_opt]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %skip\n",
    "\n",
    "# tau_vec, x_DRT = DRT(chData[0,:,freq_list].T)\n",
    "# np.shape(chData[0,:,freq_list].T)\n",
    "\n",
    "fig, axis = plt.subplots(1,3,figsize=(15,6))\n",
    "cmap = plt.get_cmap('RdYlBu')\n",
    "# cmap = plt.get_cmap('rainbow_r')\n",
    "RLC_flag = [False, False, False]\n",
    "custom_lambda = None\n",
    "# custom_lambda = 1e-4\n",
    "for i in range(np.shape(chData)[0]):\n",
    "# for i in [4,5,6]:\n",
    "    if True:\n",
    "        RLC_flag = [False, False, False]\n",
    "        ch_eis = chData[i,:,:]\n",
    "        # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "        # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "        tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag,custom_lambda)\n",
    "        \n",
    "        \n",
    "        _color = cmap(i/np.shape(chData)[0])\n",
    "        # if i == 5: _color = 'black'\n",
    "        axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        \n",
    "        axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "    \n",
    "    if False:\n",
    "        RLC_flag = [True, True, False]\n",
    "        ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "        # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "        # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "        tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag,custom_lambda)\n",
    "        \n",
    "        \n",
    "        _color = cmap(i/np.shape(chData)[0])\n",
    "        axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "        \n",
    "        axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "    # plt.plot(np.log10(ch_eis[0,:]), np.log10(np.abs(ch_eis[1,:]+1j*ch_eis[2,:])), 'r')\n",
    "    # plt.plot(np.log10(ch_eis_rec[0,:]), np.log10(np.abs(ch_eis_rec[1,:]+1j*ch_eis_rec[2,:])), 'b')\n",
    "    # plt.plot(np.log10(ch_day[0,:]), np.rad2deg(np.angle(ch_day[1,:]+1j*ch_day[2,:])), 'r')\n",
    "    # plt.plot(np.log10(ch_day_rec[0,:]), np.rad2deg(np.angle(ch_day_rec[1,:]+1j*ch_day_rec[2,:])), 'b')\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRT Pipeline - Batch Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRTPrepare(ch_eis):\n",
    "        freq_vec = ch_eis[0,:]\n",
    "        Z_real = ch_eis[1,:]\n",
    "        Z_imag = ch_eis[2,:]\n",
    "        if np.mean(np.diff(np.log(freq_vec))) > 0:\n",
    "            freq_vec = np.flip(freq_vec)\n",
    "            Z_real = np.flip(Z_real)\n",
    "            Z_imag = np.flip(Z_imag)\n",
    "        _tau_ext_scale = 0\n",
    "        _log_tau_min = -8\n",
    "        _log_tau_max = 0\n",
    "        # _log_tau_min = np.log10(1/(2*np.pi*freq_vec[0])) - _tau_ext_scale\n",
    "        # _log_tau_max = np.log10(1/(2*np.pi*freq_vec[-1])) + _tau_ext_scale\n",
    "        # _log_tau_min = np.log10(1/(freq_vec[0]))  - _tau_ext_scale\n",
    "        # _log_tau_max = np.log10(1/(freq_vec[-1])) + _tau_ext_scale\n",
    "        # tau_vec = 1/(2*np.pi*freq_vec)\n",
    "        # tau_vec = 1/freq_vec\n",
    "        tau_vec = np.logspace(_log_tau_min,_log_tau_max,np.shape(freq_vec)[0],endpoint=True)\n",
    "        # tau_vec = np.logspace(np.floor(_log_tau_min),np.ceil(_log_tau_max),np.shape(freq_vec)[0],endpoint=True)\n",
    "        return [freq_vec, tau_vec, Z_real, Z_imag]\n",
    "\n",
    "def DRTAssemble(freq_vec, tau_vec, RLC_Flag = [False, False, False], RBF_type = 'Gaussian'):\n",
    "    '''==================================================\n",
    "        Assemble A & M for Tikhonov Regularization\n",
    "        Parameter: \n",
    "            freq_vec: frequency vector\n",
    "            tau_vec: time domain vector\n",
    "            RLC_Flag: [R_inf, L_0, C_0]\n",
    "            RBF_type: RBF Kernel Type:\n",
    "                1. 'Piecewise Linear'\n",
    "                2. 'Gaussian'            (default)\n",
    "                3. 'C0 Matern'\n",
    "                4. 'C2 Matern'\n",
    "                5. 'C4 Matern'\n",
    "                6. 'C6 Matern'\n",
    "                7. 'Inverse Quadratic'\n",
    "        Returen:\n",
    "            A_re: Discretization Matrix for Real Part\n",
    "            A_im: Discretization Matrix for Imaginary Part\n",
    "            M2: Differentiation Matrixs\n",
    "        ==================================================\n",
    "    '''\n",
    "    ## Freq domain data prepare\n",
    "    n_freq  = freq_vec.shape[0]\n",
    "    n_tau   = tau_vec.shape[0]\n",
    "\n",
    "    # Validate freq in descending order & tau in ascending order\n",
    "    if np.mean(np.diff(np.log(freq_vec))) > 0:\n",
    "        logger.warning(\"Frequency is not in descending order\")\n",
    "        return None\n",
    "    if np.mean(np.diff(np.log(tau_vec))) < 0:\n",
    "        logger.warning(\"Relaxation time is not in ascending order\")\n",
    "        return None\n",
    "    # Discretization matrices Parameters\n",
    "    # Use RBF Kernel to initialize the A matrix\n",
    "    RBF_shape_control = 'FWHM Coefficient' \n",
    "    RBF_coeff = 0.5\n",
    "\n",
    "    '''Compute the RBF Shape Parameter Epsilon'''\n",
    "    epsilon = drt.basics.compute_epsilon(freq_vec, RBF_coeff, RBF_type, RBF_shape_control)\n",
    "    # logger.info(f\"epsilon: {epsilon}\")\n",
    "\n",
    "    '''Compute the discretization matrices'''\n",
    "    A_re = drt.basics.assemble_A_re(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    n_extend = np.sum(RLC_Flag)   \n",
    "    if RLC_Flag[2]:\n",
    "        A_re_C_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_C_0, A_re)) \n",
    "    if RLC_Flag[1]:\n",
    "        A_re_L_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_L_0, A_re))\n",
    "    if RLC_Flag[0]:\n",
    "        A_re_R_inf  = np.ones((n_freq, 1))\n",
    "        A_re        = np.hstack((A_re_R_inf, A_re))  \n",
    "\n",
    "    A_im = drt.basics.assemble_A_im(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    if RLC_Flag[2]:\n",
    "        A_im_C_0    = -1/(2*np.pi*freq_vec.reshape(-1,1))\n",
    "        A_im        = np.hstack((A_im_C_0, A_im))\n",
    "    if RLC_Flag[1]:\n",
    "        A_im_L_0    = 2*np.pi*freq_vec.reshape(-1,1)\n",
    "        A_im        = np.hstack((A_im_L_0, A_im))\n",
    "    if RLC_Flag[0]:\n",
    "        A_im_R_inf  = np.zeros((n_freq, 1)) \n",
    "        A_im        = np.hstack((A_im_R_inf, A_im))\n",
    "\n",
    "    # A = np.vstack((A_re, A_im))\n",
    "\n",
    "\n",
    "    '''Compute the differentiation matrices for Tiknonov regularization'''\n",
    "    M2 = np.zeros((n_tau+n_extend, n_tau+n_extend))\n",
    "    M2[n_extend:,n_extend:] = drt.basics.assemble_M_2(tau_vec, epsilon, RBF_type)\n",
    "\n",
    "    return [A_re, A_im, M2, n_extend]\n",
    "\n",
    "def DRTDeconvolve(Z_real, Z_imag, A_re, A_im, M2, n_extend, RLC_Flag = [False, False, False], custom_lambda = None, cv_type='mGCV'):\n",
    "    '''==================================================\n",
    "        Deconvolve DRT from EIS Data\n",
    "        Parameter: \n",
    "            freq_vec: frequency vector\n",
    "            tau_vec: time domain vector\n",
    "            Z_real: real part of impedance\n",
    "            Z_imag: imaginary part of impedance\n",
    "            custom_lambda: Tikhonov regularization parameter\n",
    "            cv_type: Cross-validation Method for optimize lambda\n",
    "                1. 'GCV'     \n",
    "                2. 'mGCV'    (default)\n",
    "                3. 'rGCV'    \n",
    "                4. 'LC'      \n",
    "                5. 're-im'   \n",
    "                6. 'kf'      \n",
    "        Returen:\n",
    "            x: DRT result\n",
    "            n_extend: number of extend RLC parameters\n",
    "            lambda_opt: optimized lambda\n",
    "            x_extend: extend RLC parameters\n",
    "        ==================================================\n",
    "    '''\n",
    "\n",
    "    '''Optimize lambda'''\n",
    "    if custom_lambda is None:\n",
    "        log_lambda_init = -7 # ln(lambda_init = 0.001)\n",
    "        lambda_opt = drt.basics.optimal_lambda(A_re, A_im, Z_real, Z_imag, M2, \"Combined Re-Im Data\", RLC_Flag[1], log_lambda_init, cv_type)\n",
    "    else: \n",
    "        lambda_opt = custom_lambda\n",
    "    # logger.info(f\"lambda_opt: {epsilon}\")\n",
    "    \n",
    "    '''Deconvolve The DRT from the EIS Data'''\n",
    "    H_combined, c_combined = drt.basics.quad_format_combined(A_re, A_im, Z_real, Z_imag, M2, lambda_opt)\n",
    "    G = matrix(-np.identity(Z_real.shape[0]+n_extend))\n",
    "    h = matrix(np.zeros(Z_real.shape[0]+n_extend))\n",
    "    sol = solvers.qp(matrix(H_combined), matrix(c_combined), G, h)\n",
    "    \n",
    "    # Deconvolved DRT\n",
    "    x = np.array(sol['x'])\n",
    "    \n",
    "    if n_extend > 0:\n",
    "        x_DRT = x[n_extend:]\n",
    "        x_extend = x[:n_extend]\n",
    "    else: \n",
    "        x_DRT = x\n",
    "        x_extend = None\n",
    "    return [x_DRT, lambda_opt, x_extend]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRT_Single(ch_eis, RLC_Flag=[True, True, True], custom_lambda = 0.01):\n",
    "    freq_vec, tau_vec, Z_real, Z_imag = DRTPrepare(ch_eis)\n",
    "    A_re, A_im, M2, n_extend = DRTAssemble(freq_vec, tau_vec, RLC_Flag)\n",
    "    x_DRT, lambda_opt, _ = DRTDeconvolve(Z_real, Z_imag, A_re, A_im, M2, n_extend, RLC_Flag, custom_lambda)\n",
    "\n",
    "    fig, axis = plt.subplots(1,3,figsize=(15,6))\n",
    "    axis[0].semilogx(tau_vec, x_DRT, linewidth=2, label=f\"Session {0}\")\n",
    "    axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), linewidth=2, label=f\"Session {0}\")\n",
    "    axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), linewidth=2, label=f\"Session {0}\")\n",
    "    \n",
    "    # fig.show()\n",
    "\n",
    "    # logger.info(f\"Lambda: {lambda_opt}\")    \n",
    "    # logger.info(f\"Freq: {freq_vec[0]:.2e} - {freq_vec[-1]:.2e}\")\n",
    "    # logger.info(f\"Tau: {tau_vec[0]:.2e} - {tau_vec[-1]:.2e}\")\n",
    "\n",
    "df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "DRT_Single(ch_eis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT_Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRT_Batch(ch_id, EISDict, freq_list):\n",
    "    chData = readChannel(ch_id, EISDict)\n",
    "    if True:\n",
    "        phz_calibration = np.loadtxt(\"./phz_Calib.txt\")\n",
    "        for i in range(np.shape(chData)[0]):\n",
    "            ch_eis = EIS_recal_ver02(chData[i,:,:], phz_calibration)\n",
    "            chData[i,:,:] = ch_eis\n",
    "\n",
    "\n",
    "    if np.shape(chData)[0] < 3:\n",
    "        logger.warning(f\"Channel {ch_id} has less than 3 samples\")\n",
    "        return None\n",
    "    # Parameters\n",
    "    RLC_Flag=[True, True, True]\n",
    "    custom_lambda = 0.0005\n",
    "\n",
    "    # DRT A & M Matrix Assemble\n",
    "    freq_vec, tau_vec, _, _ = DRTPrepare(chData[0,:,freq_list].T)\n",
    "    A_re, A_im, M2, n_extend = DRTAssemble(freq_vec, tau_vec, RLC_Flag)\n",
    "    \n",
    "    # DRT Main\n",
    "    ch_DRT = []\n",
    "    for i in range(np.shape(chData)[0]):\n",
    "    # for i in [0,1,2,3,4,5,6,7,8]:\n",
    "        ch_eis = chData[i,:,freq_list].T\n",
    "        # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "        freq_vec, tau_vec, Z_real, Z_imag = DRTPrepare(ch_eis)\n",
    "        x_DRT, lambda_opt, x_extend = DRTDeconvolve(Z_real, Z_imag, A_re, A_im, M2, n_extend, RLC_Flag, custom_lambda)\n",
    "        ch_DRT.append(x_DRT.flatten())\n",
    "    return [np.array(ch_DRT), tau_vec]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootPath = \"D:/Baihm/EISNN/Dataset/01037160_归档\"\n",
    "# ch_id = 20  # Normal to Short, Same to GPR  \n",
    "# ch_id = 89  # Same to GPR  \n",
    "# ch_id = 7  # Normal Example\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Dataset/05087163_归档\"\n",
    "# ch_id = 7   # one outlier\n",
    "# ch_id = 50  # Normal? \n",
    "# ch_id = 55  # One outlier &wired end point\n",
    "# ch_id = 114 # Open Circuit with on outpler\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/02067447_归档\"\n",
    "# ch_id = 68  # Short all the time\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/01067095_归档\"\n",
    "# ch_id = 19    # First Sample is outlier\n",
    "\n",
    "# rootPath = \"D:/Baihm/EISNN/Archive/09290511_归档\"\n",
    "# ch_id = 13    # Up & Down, 2 outliers\n",
    "# ch_id = 21    # Normal + 2 outlier\n",
    "# ch_id = 41    # Normal + 2 outlier - *(Hard To Tell)\n",
    "# ch_id = 79    # 3-class, What a mess\n",
    "\n",
    "rootPath = \"D:/Baihm/EISNN/Archive/11057712_归档\"\n",
    "ch_id = 106    # Very Good Electrode with 1 outlier\n",
    "\n",
    "\n",
    "\n",
    "EISDict = gatherCSV(rootPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_list = np.linspace(1000,5000-1,101,dtype=int, endpoint=True)\n",
    "\n",
    "freq_list = np.linspace(0,5000-1,501,dtype=int, endpoint=True)\n",
    "\n",
    "ch_DRT, tau_vec = DRT_Batch(ch_id, EISDict, freq_list)\n",
    "ch_DRT_cum = np.cumsum(ch_DRT,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chData = readChannel(ch_id, EISDict)\n",
    "fig, axis = plt.subplots(1,5,figsize=(15,6))\n",
    "cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "for i in range(np.shape(ch_DRT)[0]):\n",
    "# for i in [0,1,2,3,4,5,6,9,10,11,12]:\n",
    "    ch_eis = chData[i,:,freq_list].T\n",
    "    # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "    _color = cmap(i/np.shape(chData)[0])\n",
    "    axis[0].semilogx(tau_vec, np.power(ch_DRT[i],1), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    axis[2].semilogx(ch_eis[0,:], np.rad2deg(np.angle(ch_eis[1,:]+1j*ch_eis[2,:])), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    axis[3].plot(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    axis[4].loglog(ch_eis[1,:], -ch_eis[2,:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[4].semilogx(tau_vec, ch_DRT_cum[i], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    # axis[3].plot(chData[i,1,1000:], -chData[i,2,1000:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    " \n",
    " \n",
    "# axis[0].legend(frameon=False, loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chData = readChannel(ch_id, EISDict)\n",
    "# fig, axis = plt.subplots(1,1,figsize=(15,6))\n",
    "# cmap = plt.get_cmap('rainbow_r')\n",
    "# for i in range(np.shape(ch_DRT)[0]):\n",
    "# # for i in [0,1,2,3,4,5,6,9,10,11,12]:\n",
    "#     ch_eis = chData[i,:,freq_list].T\n",
    "#     # ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "#     _color = cmap(i/np.shape(chData)[0])\n",
    "#     axis.loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "    \n",
    " \n",
    "# # axis[0].legend(frameon=False, loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3D Plot\n",
    "# fig = plt.figure()\n",
    "# ax0 = fig.add_subplot(121, projection='3d')\n",
    "# ax1 = fig.add_subplot(122, projection='3d')\n",
    "# init_elev = 21  # 仰角\n",
    "# init_azim = 55  # 方位角\n",
    "# ax0.view_init(elev=init_elev, azim=init_azim)\n",
    "# ax1.view_init(elev=init_elev, azim=init_azim)\n",
    "\n",
    "# # x = np.log10(tau_vec).flatten()\n",
    "# x = np.array(range(ch_DRT.shape[0]))\n",
    "# y = np.array(range(ch_DRT.shape[1]))\n",
    "# X,Y = np.meshgrid(x,y,indexing='ij')\n",
    "# ax0.plot_surface(X, Y, ch_DRT[:,:ch_DRT.shape[1]], cmap='viridis_r', alpha=0.8)\n",
    "\n",
    "\n",
    "# ch_Data_ds = np.abs(chData[:,1,:] + 1j*chData[:,2,:])\n",
    "# x = np.array(range(ch_Data_ds.shape[0]))\n",
    "# y = np.array(range(ch_Data_ds.shape[1]))\n",
    "# X,Y = np.meshgrid(x,y,indexing='ij')\n",
    "# ax1.plot_surface(X, Y, np.log10(ch_Data_ds), cmap='viridis_r', alpha=0.8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array(range(ch_DRT.shape[1]))\n",
    "# y = np.array(range(ch_DRT.shape[0]))\n",
    "\n",
    "# X,Y = np.meshgrid(x,y)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# gs = plt.GridSpec(1,1)\n",
    "# plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0.5)\n",
    "# ax = plt.subplot(gs[0,0])\n",
    "# cs = ax.contourf(X,Y,ch_DRT,cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT_dimentional deduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "# data = ch_DRT\n",
    "# data = np.log(ch_DRT_cum)\n",
    "data = np.log(ch_EIS)\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "emb_dist = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n",
    "    \n",
    "    _x = embedding[:,0].flatten()\n",
    "    _y = embedding[:,1].flatten()\n",
    "\n",
    "    emb_dist[name] = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                         (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(3,4,figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:,0].flatten()\n",
    "    _y = emb[:,1].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                         (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "    # _dist = emb_dist[name]\n",
    "\n",
    "    axis[np.int16(i/2),(i%2)*2].scatter(emb[:, 0], emb[:, 1], c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    axis[np.int16(i/2),(i%2)*2].set_title(name)\n",
    "\n",
    "    s = axis[np.int16(i/2),(i%2)*2+1].imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2),(i%2)*2+1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axis = plt.subplots(3, 4, figsize=(12, 6), subplot_kw={'projection': '3d'})  # 指定3D投影\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten()\n",
    "    _y = emb[:, 1].flatten()\n",
    "    _z = emb[:, 2].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data 添加顺序信息\n",
    "这里需要调整顺序信息在整个DRT数据中的权重，容易因为顺序信息过强导致异常值不显著"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "\n",
    "index_scale = np.max(ch_DRT) * 0.5\n",
    "index_vec = ((np.arange(np.shape(ch_DRT)[0])+1) * index_scale ).reshape(-1,1)\n",
    "ch_DRT_ext = np.hstack((ch_DRT, index_vec))\n",
    "\n",
    "\n",
    "# data = ch_DRT\n",
    "# data = np.log(ch_EIS)\n",
    "data =np.hstack((ch_DRT, index_vec))\n",
    "# data =np.hstack((ch_EIS, index_vec))\n",
    "\n",
    "\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(3,4,figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:,0].flatten()\n",
    "    _y = emb[:,1].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                         (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n",
    "\n",
    "    axis[np.int16(i/2),(i%2)*2].scatter(emb[:, 0], emb[:, 1], c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    axis[np.int16(i/2),(i%2)*2].set_title(name)\n",
    "\n",
    "    s = axis[np.int16(i/2),(i%2)*2+1].imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2),(i%2)*2+1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten()\n",
    "    _y = emb[:, 1].flatten()\n",
    "    _z = emb[:, 2].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA添加顺序信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "\n",
    "\n",
    "data = ch_DRT\n",
    "# data = np.log(ch_EIS)\n",
    "\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten() / np.max(emb[:, 0])\n",
    "    _y = emb[:, 1].flatten() / np.max(emb[:, 1])\n",
    "    _z = (np.arange(np.shape(emb)[0]) + 1).flatten() / np.shape(emb)[0] \n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EIS变化张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_dist_tensor(data_cpx):\n",
    "    n_sample = np.shape(data_cpx)[1]\n",
    "    dist_tensor = []\n",
    "    for i in range(n_sample):\n",
    "        _vec = data_cpx[:,i].reshape(-1,1)\n",
    "        dist_tensor.append(np.real(_vec - _vec.T))\n",
    "        dist_tensor.append(np.imag(_vec - _vec.T))\n",
    "    dist_tensor = np.array(dist_tensor).T\n",
    "    return dist_tensor.reshape(np.shape(dist_tensor)[0],-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS\n",
    "import umap.umap_ as umap  # 请确保安装了 umap-learn\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "ch_EIS_cpx = chData[:,1,freq_list] + 1j*chData[:,2,freq_list]\n",
    "dist_tensor = assemble_dist_tensor(ch_EIS_cpx)\n",
    "data = dist_tensor\n",
    "# data = np.log(ch_DRT_cum)\n",
    "# data = np.log(ch_EIS)\n",
    "\n",
    "_order = 3\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "embeddings = {}\n",
    "for name, method in methods.items():\n",
    "    embedding = method.fit_transform(data)\n",
    "    embeddings[name] = embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(3,4,figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:,0].flatten()\n",
    "    _y = emb[:,1].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n",
    "\n",
    "    axis[np.int16(i/2),(i%2)*2].scatter(emb[:, 0], emb[:, 1], c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    axis[np.int16(i/2),(i%2)*2].set_title(name)\n",
    "\n",
    "    s = axis[np.int16(i/2),(i%2)*2+1].imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2),(i%2)*2+1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for i, (name, emb) in enumerate(embeddings.items()):\n",
    "    _x = emb[:, 0].flatten()\n",
    "    _y = emb[:, 1].flatten()\n",
    "    _z = emb[:, 2].flatten()\n",
    "\n",
    "    _dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "                    (_y[:, np.newaxis] - _y[np.newaxis, :])**2 + \n",
    "                    (_z[:, np.newaxis] - _z[np.newaxis, :])**2)\n",
    "\n",
    "    ax = fig.add_subplot(3,4,i*2+1, projection='3d')\n",
    "\n",
    "    # 3D散点图\n",
    "    sc = ax.scatter(_x, _y, _z, c=np.arange(np.shape(data)[0]), cmap='rainbow_r', edgecolor='k', s=100)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 2D距离矩阵可视化\n",
    "    \n",
    "    ax = fig.add_subplot(3,4,i*2+2)\n",
    "    s = ax.imshow(_dist, cmap='coolwarm', interpolation='nearest')\n",
    "    fig.colorbar(s, ax=axis[np.int16(i/2), (i%2)*2+1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRT or EIS based OD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM\n",
    "由于需要手动设置状态，无法很好的区分异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# 假设你的数据是一个 16x101 的矩阵，这里用随机数据模拟\n",
    "np.random.seed(42)\n",
    "# data = ch_DRT\n",
    "data = np.log(ch_EIS)\n",
    "\n",
    "# 如果需要，也可以对数据做预处理，例如归一化\n",
    "\n",
    "# 定义最大可能状态数，比如设为5\n",
    "max_states = 4\n",
    "\n",
    "# 初始化高斯隐马尔可夫模型\n",
    "# covariance_type 可以根据数据特性选择 'diag' 或 'full'\n",
    "model = hmm.GaussianHMM(n_components=max_states, covariance_type='diag', n_iter=100, random_state=42)\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(data)\n",
    "\n",
    "# 使用模型预测隐状态序列（返回长度为16的一维数组）\n",
    "hidden_states = model.predict(data)\n",
    "print(\"预测的隐状态序列:\", hidden_states)\n",
    "\n",
    "# 输出状态转移矩阵，观察哪些状态有较高的占用概率\n",
    "print(\"状态转移矩阵:\\n\", model.transmat_)\n",
    "\n",
    "# 可视化隐状态随时间的变化\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(hidden_states, marker='o', linestyle='-')\n",
    "plt.xlabel('Time Stamp')\n",
    "plt.ylabel('Hidden State')\n",
    "plt.title('HMM Hidden State Series')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Change Point Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import t  # 导入 Student-t 分布\n",
    "\n",
    "# ----------------------------\n",
    "# 1. 数据准备与降维\n",
    "# ----------------------------\n",
    "np.random.seed(42)\n",
    "data = ch_DRT\n",
    "# data = np.random.randn(16, 101)\n",
    "# data[8:] += 5  # 模拟状态转移\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "data_1d = pca.fit_transform(data).flatten()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. BOCPD实现（Univariate case）\n",
    "# ----------------------------\n",
    "T = len(data_1d)\n",
    "R = np.zeros((T + 1, T + 1))\n",
    "R[0, 0] = 1\n",
    "\n",
    "# Normal-Inverse-Gamma先验参数\n",
    "mu0 = 0.0\n",
    "kappa0 = 1.0\n",
    "alpha0 = 1.0\n",
    "beta0 = 1.0\n",
    "\n",
    "# 初始化足够统计量，使用字典存储，key为运行长度\n",
    "mu = {0: mu0}\n",
    "kappa = {0: kappa0}\n",
    "alpha = {0: alpha0}\n",
    "beta = {0: beta0}\n",
    "\n",
    "def predictive_pdf(x, mu_val, kappa_val, alpha_val, beta_val):\n",
    "    \"\"\"\n",
    "    预测分布为 Student-t 分布：\n",
    "      - 自由度: nu = 2 * alpha_val\n",
    "      - 位置: mu_val\n",
    "      - 尺度: sqrt( beta_val*(kappa_val+1) / (alpha_val*kappa_val) )\n",
    "    \"\"\"\n",
    "    nu = 2 * alpha_val\n",
    "    scale = np.sqrt(beta_val * (kappa_val + 1) / (alpha_val * kappa_val))\n",
    "    return t.pdf(x, df=nu, loc=mu_val, scale=scale)\n",
    "\n",
    "def constant_hazard(lam):\n",
    "    \"\"\"常数危险函数\"\"\"\n",
    "    return lambda r: np.full(r.shape, 1.0 / lam)\n",
    "\n",
    "hazard = constant_hazard(100)\n",
    "cp_probabilities = []\n",
    "\n",
    "for time_idx in range(1, T + 1):\n",
    "    x = data_1d[time_idx - 1]\n",
    "    pred_probs = np.zeros(time_idx)\n",
    "    for r in range(time_idx):\n",
    "        pred_probs[r] = predictive_pdf(x, mu[r], kappa[r], alpha[r], beta[r])\n",
    "    \n",
    "    growth_probs = R[time_idx - 1, :time_idx] * (1 - hazard(np.arange(1, time_idx + 1))) * pred_probs\n",
    "    cp_prob = np.sum(R[time_idx - 1, :time_idx] * hazard(np.arange(1, time_idx + 1)) * pred_probs)\n",
    "    \n",
    "    R[time_idx, 1:time_idx + 1] = growth_probs\n",
    "    R[time_idx, 0] = cp_prob\n",
    "    R[time_idx, :time_idx + 1] /= np.sum(R[time_idx, :time_idx + 1])\n",
    "    \n",
    "    cp_probabilities.append(R[time_idx, 0])\n",
    "    \n",
    "    new_mu = {}\n",
    "    new_kappa = {}\n",
    "    new_alpha = {}\n",
    "    new_beta = {}\n",
    "    \n",
    "    new_mu[0] = mu0\n",
    "    new_kappa[0] = kappa0\n",
    "    new_alpha[0] = alpha0\n",
    "    new_beta[0] = beta0\n",
    "    \n",
    "    for r in range(1, time_idx + 1):\n",
    "        new_mu[r] = (kappa[r - 1] * mu[r - 1] + x) / (kappa[r - 1] + 1)\n",
    "        new_kappa[r] = kappa[r - 1] + 1\n",
    "        new_alpha[r] = alpha[r - 1] + 0.5\n",
    "        new_beta[r] = beta[r - 1] + 0.5 * ((x - mu[r - 1]) ** 2 * kappa[r - 1] / (kappa[r - 1] + 1))\n",
    "    \n",
    "    mu = new_mu\n",
    "    kappa = new_kappa\n",
    "    alpha = new_alpha\n",
    "    beta = new_beta\n",
    "\n",
    "# ----------------------------\n",
    "# 3. 可视化\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stem(range(1, T + 1), cp_probabilities, basefmt=\" \")\n",
    "plt.xlabel('时间点')\n",
    "plt.ylabel('变点概率')\n",
    "plt.title('贝叶斯在线变点检测 - 变点概率')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, T + 1), data_1d, marker='o')\n",
    "plt.xlabel('时间点')\n",
    "plt.ylabel('PCA降维后数据')\n",
    "plt.title('1D降维数据及变点检测')\n",
    "plt.axvline(x=8, color='red', linestyle='--', label='模拟变点（时刻8）')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OD - IsoForest / LOF / SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "# from pyod.models.pca import PCA as PCA_OD\n",
    "\n",
    "# 生成示例数据\n",
    "# np.random.seed(42)\n",
    "ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "# data = ch_DRT\n",
    "data = np.log(ch_EIS)\n",
    "\n",
    "methods = {\n",
    "    'PCA': PCA(n_components=_order),\n",
    "    't-SNE': TSNE(n_components=_order, perplexity=5, random_state=42),  # perplexity 设置为 5\n",
    "    'Isomap': Isomap(n_components=_order),\n",
    "    'LLE': LocallyLinearEmbedding(n_components=_order, random_state=42),\n",
    "    'MDS': MDS(n_components=_order, random_state=42),\n",
    "    'UMAP': umap.UMAP(n_components=_order, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "# 使用PCA将数据降维到2D，以便可视化\n",
    "data_2d = methods['PCA'].fit_transform(data)\n",
    "\n",
    "# 定义子图布局\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 1. 使用PCA进行异常检测\n",
    "# pca_od = PCA_OD(contamination=0.1)\n",
    "# pca_od.fit(data)\n",
    "# pca_scores = pca_od.decision_function(data)\n",
    "# pca_predictions = pca_od.predict(data)\n",
    "# axes[0].scatter(data_2d[:, 0], data_2d[:, 1], c=pca_predictions, cmap='coolwarm', edgecolor='k')\n",
    "# axes[0].set_title('PCA Anomaly Detection')\n",
    "\n",
    "# 2. 使用Isolation Forest进行异常检测\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=100)\n",
    "iso_forest.fit(data)\n",
    "iso_predictions = iso_forest.predict(data)\n",
    "iso_predictions = np.where(iso_predictions == 1, 0, 1)  # 转换为0表示正常，1表示异常\n",
    "axes[0].scatter(data_2d[:, 0], data_2d[:, 1], c=iso_predictions, cmap='coolwarm', edgecolor='k')\n",
    "axes[0].set_title('Isolation Forest Anomaly Detection')\n",
    "\n",
    "# 3. 使用LOF进行异常检测\n",
    "lof = LocalOutlierFactor(n_neighbors=4, contamination=0.2)\n",
    "lof_predictions = lof.fit_predict(data)\n",
    "lof_predictions = np.where(lof_predictions == 1, 0, 1)  # 转换为0表示正常，1表示异常\n",
    "axes[1].scatter(data_2d[:, 0], data_2d[:, 1], c=lof_predictions, cmap='coolwarm', edgecolor='k')\n",
    "axes[1].set_title('LOF Anomaly Detection')\n",
    "\n",
    "# 4. 使用One-Class SVM进行异常检测\n",
    "oc_svm = OneClassSVM(nu=0.1, kernel='rbf', gamma='auto')\n",
    "oc_svm.fit(data)\n",
    "oc_predictions = oc_svm.predict(data)\n",
    "oc_predictions = np.where(oc_predictions == 1, 0, 1)  # 转换为0表示正常，1表示异常\n",
    "axes[2].scatter(data_2d[:, 0], data_2d[:, 1], c=oc_predictions, cmap='coolwarm', edgecolor='k')\n",
    "axes[2].set_title('One-Class SVM Anomaly Detection')\n",
    "\n",
    "# 设置图形标题和布局\n",
    "plt.suptitle('Anomaly Detection Results Using Different Algorithms')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dist Based Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 生成模拟的 16x16 距离矩阵（对称矩阵，模拟样本间距离）\n",
    "np.random.seed(42)\n",
    "A = emb_dist['PCA']\n",
    "\n",
    "# PCA 降维用于可视化\n",
    "pca = PCA(n_components=2)\n",
    "X_2D = pca.fit_transform(A)\n",
    "\n",
    "# ==================== 层次聚类 ====================\n",
    "Z = linkage(A, method='average',optimal_ordering=True)  # 使用 Ward 方式进行层次聚类\n",
    "clusters_hierarchical = fcluster(Z, t=3, criterion='maxclust')\n",
    "\n",
    "# ==================== DBSCAN ====================\n",
    "dbscan = DBSCAN(metric='precomputed', eps=0.5, min_samples=2)\n",
    "clusters_dbscan = dbscan.fit_predict(A)\n",
    "\n",
    "# ==================== LOF ====================\n",
    "lof = LocalOutlierFactor(metric='precomputed', n_neighbors=5)\n",
    "lof_outlier_scores = lof.fit_predict(A)\n",
    "\n",
    "# 可视化函数\n",
    "def plot_results(title, labels):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(X_2D[:, 0], X_2D[:, 1], c=labels, cmap='coolwarm', edgecolors='k', s=100)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PCA 1\")\n",
    "    plt.ylabel(\"PCA 2\")\n",
    "    plt.show()\n",
    "\n",
    "# 绘制层次聚类结果\n",
    "plot_results(\"Hierarchical Clustering\", clusters_hierarchical)\n",
    "\n",
    "# 绘制 DBSCAN 结果\n",
    "plot_results(\"DBSCAN Clustering\", clusters_dbscan)\n",
    "\n",
    "# 绘制 LOF 结果（-1 为异常点）\n",
    "plot_results(\"Local Outlier Factor (LOF)\", lof_outlier_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dist Based series order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# 模拟 16x16 的相关性矩阵（对称，主对角线为1）\n",
    "np.random.seed(42)\n",
    "D = emb_dist['MDS']/np.max(emb_dist['MDS'])  # 16x16 距离矩阵\n",
    "# D = (pca_dist-np.mean(pca_dist))  # 16x16 距离矩阵\n",
    "\n",
    "# --- 方法1：修改距离矩阵 ---\n",
    "lambda_penalty = 0  # 调节因子，可根据需要调整\n",
    "n = D.shape[0]\n",
    "indices = np.arange(n)\n",
    "# 构造原始顺序差值矩阵 |i - j|\n",
    "diff_matrix = np.abs(indices.reshape(-1, 1) - indices.reshape(1, -1)) / n\n",
    "P = lambda_penalty * diff_matrix\n",
    "D_mod = D + P  # 修改后的距离矩阵\n",
    "\n",
    "# 转换为 condensed 距离向量供 linkage 使用\n",
    "condensed_D_mod = squareform(D_mod)\n",
    "# 使用平均链接法构造层次聚类树\n",
    "Z_mod = linkage(condensed_D_mod, method='average',optimal_ordering=True)\n",
    "# Z_mod = linkage(condensed_D_mod, method='ward',optimal_ordering=True)\n",
    "# 可选：利用 optimal_leaf_ordering 获得最优叶排序\n",
    "Z_mod_olo = optimal_leaf_ordering(Z_mod, condensed_D_mod)\n",
    "dendro1 = dendrogram(Z_mod_olo, no_plot=True)\n",
    "order1 = dendro1['leaves']\n",
    "# print(\"方法1排序结果：\", order1)\n",
    "\n",
    "# 可视化排序后矩阵\n",
    "sorted_A1 = D[np.ix_(order1, order1)]\n",
    "plt.figure(figsize=(6, 5))\n",
    "# sns.heatmap(sorted_A1, annot=False, cmap='coolwarm')\n",
    "sns.heatmap(D+P, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Ordered Matrix Based on Modified Distance\")\n",
    "plt.show()\n",
    "\n",
    "# 可视化层次聚类树\n",
    "plt.figure(figsize=(8, 4))\n",
    "# dendrogram(Z_mod_olo, labels=np.arange(n))\n",
    "dendrogram(Z_mod, labels=np.arange(n))\n",
    "plt.title(\"H\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Dist\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Optimal Leaf Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# 示例16x16距离矩阵\n",
    "np.random.seed(42)\n",
    "distance_matrix = emb_dist['PCA']/np.max(emb_dist['PCA'])  # 16x16 距离矩阵\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# 使用MDS将距离矩阵转换为坐标形式\n",
    "mds = MDS(n_components=2, dissimilarity='euclidean', random_state=42)\n",
    "coords = mds.fit_transform(ch_DRT)\n",
    "\n",
    "# 进行GMM聚类\n",
    "n_components = 3  # 假设分为4个高斯成分\n",
    "gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "gmm.fit(coords)\n",
    "labels = gmm.predict(coords)\n",
    "\n",
    "# 可视化GMM聚类结果\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c=labels, cmap='viridis', s=100, )\n",
    "plt.title(\"高斯混合模型 - MDS降维后的聚类结果\")\n",
    "plt.xlabel(\"MDS Dimension 1\")\n",
    "plt.ylabel(\"MDS Dimension 2\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRT_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import numpy as np\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # 假设你的数据是 16x101 的 numpy 数组\n",
    "# # freq_list = np.linspace(1000,5000-1,101,dtype=int, endpoint=True)\n",
    " \n",
    "# chData = readChannel(ch_id, EISDict)\n",
    "# ch_EIS = np.abs(chData[:,1,freq_list] + 1j*chData[:,2,freq_list])\n",
    "# # data = np.log(ch_EIS)\n",
    "# # data = ch_EIS\n",
    "\n",
    "# # data = np.log(ch_DRT+1)\n",
    "# data = ch_DRT_cum\n",
    "\n",
    "# # 1. 数据中心化（去均值）\n",
    "# mean = np.mean(data, axis=0)\n",
    "# data_centered = data - mean\n",
    "\n",
    "# # 2. 计算协方差矩阵\n",
    "# cov_matrix = np.cov(data_centered, rowvar=False)\n",
    "\n",
    "# # 3. 计算特征值和特征向量\n",
    "# eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "# # 4. 按特征值大小排序\n",
    "# idx = np.argsort(eigenvalues)[::-1]  # 从大到小排序\n",
    "# eigenvalues = eigenvalues[idx]\n",
    "# eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "# # 5. 选择前 k 个主成分（这里 k=2）\n",
    "# k = 2\n",
    "# top_eigenvectors = np.hstack((eigenvectors[:, 0].reshape(-1,1),eigenvectors[:, 1].reshape(-1,1)))\n",
    "\n",
    "# # 6. 投影数据到主成分空间\n",
    "# pca_data = np.dot(data_centered, top_eigenvectors)\n",
    "\n",
    "# # 7. 计算PCA下距离\n",
    "# _x = pca_data[:,0].flatten()\n",
    "# _y = pca_data[:,1].flatten()\n",
    "\n",
    "# pca_dist = np.sqrt((_x[:, np.newaxis] - _x[np.newaxis, :])**2 + \n",
    "#                          (_y[:, np.newaxis] - _y[np.newaxis, :])**2)\n",
    "\n",
    "# # pca_dist_Z = (pca_dist-np.mean(pca_dist))/np.std(pca_dist)\n",
    "\n",
    "\n",
    "# fig, axis = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "# # 7. 画出前两个主成分\n",
    "# axis[0].scatter(pca_data[:, 0], pca_data[:, 1],c=np.arange(len(pca_data)), cmap='rainbow_r')\n",
    "# axis[0].set_xlabel(\"Principal Component 1\")\n",
    "# axis[0].set_ylabel(\"Principal Component 2\")\n",
    "# axis[0].set_title(\"PCA Projection\")\n",
    "# # axis[0].set_aspect('equal')\n",
    "\n",
    "\n",
    "\n",
    "# # 绘制热图\n",
    "# # s = axis[1].imshow(pca_dist_Z, vmin=-1, vmax=1, cmap='coolwarm', interpolation='nearest')\n",
    "# s = axis[1].imshow(pca_dist, cmap='coolwarm', interpolation='nearest')\n",
    "# # s = axis[1].imshow(pca_dist, cmap='coolwarm', interpolation='nearest')\n",
    "# fig.colorbar(s, ax=axis[1])\n",
    "# axis[1].set_ylabel(\"Point Index\")\n",
    "# axis[1].set_title(\"Distance Matrix Heatmap\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discuss lambda\n",
    "if False:\n",
    "    chData = readChannel(ch_id, EISDict)\n",
    "    freq_list = np.linspace(500,np.shape(chData)[2]-1,101,dtype=int, endpoint=True)\n",
    "    # tau_vec, x_DRT = DRT(chData[0,:,freq_list].T)\n",
    "    # np.shape(chData[0,:,freq_list].T)\n",
    "\n",
    "    fig, axis = plt.subplots(1,3,figsize=(15,6))\n",
    "    cmap = plt.get_cmap('RdYlBu')\n",
    "    # cmap = plt.get_cmap('rainbow_r')\n",
    "    RLC_flag = [False, False, False]\n",
    "    # custom_lambda = None\n",
    "    custom_lambda_list = np.logspace(-6, 0, 7, endpoint=True)\n",
    "    # for i in range(np.shape(chData)[0]):\n",
    "    for i in range(7):\n",
    "        if True:\n",
    "            ch_eis = chData[0,:,freq_list].T\n",
    "            # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "            # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "            tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag,custom_lambda_list[i])\n",
    "            \n",
    "            \n",
    "            _color = cmap(i/np.shape(custom_lambda_list)[0])\n",
    "            # if i == 5: _color = 'black'\n",
    "            axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"$\\lambda$={custom_lambda_list[i]:.1e}\")\n",
    "            axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"$\\lambda$={custom_lambda_list[i]:.1e}\")\n",
    "            axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"$\\lambda$={custom_lambda_list[i]:.1e}\")\n",
    "            \n",
    "            axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "        \n",
    "        if False:\n",
    "            ch_eis = EIS_recal(chData[i,:,:])[:,freq_list]\n",
    "            # df = pd.read_csv('D:/Baihm/EISNN/Download/pyDRTtools/tutorial/data/1ZARC.csv')\n",
    "            # ch_eis = np.array([df['Freq'].values, df['Real'].values, df['Imag'].values])\n",
    "\n",
    "            tau_vec, x_DRT, n_extend, _ = DRT(ch_eis, RLC_flag)\n",
    "            \n",
    "            \n",
    "            _color = cmap(i/np.shape(chData)[0])\n",
    "            axis[0].semilogx(tau_vec[:], x_DRT[n_extend:], color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "            axis[1].loglog(ch_eis[0,:], np.abs(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "            axis[2].semilogx(ch_eis[0,:], np.angle(ch_eis[1,:]+1j*ch_eis[2,:]), color = _color, linewidth=2, label=f\"Session {i}\")\n",
    "            \n",
    "            axis[0].legend(frameon=False, loc='upper left')\n",
    "\n",
    "        # plt.plot(np.log10(ch_eis[0,:]), np.log10(np.abs(ch_eis[1,:]+1j*ch_eis[2,:])), 'r')\n",
    "        # plt.plot(np.log10(ch_eis_rec[0,:]), np.log10(np.abs(ch_eis_rec[1,:]+1j*ch_eis_rec[2,:])), 'b')\n",
    "        # plt.plot(np.log10(ch_day[0,:]), np.rad2deg(np.angle(ch_day[1,:]+1j*ch_day[2,:])), 'r')\n",
    "        # plt.plot(np.log10(ch_day_rec[0,:]), np.rad2deg(np.angle(ch_day_rec[1,:]+1j*ch_day_rec[2,:])), 'b')\n",
    "\n",
    "\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
