{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f06b92",
   "metadata": {},
   "source": [
    "# Import\n",
    "该文档通过生成仿真数据来研究DRT数据性值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d10b68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys \n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from scipy.linalg import eig, svd, solve\n",
    "# import scipy\n",
    "\n",
    "from cvxopt import matrix, solvers\n",
    "solvers.options['show_progress'] = False\n",
    "\n",
    "\n",
    "import pyDRTtools as drt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2904e",
   "metadata": {},
   "source": [
    "# Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b37d1",
   "metadata": {},
   "source": [
    "## Loewner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4e75c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Loewner_Framework(f, Z, REALFLAG = True):\n",
    "    '''==================================================\n",
    "        Construct Loewner Pencel\n",
    "        Parameter: \n",
    "            f:          real array of frequency values\n",
    "            Z:          complex array of impedance values (H = Z)\n",
    "            REALFLAG:   boolean flag to indicate if the model should have real entries\n",
    "        Returen:\n",
    "            L:          Loewner matrix\n",
    "            Ls:         Shifted Loewner matrix\n",
    "            H_left:     Impedance values for group left\n",
    "            H_right:    Impedance values for group right\n",
    "        ==================================================\n",
    "    '''\n",
    "    _n = len(f)\n",
    "    s = 2j * np.pi * f\n",
    "\n",
    "    # Ensuring the input have an even number of elements \n",
    "    # for constructing the model having real entries\n",
    "    if REALFLAG:\n",
    "        if _n % 2 != 0:\n",
    "            _n = _n - 1\n",
    "\n",
    "    # Left & Right Data for Loewner Framework\n",
    "    s_left  = s[:_n:2]\n",
    "    H_left  = Z[:_n:2]\n",
    "    s_right = s[1:_n:2] \n",
    "    H_right = Z[1:_n:2]\n",
    "\n",
    "    # Construct complex conjugate values for ensuring model having real entries\n",
    "    if REALFLAG:\n",
    "        s_left  = np.stack([s_left, s_left.conj()], axis=1).flatten()\n",
    "        H_left  = np.stack([H_left, H_left.conj()], axis=1).flatten()\n",
    "        s_right = np.stack([s_right, s_right.conj()], axis=1).flatten()\n",
    "        H_right = np.stack([H_right, H_right.conj()], axis=1).flatten()\n",
    "\n",
    "    # Constructing the Loewner Matrix & Shifted Loewner Matrix\n",
    "    # L   = (H_left[:,None] - H_right[None,:]) / (s_left[:,None] - s_right[None,:])\n",
    "    # Ls  = (s_left[:,None] * H_left[:,None] - s_right[None,:] * H_right[None,:]) / (s_left[:,None] - s_right[None,:])\n",
    "    L   = (H_left[None,:] - H_right[:,None]) / (s_left[None,:] - s_right[:,None])\n",
    "    Ls  = (s_left[None,:] * H_left[None,:] - s_right[:,None] * H_right[:,None]) / (s_left[None,:] - s_right[:,None])\n",
    "\n",
    "    # Transforming the conplex L & Ls to obtain matrices with real entries\n",
    "    if REALFLAG:\n",
    "        _J_diag = np.eye(_n//2)\n",
    "        _J  = (1/np.sqrt(2)) * np.array([[1, 1j], [1, -1j]])\n",
    "        _J  = np.kron(_J_diag, _J)\n",
    "\n",
    "        L       = (_J.conj().T @ L @ _J).real\n",
    "        Ls      = (_J.conj().T @ Ls @ _J).real\n",
    "        H_left  = ((_J.T @ H_left).T).real\n",
    "        H_right = (_J.conj().T @ H_right).real\n",
    "\n",
    "        \n",
    "    return L, Ls, H_left, H_right\n",
    "\n",
    "def state_space_model(L, Ls, H_left, H_right):\n",
    "    '''==================================================\n",
    "        Construct state space model from Loewner Pencel\n",
    "        Parameter: \n",
    "            L:          Loewner matrix\n",
    "            Ls:         Shifted Loewner matrix\n",
    "            H_left:     Impedance values for group left\n",
    "            H_right:    Impedance values for group right\n",
    "        Returen:\n",
    "            Ek, Ak, Bk, Ck:\n",
    "                Ek x' = Ak x + Bk u\n",
    "                   y  = Ck x + Dk u (Dk = 0)\n",
    "        ==================================================\n",
    "    '''\n",
    "    # rank of the Loewner Pencel\n",
    "    _rank = np.linalg.matrix_rank(np.concatenate((L, Ls), axis=0))\n",
    "    Y_L, svd_L, X_L = svd(L, full_matrices=False, lapack_driver='gesvd')\n",
    "    X_L = X_L.T\n",
    "    \n",
    "    # Reduced state space model interpolating the data\n",
    "    Yk = Y_L[:, :_rank]\n",
    "    Xk = X_L[:, :_rank]\n",
    "\n",
    "    Ek = -Yk.T@L@Xk\n",
    "    Ak = -Yk.T@Ls@Xk\n",
    "    Bk = Yk.T@H_right\n",
    "    Ck = H_left.T@Xk\n",
    "\n",
    "    return Ek, Ak, Bk, Ck\n",
    "\n",
    "def DRT_Transform(Ek, Ak, Bk, Ck, REALFLAG = True, real_th = 1e5):\n",
    "    '''==================================================\n",
    "        Transform state space model to DRT model\n",
    "        Parameter: \n",
    "            Ek, Ak, Bk, Ck:\n",
    "                Ek x' = Ak x + Bk u\n",
    "                   y  = Ck x + Dk u (Dk = 0)\n",
    "        Returen:\n",
    "            R_i:    R_i from RC pair in DRT\n",
    "            C_i:    C_i from RC pair in DRT\n",
    "            tau_i   tau_i from RC pair in DRT\n",
    "        ==================================================\n",
    "    '''\n",
    "    # Solve Av= λEv & wT A= λ wT E & Res = CvwB/wEv, wEv =  δ\n",
    "    _pol, _U = eig(Ak, Ek)     # \n",
    "    wB = solve(_U, solve(Ek,Bk))\n",
    "    Cv = Ck @ _U\n",
    "    _res = Cv * wB\n",
    "\n",
    "    # Calculate R_i & tau_i\n",
    "    tau_i   = (-1/_pol) \n",
    "    R_i     = (-_res / _pol)\n",
    "    C_i     = (1/_res)\n",
    "    # tau_i   = abs(-1/_pol) \n",
    "\n",
    "    if REALFLAG:\n",
    "        # real_ratio = np.where(np.abs(tau_i.imag) == 0, np.inf, np.abs(tau_i.real / (tau_i.imag+1e-20)))\n",
    "        # tau_i = np.abs(tau_i[real_ratio > real_th])\n",
    "        # R_i = np.abs(R_i[real_ratio > real_th])\n",
    "        # C_i = np.abs(C_i[real_ratio > real_th])\n",
    "\n",
    "\n",
    "        real_ratio = np.where(np.abs(tau_i.imag) == 0, np.inf, np.abs(tau_i.real / (tau_i.imag+1e-20)))       \n",
    "        real_mask = (real_ratio > real_th) & (tau_i.real>0) & (R_i.real>0)\n",
    "        tau_i = tau_i[real_mask].real\n",
    "        R_i = R_i[real_mask].real\n",
    "        C_i = tau_i/R_i\n",
    "\n",
    "\n",
    "        # real_mask = (tau_i.real>0)\n",
    "        # tau_i = np.real(tau_i[real_mask])\n",
    "        # R_i = np.real(R_i[real_mask])\n",
    "\n",
    "        # R_i = R_i[tau_i.argsort()]\n",
    "        # tau_i = tau_i[tau_i.argsort()]\n",
    "        \n",
    "        # uniq_cnt_mask = np.abs(np.diff(tau_i, prepend=0)) < 1e-16\n",
    "        # uniq_mask = np.abs(np.diff(tau_i, append=0)) > 1e-16\n",
    "        \n",
    "        # R_i[uniq_cnt_mask] = R_i[uniq_cnt_mask] * 2\n",
    "        # R_i = R_i[uniq_mask]\n",
    "        # tau_i = tau_i[uniq_mask]\n",
    "        # C_i = tau_i / R_i\n",
    "        \n",
    "\n",
    "    return R_i, C_i, tau_i\n",
    "\n",
    "def DRT_Reconstruction_SSM(Ek, Ak, Bk, Ck, f, Z):\n",
    "    '''==================================================\n",
    "        Reconstruct DRT from state space model\n",
    "        Parameter: \n",
    "            R_i:    R_i from RC pair in DRT\n",
    "            tau_i   tau_i from RC pair in DRT\n",
    "            f:  real array of frequency values\n",
    "            Z:  complex array of impedance values (H = Z)\n",
    "        Returen:\n",
    "            H:  reconstructed impedance values\n",
    "        ==================================================\n",
    "    '''\n",
    "    s = 2j * np.pi * f\n",
    "    H = np.array([Ck @ solve(si * Ek - Ak, Bk) for si in s])\n",
    "    res_ReZ = np.abs(((Z.real - H.real) / np.abs(Z))) * 100\n",
    "    res_ImZ = np.abs(((Z.imag - H.imag) / np.abs(Z))) * 100\n",
    "\n",
    "    return H, res_ReZ, res_ImZ\n",
    "\n",
    "\n",
    "def DRT_Reconstruction_DRT(R_i, tau_i, f, Z):\n",
    "    '''==================================================\n",
    "        Reconstruct DRT from state space model\n",
    "        Parameter: \n",
    "            Ek, Ak, Bk, Ck:\n",
    "                Ek x' = Ak x + Bk u\n",
    "                   y  = Ck x + Dk u (Dk = 0)\n",
    "            f:  real array of frequency values\n",
    "            Z:  complex array of impedance values (H = Z)\n",
    "        Returen:\n",
    "            H:  reconstructed impedance values\n",
    "        ==================================================\n",
    "    '''\n",
    "    s = 2j * np.pi * f  # Broadcasting tau_i to match f\n",
    "    _RC = R_i[None, :] / (1+s[:,None] * tau_i[None,:])\n",
    "    H = np.sum(_RC, axis=1)\n",
    "\n",
    "    res_ReZ = np.abs(((Z.real - H.real) / np.abs(Z))) * 100\n",
    "    res_ImZ = np.abs(((Z.imag - H.imag) / np.abs(Z))) * 100\n",
    "\n",
    "    return H, res_ReZ, res_ImZ\n",
    "\n",
    "def Loe_singularity_analysis(f, Z, REALFLAG = True):\n",
    "    '''==================================================\n",
    "        DRT Singularity Analysis\n",
    "        Parameter: \n",
    "            f:          real array of frequency values\n",
    "            Z:          complex array of impedance values (H = Z)\n",
    "            REALFLAG:   boolean flag to indicate if the model should have real entries\n",
    "        Returen:\n",
    "            R_i:        R_i from RC pair in DRT\n",
    "            tau_i:      tau_i from RC pair in DRT\n",
    "        ==================================================\n",
    "    '''\n",
    "    L, Ls, H_left, H_right = Loewner_Framework(f, Z, REALFLAG)\n",
    "    Y, svd_L, X = svd(np.concatenate([L, Ls]), full_matrices=False)\n",
    "\n",
    "    return svd_L\n",
    "\n",
    "def Loe_Analysis_Single(f, Z, REALFLAG = True):\n",
    "    '''==================================================\n",
    "        DRT Analysis\n",
    "        Parameter: \n",
    "            f:          real array of frequency values\n",
    "            Z:          complex array of impedance values (H = Z)\n",
    "            REALFLAG:   boolean flag to indicate if the model should have real entries\n",
    "        Returen:\n",
    "            R_i:        R_i from RC pair in DRT\n",
    "            tau_i:      tau_i from RC pair in DRT\n",
    "            H:          reconstructed impedance values\n",
    "            res_ReZ:    relative error of real part of impedance values\n",
    "            res_ImZ:    relative error of imaginary part of impedance values\n",
    "        ==================================================\n",
    "    '''\n",
    "    L, Ls, H_left, H_right = Loewner_Framework(f, Z, REALFLAG)\n",
    "    Ek, Ak, Bk, Ck = state_space_model(L, Ls, H_left, H_right)\n",
    "    R_i, C_i, tau_i = DRT_Transform(Ek, Ak, Bk, Ck, REALFLAG=True)\n",
    "    # H, res_ReZ, res_ImZ = DRT_Reconstruction_SSM(Ek, Ak, Bk, Ck, f, Z)\n",
    "    H, res_ReZ, res_ImZ = DRT_Reconstruction_DRT(R_i, tau_i, f, Z)\n",
    "\n",
    "    return R_i, C_i, tau_i, H, res_ReZ, res_ImZ\n",
    "    \n",
    "def Loe_Analysis_Batch(chData, REALFLAG = True):\n",
    "    '''==================================================\n",
    "        DRT Analysis for Batch Data\n",
    "        Parameter: \n",
    "            chData:     list of tuples (f, Z) for each channel\n",
    "            REALFLAG:   boolean flag to indicate if the model should have real entries\n",
    "        Returen:\n",
    "            results:    list of tuples (R_i, C_i, tau_i, H, res_ReZ, res_ImZ) for each channel\n",
    "        ==================================================\n",
    "    '''\n",
    "    DRTdata = []\n",
    "    f = chData[0,0,:]\n",
    "    for i in range(chData.shape[0]):\n",
    "        _Z = chData[i,1,:] + 1j*chData[i,2,:]\n",
    "        R_i, C_i, tau_i, _, _, _ = DRT_Analysis_Single(f, _Z, REALFLAG)\n",
    "        DRTdata.append((np.array([R_i, C_i, tau_i])))\n",
    "    return DRTdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1cd0e",
   "metadata": {},
   "source": [
    "## Tikhonov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "540e2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TikDRT(f, Z, RLC_Flag=[False, False, False], custom_lambda = None):\n",
    "    '''==================================================\n",
    "        Tikhonov DRT Deconvolution\n",
    "        Parameter: \n",
    "            f:  real array of frequency values\n",
    "            Z:  complex array of impedance values (H = Z)\n",
    "            ch_eis: 3 x n_freq Matrix: [freq, Real, Imag]\n",
    "        Returen:\n",
    "            tau_vec: time domain vector\n",
    "            x: DRT result\n",
    "            n_extend: number of extend RLC parameters\n",
    "        ==================================================\n",
    "    '''\n",
    "    ## Freq domain data prepare\n",
    "    \n",
    "    n_freq = len(f)\n",
    "    # freq_vec = f\n",
    "    # Z_exp = Z\n",
    "    freq_vec = np.flip(f)\n",
    "    Z_exp = np.flip(Z)\n",
    "\n",
    "    '''Hyper Parameters'''\n",
    "    # Time domain parameters\n",
    "    log_tau_min = np.log10(1/(2*np.pi*freq_vec[0]))  \n",
    "    log_tau_max = np.log10(1/(2*np.pi*freq_vec[-1])) \n",
    "    # log_tau_min = np.log10(1/(freq_vec[0]))  \n",
    "    # log_tau_max = np.log10(1/(freq_vec[-1]))   \n",
    "    n_tau = n_freq\n",
    "\n",
    "    # tau_vec = 1/(2*np.pi*freq_vec)\n",
    "    # tau_vec = 1/(2*np.pi*100*freq_vec)\n",
    "    # tau_vec = np.logspace(-4,4, n_tau, endpoint=True)\n",
    "    tau_vec = np.logspace(log_tau_min, log_tau_max, num = n_tau, endpoint=True)\n",
    "\n",
    "    # log_tau = np.log(tau_vec)\n",
    "    # tau_vec = np.logspace(-6, 0, n_tau, endpoint=True)\n",
    "    # freq_vec = np.flip(np.logspace(0, 6, n_freq, endpoint=True))\n",
    "    \n",
    "\n",
    "\n",
    "    # Discretization matrices Parameters\n",
    "    # Use RBF Kernel to initialize the A matrix\n",
    "    RBF_shape_control = 'FWHM Coefficient' \n",
    "    RBF_coeff = 0.5\n",
    "    # RBF_type = 'Piecewise Linear'\n",
    "    RBF_type = 'Gaussian'\n",
    "    # RBF_type = 'C0 Matern'\n",
    "    # RBF_type = 'C2 Matern'\n",
    "    # RBF_type = 'C4 Matern'\n",
    "    # RBF_type = 'C6 Matern'\n",
    "    # RBF_type = 'Inverse Quadratic'\n",
    "\n",
    "    # Cross-validation Method for optimize lambda (Tikhonov regularization parameter) \n",
    "    cv_type = 'GCV'     # Generalized Cross Validation\n",
    "    # cv_type = 'mGCV'    # Modified Generalized Cross Validation\n",
    "    # cv_type = 'rGCV'    # Robust Generalized Cross Validation\n",
    "    # cv_type = 'LC'      # L-curve\n",
    "    # cv_type = 're-im'   # Real-Imaginary discrepancy\n",
    "    # cv_type = 'kf'      # k-fold cross-validation\n",
    "\n",
    "    '''Compute the RBF Shape Parameter Epsilon'''\n",
    "    epsilon = drt.basics.compute_epsilon(freq_vec, RBF_coeff, RBF_type, RBF_shape_control)\n",
    "\n",
    "    # logger.info(f\"{epsilon}\")\n",
    "    # return\n",
    "    '''Compute the discretization matrices'''\n",
    "    A_re = drt.basics.assemble_A_re(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    n_extend = np.sum(RLC_Flag)   \n",
    "    if RLC_Flag[2]:\n",
    "        A_re_C_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_C_0, A_re)) \n",
    "    if RLC_Flag[1]:\n",
    "        A_re_L_0    = np.zeros((n_freq, 1)) \n",
    "        A_re        = np.hstack((A_re_L_0, A_re))\n",
    "    if RLC_Flag[0]:\n",
    "        A_re_R_inf  = np.ones((n_freq, 1))\n",
    "        A_re        = np.hstack((A_re_R_inf, A_re)) \n",
    "\n",
    "    A_im = drt.basics.assemble_A_im(freq_vec, tau_vec, epsilon, RBF_type)\n",
    "    if RLC_Flag[2]:\n",
    "        A_im_C_0    = -1/(2*np.pi*freq_vec.reshape(-1,1))\n",
    "        A_im        = np.hstack((A_im_C_0, A_im))\n",
    "    if RLC_Flag[1]:\n",
    "        A_im_L_0    = 2*np.pi*freq_vec.reshape(-1,1)\n",
    "        A_im        = np.hstack((A_im_L_0, A_im))\n",
    "    if RLC_Flag[0]:\n",
    "        A_im_R_inf  = np.zeros((n_freq, 1)) \n",
    "        A_im        = np.hstack((A_im_R_inf, A_im))\n",
    "\n",
    "    A = np.vstack((A_re, A_im))\n",
    "     \n",
    "\n",
    "\n",
    "    '''Compute the differentiation matrices for Tiknonov regularization'''\n",
    "    M2 = np.zeros((n_tau+n_extend, n_tau+n_extend))\n",
    "    M2[n_extend:,n_extend:] = drt.basics.assemble_M_2(tau_vec, epsilon, RBF_type)\n",
    "\n",
    "    '''Optimize lambda'''\n",
    "    if custom_lambda is None:\n",
    "        log_lambda_init = -3 # ln(lambda_init = 0.001)\n",
    "        # lambda_opt = drt.basics.optimal_lambda(A_re, A_im, np.real(Z_exp), np.imag(Z_exp), M2, \"Combined Re-Im Data\", RLC_Flag[1], log_lambda_init, cv_type)\n",
    "        lambda_opt = drt.basics.optimal_lambda(A_re, A_im, np.real(Z_exp), np.imag(Z_exp), M2, \"Combined Re-Im Data\", 0, log_lambda_init, cv_type)\n",
    "    else: \n",
    "        lambda_opt = custom_lambda\n",
    "    # logger.info(f\"Lambda: {lambda_opt}\")\n",
    "    '''Deconvolve The DRT from the EIS Data'''\n",
    "    # Set Bound Constraints\n",
    "    # lb = np.zeros([n_tau+n_extend])\n",
    "    # bound_mat = np.eye(lb.shape[0])\n",
    "    H_combined, c_combined = drt.basics.quad_format_combined(A_re, A_im, np.real(Z_exp), np.imag(Z_exp), M2, lambda_opt)\n",
    "    G = matrix(-np.identity(Z_exp.shape[0]+n_extend))\n",
    "    h = matrix(np.zeros(Z_exp.shape[0]+n_extend))\n",
    "\n",
    "\n",
    "    # Deconvolved DRT - Old\n",
    "    sol = solvers.qp(matrix(H_combined), matrix(c_combined), G, h)\n",
    "    x = np.array(sol['x'])\n",
    "\n",
    "    # Deconvolved DRT - New\n",
    "    # x_var = cp.Variable(H_combined.shape[0])\n",
    "    # objective = cp.Minimize(0.5 * cp.quad_form(x_var, H_combined) + c_combined.T @ x_var)\n",
    "    # constraints = [x_var >= 0]\n",
    "    # prob = cp.Problem(objective, constraints)\n",
    "    # prob.solve(solver=cp.ECOS, verbose=False,\n",
    "    #        abstol=1e-6, reltol=1e-6)\n",
    "\n",
    "    # x = x_var.value\n",
    "\n",
    "    # Output layer\n",
    "    H = A@x\n",
    "    H = H[:n_freq] + 1j*H[n_freq:]\n",
    "    H = np.flip(H).flatten()\n",
    "    R_i = x[n_extend:].flatten() / 2\n",
    "    C_i = tau_vec/R_i\n",
    "\n",
    "    return R_i, C_i, tau_vec, H, x[:n_extend].flatten(), lambda_opt\n",
    "\n",
    "\n",
    "\n",
    "def Tik_Analysis_Batch(chData, RLC_Flag=[False, False, False], custom_lambda = None):\n",
    "    '''==================================================\n",
    "        DRT Analysis for Batch Data\n",
    "        Parameter: \n",
    "            chData:     list of tuples (f, Z) for each channel\n",
    "            REALFLAG:   boolean flag to indicate if the model should have real entries\n",
    "        Returen:\n",
    "            results:    list of tuples (R_i, C_i, tau_i, H, res_ReZ, res_ImZ) for each channel\n",
    "        ==================================================\n",
    "    '''\n",
    "    DRTdata = []\n",
    "    H_list = []\n",
    "    f = chData[0,0,:]\n",
    "    for i in range(chData.shape[0]):\n",
    "        _Z = chData[i,1,:] + 1j*chData[i,2,:]\n",
    "        R_i, C_i, tau_i, H, _, _= TikDRT(f, _Z, RLC_Flag, custom_lambda)\n",
    "        DRTdata.append((np.array([R_i, C_i, tau_i])))\n",
    "        H_list.append(H)\n",
    "    return DRTdata, H_list\n",
    "\n",
    "def Tik_Res(Z, H):\n",
    "    '''==================================================\n",
    "        Reconstruct DRT from state space model\n",
    "        Parameter: \n",
    "            Z:  complex array of impedance values (H = Z)\n",
    "        Returen:\n",
    "            H:  reconstructed impedance values\n",
    "        ==================================================\n",
    "    '''\n",
    "    res_ReZ = np.abs(((Z.real - H.real) / np.abs(Z))) * 100\n",
    "    res_ImZ = np.abs(((Z.imag - H.imag) / np.abs(Z))) * 100\n",
    "\n",
    "    return res_ReZ, res_ImZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb2a64",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7b183904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DRT_Plot_Batch(DRTdata):\n",
    "\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    axis1 = fig.add_subplot(121)\n",
    "    axis2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "    cmap = plt.colormaps.get_cmap('rainbow_r')\n",
    "    for i in range(len(DRTdata)):\n",
    "        ch_drt = DRTdata[i]\n",
    "        _color = cmap(i/len(DRTdata))\n",
    "\n",
    "        axis1.plot(ch_drt[2,:], ch_drt[0,:], color=_color, linewidth=2, alpha=0.5)\n",
    "        axis2.plot(ch_drt[2,:], 1/ch_drt[1,:], color=_color, linewidth=2, alpha=0.5)\n",
    "\n",
    "    axis1.set_xscale('log')\n",
    "    axis1.set_yscale('log')\n",
    "    axis2.set_xscale('log')\n",
    "    axis2.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45951706",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d346f",
   "metadata": {},
   "source": [
    "## Monte-Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b85482a",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "25b685b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x219ba647bd0>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_TYPE = 'R-(R||C)-(R||C)'\n",
    "# ECM_TYPE = 'Randle'\n",
    "# ECM_TYPE = 'R-((R-Q)||Q)'\n",
    "# ECM_TYPE = 'R-((R-Q)||Q)-5000'\n",
    "\n",
    "\n",
    "if ECM_TYPE == 'R-(R||C)-(R||C)':\n",
    "    # Element\n",
    "    R1 = 200; # Ω\n",
    "    R2 = 100; # Ω\n",
    "    R0 = 70;  # Ω\n",
    "\n",
    "    C1 = 2.5e-3; # \n",
    "    C2 = 1e-4;   # \n",
    "\n",
    "    # tau1 = R1*C1;  # s\n",
    "    # tau2 = R2*C2;  # s\n",
    "\n",
    "    f = np.logspace(-2,2,41);  # Hz\n",
    "\n",
    "    # Calculation of the impedance dataset \n",
    "    Z_sim = np.array([1/((1/R1)+1j*w*C1) +1/((1/R2)+1j*w*C2) +R0 for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "elif ECM_TYPE == 'Randle':\n",
    "    R0 = 70\n",
    "\n",
    "    R1 = 10000 \n",
    "    C1 = 2.5e-9\n",
    "\n",
    "    Y1 = 1e-5 \n",
    "    \n",
    "    n1 = 0.66\n",
    "    f = np.logspace(-1,5,61);  # Hz \n",
    "\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Z_sim = np.array([ R0 + (R1+Q1(w))/(1+1j*w*C1*(R1+Q1(w))) for w in 2*np.pi*f])\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.01, Z_sim.shape) * Z_sim\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "        \n",
    "elif ECM_TYPE == 'R-((R-Q)||Q)':\n",
    "    R0 = 70\n",
    "\n",
    "    R1 = 50000 \n",
    "    \n",
    "    Y1 = 1e-8\n",
    "    n1 = 0.8\n",
    "    \n",
    "    Y2 = 1e-5 \n",
    "    n2 = 0.66\n",
    "\n",
    "    f = np.logspace(-1,5,61);  # Hz \n",
    "\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Q2 = lambda x: 1/(Y2*(1j*x)**n2)\n",
    "\n",
    "    Z_sim = np.array([ R0 + (1/(1/(R1+Q2(w)) + 1/(Q1(w)))) for w in 2*np.pi*f])\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.01, Z_sim.shape) * Z_sim\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "elif ECM_TYPE == 'R-((R-Q)||Q)-5000':\n",
    "    R0 = 70\n",
    "\n",
    "    R1 = 50000 \n",
    "    \n",
    "    Y1 = 1e-8\n",
    "    n1 = 0.8\n",
    "    \n",
    "    Y2 = 1e-5 \n",
    "    n2 = 0.66\n",
    "\n",
    "    f = np.logspace(-1,5,5000);  # Hz \n",
    "\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Q2 = lambda x: 1/(Y2*(1j*x)**n2)\n",
    "\n",
    "    Z_sim = np.array([ R0 + (1/(1/(R1+Q2(w)) + 1/(Q1(w)))) for w in 2*np.pi*f])\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.01, Z_sim.shape) * Z_sim\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Z_sim.real, -Z_sim.imag, label='Simulated Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6258091",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f220b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if f.shape[0] < 1000:\n",
    "    # R_i, C_i, tau_i, H, res_ReZ, res_ImZ = Loe_Analysis_Single(f, Z_sim, REALFLAG=True)\n",
    "    # svd_L = Loe_singularity_analysis(f, Z_sim, REALFLAG=True)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.loglog(tau_i,R_i, '.')\n",
    "\n",
    "\n",
    "    _n_noise = 100\n",
    "    _drt_noise = []\n",
    "\n",
    "    Z_org = Z_sim\n",
    "    # Z_org = Z_sim_noise\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axis = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(_n_noise):\n",
    "        _Z_noise = Z_org + np.random.normal(0, 0.0001, Z_org.shape) * Z_org.real + np.random.normal(0, 0.0001, Z_org.shape) * Z_org.imag\n",
    "        \n",
    "        _R_i, _C_i, _tau_i, _, _, _ = Loe_Analysis_Single(f, _Z_noise, REALFLAG=True)\n",
    "        _drt_noise.append(np.array([_R_i, _C_i, _tau_i]))\n",
    "        # axis.scatter(_tau_i[1:-1],_R_i[1:-1], s=1, color='blue')\n",
    "        # axis.scatter(_tau_i[1:-1],_R_i[1:-1]*_R_i.shape[0], s=1,color='red')\n",
    "        plt.loglog(_tau_i,_R_i, '.',color='gray')\n",
    "        plt.loglog(_tau_i,_R_i*_R_i.shape[0], '.',color='gray')\n",
    "\n",
    "\n",
    "        \n",
    "    _R_i, _C_i, _tau_i, _, _, _ = Loe_Analysis_Single(f, Z_org, REALFLAG=True)\n",
    "    _drt_noise.append(np.array([_R_i, _C_i, _tau_i]))\n",
    "    # axis.scatter(_tau_i,_R_i, color='red')\n",
    "    # axis.scatter(_tau_i,_R_i*R_i.shape[0], color='red')\n",
    "\n",
    "    axis.set_xscale('log')\n",
    "    axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d117a1",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40599e7",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e62e6bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '((R-(C1||W)) || C2)-5000')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECM_TYPE = 'R-(R||C)-(R||C)'\n",
    "# ECM_TYPE = 'R-((R-C))||C)'\n",
    "# ECM_TYPE = 'Randle'\n",
    "# ECM_TYPE = 'R-((R-Q2)||Q1)-5000'\n",
    "# ECM_TYPE = 'R-(Q1 || (R-W))-5000'\n",
    "# ECM_TYPE = 'C-R-(Q1 || (R-W))-5000'\n",
    "ECM_TYPE = '((R-(C1||W)) || C2)-5000'\n",
    "# ECM_TYPE = 'C-R-W'\n",
    "# ECM_TYPE = 'C-R-Q'\n",
    "# ECM_TYPE = 'C-R-(W||C1)'\n",
    "# ECM_TYPE = 'C||(R-(W||C1))'\n",
    "# ECM_TYPE = '(R-(R||Q))||R||Q)'\n",
    "\n",
    "\n",
    "if ECM_TYPE == 'R-(R||C)-(R||C)':\n",
    "    # Element\n",
    "    R1 = 200; # Ω\n",
    "    R2 = 100; # Ω\n",
    "    R0 = 70;  # Ω\n",
    "\n",
    "    C1 = 2.5e-3; # \n",
    "    C2 = 1e-4;   # \n",
    "\n",
    "    # tau1 = R1*C1;  # s\n",
    "    # tau2 = R2*C2;  # s\n",
    "\n",
    "    f = np.logspace(0,8,5000);  # Hz\n",
    "\n",
    "    # Calculation of the impedance dataset \n",
    "    Z_sim = np.array([1/((1/R1)+1j*w*C1) +1/((1/R2)+1j*w*C2) +R0 for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "elif ECM_TYPE == 'R-((R-C))||C)':\n",
    "    # Element\n",
    "    R1 = 20000; # Ω\n",
    "    R0 = 100;  # Ω\n",
    "\n",
    "    C1 = 2.5e-3; # \n",
    "    C2 = 1e-4;   # \n",
    "\n",
    "    # tau1 = R1*C1;  # s\n",
    "    # tau2 = R2*C2;  # s\n",
    "\n",
    "    f = np.logspace(-2,2,5000);  # Hz\n",
    "\n",
    "    Q1 = lambda x: 1/(C1*1j*x)\n",
    "    Q2 = lambda x: 1/(C2*1j*x)\n",
    "\n",
    "    # Calculation of the impedance dataset \n",
    "    # Z_sim = np.array([1/(1/Q1(w) + 1/(R1+Q2(w))) +R0 for w in 2*np.pi*f])\n",
    "    Z_sim = np.array([1/(1/Q1(w) + 1/(R1+Q2(w))) for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "\n",
    "elif ECM_TYPE == 'R-((R-Q2)||Q1)-5000':\n",
    "    R0 = 1000\n",
    "\n",
    "    R1 = 10000\n",
    "    \n",
    "    Y1 = 1e-9\n",
    "    n1 = 1\n",
    "    \n",
    "    Y2 = 1e-5\n",
    "    n2 = 0.6\n",
    "\n",
    "    f = np.logspace(0,6,5000);  # Hz \n",
    "\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Q2 = lambda x: 1/(Y2*(1j*x)**n2)\n",
    "\n",
    "    Z_sim = np.array([ R0 + (1/(1/(R1+Q2(w)) + 1/(Q1(w)))) for w in 2*np.pi*f])\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.01, Z_sim.shape) * Z_sim\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "elif ECM_TYPE == '((R-(C1||W)) || C2)-5000':\n",
    "    R0 = 1000\n",
    "\n",
    "    C1 = 1e-8\n",
    "    C2 = 1e-10\n",
    "\n",
    "    \n",
    "    WR = 1e5\n",
    "    WT = 1e-3\n",
    "    n2 = 0.6\n",
    "\n",
    "    f = np.logspace(0,8,5000);  # Hz \n",
    "\n",
    "    W1 = lambda x: WR/((WT*1j*x)**n2)\n",
    "    Q1 = lambda x: 1/(C1*(1j*x))\n",
    "    Q2 = lambda x: 1/(C2*(1j*x))\n",
    "\n",
    "    Z_sim = np.array([ 1/( 1/Q2(w) + 1/( R0+ 1/(1/Q1(w)+1/W1(w)) ) ) for w in 2*np.pi*f])\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.01, Z_sim.shape) * Z_sim\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "elif ECM_TYPE == 'R-(Q1 || (R-W))-5000':\n",
    "    R0 = 1000\n",
    "\n",
    "    R1 = 1e5\n",
    "    \n",
    "    Y1 = 1e-10\n",
    "    n1 = 0.9\n",
    "    \n",
    "    WR = 100\n",
    "    WT = 1e-7\n",
    "    n2 = 0.6\n",
    "\n",
    "    f = np.logspace(-5,6,5000);  # Hz \n",
    "\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Q2 = lambda x: WR/((1j*x*WT)**n2)\n",
    "\n",
    "    Z_sim = np.array([ R0 + (1/(1/(R1+Q2(w)) + 1/(Q1(w)))) for w in 2*np.pi*f])\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.01, Z_sim.shape) * Z_sim\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "elif ECM_TYPE == 'C-R-(Q1 || (R-W))-5000':\n",
    "    R0 = 1000\n",
    "    C0 = 1e-7\n",
    "\n",
    "    R1 = 1e5\n",
    "    \n",
    "    Y1 = 1e-10\n",
    "    n1 = 0.9\n",
    "    \n",
    "    WR = 100\n",
    "    WT = 1e-7\n",
    "    n2 = 0.6\n",
    "\n",
    "    f = np.logspace(0,6,5000);  # Hz \n",
    "\n",
    "    Q0 = lambda x: 1/((1j*x*C0))\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Q2 = lambda x: WR/((1j*x*WT)**n2)\n",
    "\n",
    "    Z_sim = np.array([ Q0(w)+R0 + (1/(1/(R1+Q2(w)) + 1/(Q1(w)))) for w in 2*np.pi*f])\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.01, Z_sim.shape) * Z_sim\n",
    "    # Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 1e-2, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 1e-2, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "elif ECM_TYPE == 'C-R-W':    \n",
    "    R0 = 1000\n",
    "    C0 = 1e-7\n",
    "\n",
    "    \n",
    "    WR = 100\n",
    "    WT = 1e-1\n",
    "    n1 = 0.5\n",
    "\n",
    "\n",
    "    WR2 = 10000\n",
    "    WT2 = 1e-3\n",
    "    n2 = 0.1\n",
    "\n",
    "    f = np.logspace(0,6,5000);  # Hz \n",
    "\n",
    "    Q0 = lambda x: 1/((1j*x*C0))\n",
    "    Q1 = lambda x: WR/((1j*x*WT)**n1)\n",
    "    Q2 = lambda x: WR/((1j*x*WT2)**n2)\n",
    "\n",
    "    # Z_sim = np.array([ Q0(w)+R0 +Q1(w) +Q2(w)  for w in 2*np.pi*f])\n",
    "    Z_sim = np.array([ R0 +Q1(w) +Q2(w)  for w in 2*np.pi*f])\n",
    "    # Z_sim = np.array([ Q0(w)+R0 +Q1(w)  for w in 2*np.pi*f])\n",
    "    # Z_sim = np.array([ Q0(w)+R0   for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "elif ECM_TYPE == 'C-R-Q':    \n",
    "    R0 = 1000\n",
    "    C0 = 1e-7\n",
    "\n",
    "    Y1 = 1e-10\n",
    "    n1 = 0.9\n",
    "\n",
    "\n",
    "    Y2 = 1e-5\n",
    "    n2 = 0.1\n",
    "\n",
    "    f = np.logspace(0,6,5000);  # Hz \n",
    "\n",
    "    Q0 = lambda x: 1/((1j*x*C0))\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Q2 = lambda x: 1/(Y2*(1j*x)**n2)\n",
    "\n",
    "    # Z_sim = np.array([ Q0(w)+R0 +Q1(w) +Q2(w)  for w in 2*np.pi*f])\n",
    "    Z_sim = np.array([ Q0(w)+R0 +Q1(w)  for w in 2*np.pi*f])\n",
    "    # Z_sim = np.array([ Q0(w)+R0   for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "elif ECM_TYPE == 'C-R-(W||C1)':    \n",
    "    R0 = 1000\n",
    "    C0 = 1e-7\n",
    "    C1 = 1e-10\n",
    "    \n",
    "    WR = 1000000\n",
    "    WT = 1e-1\n",
    "    n1 = 0.1\n",
    "\n",
    "\n",
    "    f = np.logspace(0,6,5000);  # Hz \n",
    "\n",
    "    Q0 = lambda x: 1/((1j*x*C0))\n",
    "    Q1 = lambda x: 1/((1j*x*C1))\n",
    "    Q2 = lambda x: WR/((1j*x*WT)**n1)\n",
    "\n",
    "    Z_sim = np.array([ Q0(w)+R0 +(1/(1/Q1(w)+1/Q2(w))) for w in 2*np.pi*f])\n",
    "    # Z_sim = np.array([ Q0(w)+R0 +Q1(w)  for w in 2*np.pi*f])\n",
    "    # Z_sim = np.array([ Q0(w)+R0   for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "elif ECM_TYPE == 'C||(R-(W||C1))':    \n",
    "    R0 = 1000\n",
    "    C0 = 9e-11\n",
    "    C1 = 7e-9\n",
    "    \n",
    "    WR = 1e3\n",
    "    WT = 1e-2\n",
    "    n1 = 0.30\n",
    "\n",
    "\n",
    "    f = np.logspace(0,8,5000);  # Hz \n",
    "\n",
    "    Q0 = lambda x: 1/((1j*x*C0))\n",
    "    Q1 = lambda x: 1/((1j*x*C1))\n",
    "    Q2 = lambda x: WR/((1j*x*WT)**n1)\n",
    "\n",
    "    Z_sim = np.array([ 1/(1/Q0(w) + 1/(R0 + 1/(1/Q1(w)+1/Q2(w)))) for w in 2*np.pi*f])\n",
    "\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "elif ECM_TYPE == '(R-(R||Q))||R||Q)':    \n",
    "    R0 = 1000\n",
    "    R1 = 1e4\n",
    "    R2 = 1e6\n",
    "\n",
    "    Y1 = 1e-10\n",
    "    n1 = 0.9\n",
    "\n",
    "\n",
    "    Y2 = 1e-11\n",
    "    n2 = 0.9\n",
    "\n",
    "    f = np.logspace(0,6,5000);  # Hz \n",
    "\n",
    "    Q0 = lambda x: 1/((1j*x*C0))\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "    Q2 = lambda x: 1/(Y2*(1j*x)**n2)\n",
    "\n",
    "    # Z_sim = np.array([ Q0(w)+R0 +Q1(w) +Q2(w)  for w in 2*np.pi*f])\n",
    "    Z_sim = np.array([ 1/(1/(R0+1/(1/R1+1/Q1(w)) + 1/R2 + 1/Q2(w)  ))  for w in 2*np.pi*f])\n",
    "    # Z_sim = np.array([ Q0(w)+R0   for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, 0.001, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Z_sim.real, -Z_sim.imag, label='Simulated Data')\n",
    "# plt.loglog(f, np.abs(Z_sim), label='Ampletude')\n",
    "# plt.semilogx(f, np.angle(Z_sim)*180/np.pi, label='Ampletude')\n",
    "# plt.plot((1/Z_sim).real, (1/Z_sim).imag, label='Simulated Data')\n",
    "plt.title(ECM_TYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1aeaf775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = np.array([1, 1e40])\n",
    "# # Z_sim = np.array([ 1/( 1/Q2(w) + 1/( R0+ 1/(1/Q1(w)+1/W1(w)) ) ) for w in 2*np.pi*f])\n",
    "# # Z_sim = np.array([ R0 + (1/(1/(R1+Q2(w)) + 1/(Q1(w)))) for w in 2*np.pi*f])\n",
    "# # Z_sim = np.array([ Q0(w)+R0 + (1/(1/(R1+Q2(w)) + 1/(Q1(w)))) for w in 2*np.pi*f])\n",
    "# pc = 1/Z_sim[0].imag/(2*np.pi*f[0])\n",
    "# pc\n",
    "\n",
    "# _C_nf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8c0e9",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b637c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_subsample(total_size, n_subsample, idx_base=1000, seed=None):\n",
    "    \"\"\"\n",
    "    将 total_size 个点均匀分成 n_subsample 段，每段随机取 1 个索引，无放回采样。\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    indices = np.arange(idx_base, total_size)\n",
    "    bins = np.array_split(indices, n_subsample)\n",
    "    sampled_indices = [np.random.choice(bin, 1)[0] for bin in bins]\n",
    "    \n",
    "    return np.array(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d48a190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Z_org = Z_sim\n",
    "Z_org = Z_sim_noise\n",
    "\n",
    "_f = f\n",
    "_Z = Z_org\n",
    "\n",
    "\n",
    "\n",
    "n_batch = 100\n",
    "n_point = 100\n",
    "\n",
    "_f_bootstrap = []\n",
    "_Z_bootstrap = []\n",
    "\n",
    "_Z_bootstrap_nf = []\n",
    "for i in range(n_batch):\n",
    "    _idx = stratified_subsample(_f.shape[0], n_point, idx_base=1000)\n",
    "    # _idx[0] = 1000\n",
    "    # _idx[-1] = _f.shape[0]-1\n",
    "\n",
    "    _f_bootstrap.append(_f[_idx])\n",
    "    _Z_bootstrap.append(_Z[_idx])\n",
    "    _Z_bootstrap_nf.append(Z_sim[_idx])\n",
    "\n",
    "_f = np.stack(_f_bootstrap, axis=0)\n",
    "_Z = np.stack(_Z_bootstrap, axis=0)\n",
    "_Z_nf = np.stack(_Z_bootstrap_nf, axis=0)\n",
    "\n",
    "if False:\n",
    "    plt.figure()\n",
    "    for i in range(_f.shape[0]):\n",
    "        plt.loglog(_f[i,:], np.abs(_Z[i,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f1c8442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=5.59352e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.14387e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.72576e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.20031e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.76851e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=1.37334e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.92497e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.49722e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.40606e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.79052e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.27018e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.42316e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=1.9374e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.5808e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.0119e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.82356e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=7.25295e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.36254e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.09729e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.88918e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.86609e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.39137e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.18946e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.5628e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.5021e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.38019e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=1.83673e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.41929e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.75173e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.45093e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=1.85969e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.49825e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=5.37098e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.86023e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=6.58703e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.28635e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.83389e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.96625e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.66443e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.94035e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.27353e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.36508e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.63708e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=7.52832e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.77008e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.16702e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.77272e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.77649e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.58097e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.00192e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.80892e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=6.76237e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.52718e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=8.73999e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=6.4134e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.60626e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.84716e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.89443e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.54781e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.61324e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.72413e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.34747e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=5.7811e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.22715e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.65652e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.03983e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=6.19202e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.87199e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.48019e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=6.44234e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.22595e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.44224e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.67845e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.13993e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.01256e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=5.9422e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.5752e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.91997e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.57181e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.01343e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=8.04481e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=6.20709e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.41309e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.6192e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.10112e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.19391e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=7.11765e-18): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.58806e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.48104e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=9.50079e-18): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.29666e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.74508e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.16525e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.31524e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=4.74512e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=9.84473e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=1.88362e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=2.58176e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=6.3756e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n",
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\129456308.py:102: LinAlgWarning: Ill-conditioned matrix (rcond=3.54917e-17): result may not be accurate.\n",
      "  wB = solve(_U, solve(Ek,Bk))\n"
     ]
    }
   ],
   "source": [
    "_drt_list = []\n",
    "_nf_list = []\n",
    "\n",
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(131)\n",
    "axis2 = fig.add_subplot(132)\n",
    "axis3 = fig.add_subplot(133)\n",
    "for i in range(_f.shape[0]):\n",
    "    # if i <20: continue\n",
    "    _R_i, _C_i, _tau_i, _, _, _ = Loe_Analysis_Single(_f[i,:], _Z[i,:], REALFLAG=True)\n",
    "    _R_nf, _C_nf, _tau_nf, _, _, _ = Loe_Analysis_Single(_f[i,:], _Z_nf[i,:], REALFLAG=True)\n",
    "    _drt_list.append(np.array([_R_i, _C_i, _tau_i]))\n",
    "    _nf_list.append(np.array([_R_nf, _C_nf, _tau_nf]))\n",
    "\n",
    "    # R_0 = _R_i[0]\n",
    "    # C_0 = _C_i[-1]\n",
    "    # Z_cal = _Z[i,:] - R_0 - 1/(2j*np.pi*_f[i,:]*C_0)\n",
    "    # _R_cal, _C_cal, _tau_cal, _, _, _ = Loe_Analysis_Single(_f[i,:], Z_cal, REALFLAG=True)\n",
    "\n",
    "\n",
    "\n",
    "    # axis.scatter(_tau_i,_R_i, s=2, color = 'gray')\n",
    "    # axis.scatter(_R_i, _C_i, s=2, color = 'gray')\n",
    "    # axis.scatter(_tau_i[0],_R_i[0], s=2)\n",
    "    # axis.scatter(_tau_i[0],_R_i[0]*_R_i.shape[0], s=2)\n",
    "\n",
    "    ## Last Point Discuss\n",
    "    # axis.scatter(_tau_i[1:-4],_R_i[1:-4], s=2, color = 'gray')\n",
    "    # axis.scatter(_tau_i[0],_R_i[0], s=2, color = 'red')\n",
    "    # axis.scatter(_tau_i[-4],_R_i[-4], s=2, color='blue')\n",
    "    # axis.scatter(_tau_i[-3],_R_i[-3], s=2, color='green')\n",
    "    # axis.scatter(_tau_i[-2],_R_i[-2], s=2, color='orange')\n",
    "    # axis.scatter(_tau_i[-1],_R_i[-1], s=2, color='red')\n",
    "\n",
    "    ## Order Correction Discuss - Conclusion: correction should NOT be applied here\n",
    "    # axis.scatter(_tau_i[1:-10],_R_i[1:-10], s=2, color='red')\n",
    "    # axis.scatter(_tau_i[1:-10],_R_i[1:-10]*_R_i.shape[0], s=2, color='blue')\n",
    "\n",
    "    # R or C\n",
    "    axis.scatter(_R_i[1:]*_C_i[1:], _R_i[1:], s=2, color = 'gray')\n",
    "    axis.scatter(_R_i[0]*_C_i[0], _R_i[0], s=2, color = 'orange')\n",
    "    axis.scatter(_R_nf[:]*_C_nf[:], _R_nf[:], s=10, color = 'blue')\n",
    "    # axis.vlines(1/2/np.pi/f[0], np.min(_R_nf[:]), np.max(_R_nf[:]))\n",
    "    # axis.vlines(1/2/np.pi/f[-1], np.min(_R_nf[:]), np.max(_R_nf[:]))\n",
    "\n",
    "\n",
    "    # axis.scatter(_R_i[1:]*_C_i[1:], 1/_C_i[1:], s=2, color = 'gray')\n",
    "    # axis.scatter(_R_i[0]*_C_i[0], 1/_C_i[0], s=2, color = 'orange')\n",
    "    # axis.scatter(_R_nf[:]*_C_nf[:], 1/_C_nf[:], s=2, color = 'blue')\n",
    "    # axis.vlines(1/2/np.pi/f[0], np.min(1/_C_nf[:]), np.max(1/_C_nf[:]))\n",
    "    # axis.vlines(1/2/np.pi/f[-1], np.min(1/_C_nf[:]), np.max(1/_C_nf[:]))\n",
    "\n",
    "\n",
    "\n",
    "    # ## RC Discussion\n",
    "    axis2.scatter(_R_i[1:-1], _C_i[1:-1], s=2, color = 'gray')\n",
    "    axis2.scatter(_R_i[-1], _C_i[-1], s=2, color = 'red')\n",
    "    axis2.scatter(_R_i[0], _C_i[0], s=2, color = 'orange')\n",
    "    axis2.scatter(_R_nf[:], _C_nf[:], s=10, color = 'blue')\n",
    "\n",
    "\n",
    "    ## R/C Discussion\n",
    "    # axis.scatter(_R_i[1:-1]*_C_i[1:-1], _R_i[1:-1]/_C_i[1:-1], s=2, color = 'gray')\n",
    "    # axis.scatter(_R_i[-1]*_C_i[-1], _R_i[-1]/_C_i[-1], s=2, color = 'red')\n",
    "    # axis.scatter(_R_i[0]*_C_i[0], _R_i[0]/_C_i[0], s=2, color = 'orange')\n",
    "    # axis.scatter(_R_nf[:]*_C_nf[:], _R_nf[:]/_C_nf[:], s=2, color = 'blue')\n",
    "    \n",
    "\n",
    "    ## R/C/(x+1/x)\n",
    "    _tt = _R_i[:]*_C_i[:]\n",
    "    _yy = _R_i[:] / _C_i[:]\n",
    "    # _yy = _yy / (((_tt/1e0)**-1) + ((_tt/1e0)**1))\n",
    "    # _yy = _yy / (((_tt/1e-4)**-1) + ((_tt/1e-4)**1))\n",
    "    _yy = _yy / (((_tt/1e6)**-1) + ((_tt/1e-14)**1))\n",
    "    axis3.scatter(_tt[1:-1], _yy[1:-1], s=2, color = 'gray')\n",
    "    axis3.scatter(_tt[-1], _yy[-1], s=2, color = 'red')\n",
    "    axis3.scatter(_tt[0], _yy[0], s=2, color = 'orange')\n",
    "\n",
    "\n",
    "\n",
    "    _tt = _R_nf[:]*_C_nf[:]\n",
    "    _yy = _R_nf[:] / _C_nf[:]\n",
    "    # _yy = _yy / (((_tt/1e0)**-1) + ((_tt/1e0)**1))\n",
    "    # _yy = _yy / (((_tt/1e-4)**-1) + ((_tt/1e-4)**1))\n",
    "    # _yy = _yy / (((_tt/_R_nf[0]/_R_nf[0])**-1) + ((_tt/_C_nf[-1]/_C_nf[-1])**1))\n",
    "    _yy = _yy / (((_tt/1e6)**-1) + ((_tt/1e-14)**1))\n",
    "    axis3.scatter(_tt[1:-1], _yy[1:-1], s=2, color = 'blue')\n",
    "    axis3.scatter(_tt[-1], _yy[-1], s=2, color = 'blue')\n",
    "    axis3.scatter(_tt[0], _yy[0], s=2, color = 'blue')\n",
    "\n",
    "\n",
    "    # axis.scatter(_tt, (((_tt/1e-4)**-1) + ((_tt/1e-4)**1)), s=2, color = 'orange')\n",
    "    # axis.scatter(_tt, (((_tt/1e-2)**-1) + ((_tt/1e-6)**1)), s=2, color = 'red')\n",
    "    # axis.scatter(_tt, (((_tt/1e-6)**-1) + ((_tt/1e-2)**1)), s=2, color = 'red')\n",
    "    \n",
    "\n",
    "\n",
    "# axis.set_xlim([1e-10,1e2])\n",
    "# axis.set_ylim([1e0,1e10])\n",
    "axis.set_xscale('log')\n",
    "axis.set_yscale('log')\n",
    "axis.set_aspect('equal')\n",
    "\n",
    "axis2.set_xscale('log')\n",
    "axis2.set_yscale('log')\n",
    "axis2.set_aspect('equal')\n",
    "\n",
    "axis3.set_xscale('log')\n",
    "axis3.set_yscale('log')\n",
    "axis3.set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "03075516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(692.7023368268835)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_R_list = np.array([i[0,0] for i in _drt_list])\n",
    "_R_para = 1/np.sum(1/_R_list)\n",
    "np.mean(_R_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d015f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.105692229683039e-08\n",
      "982.5200505394247\n"
     ]
    }
   ],
   "source": [
    "print(_C_i[-1])\n",
    "print(_R_i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecbaa0",
   "metadata": {},
   "source": [
    "## Theoretical CPE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29fdc75",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "e3bf512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECM_TYPE = 'R-(R||Q)'\n",
    "\n",
    "if  ECM_TYPE == 'R-(R||Q)':    \n",
    "    R0 = 0\n",
    "    C0 = 1e-7\n",
    "\n",
    "    \n",
    "    # R1 = 10000\n",
    "    # Y1 = 5e-8\n",
    "    # n1 = 0.9\n",
    "\n",
    "    \n",
    "    R1 = 10000\n",
    "    Y1 = 1e-6\n",
    "    n1 = 0.5\n",
    "\n",
    "\n",
    "    f = np.logspace(0,6,5000);  # Hz \n",
    "\n",
    "    Q0 = lambda x: 1/((1j*x*C0))\n",
    "    Q1 = lambda x: 1/(Y1*(1j*x)**n1)\n",
    "\n",
    "\n",
    "    noise_level = 1e-3\n",
    "    Z_sim = np.array([ R0 + (1/(1/R1 + 1/Q1(w)))  for w in 2*np.pi*f])\n",
    "    # Z_sim = np.array([ R0 + Q0(w) + (1/(1/R1 + 1/Q1(w)))  for w in 2*np.pi*f])\n",
    "    Z_sim_noise = Z_sim + np.random.normal(0, noise_level, Z_sim.shape) * Z_sim.real + 1j*np.random.normal(0, noise_level, Z_sim.shape) * Z_sim.imag\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "    plt.figure()\n",
    "    plt.plot(Z_sim.real, -Z_sim.imag, label='Simulated Data')\n",
    "    # plt.plot((1/Z_sim).real, (1/Z_sim).imag, label='Simulated Data')\n",
    "    plt.title(ECM_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d9a27332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_subsample(total_size, n_subsample, idx_base=1000, seed=None):\n",
    "    \"\"\"\n",
    "    将 total_size 个点均匀分成 n_subsample 段，每段随机取 1 个索引，无放回采样。\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    indices = np.arange(idx_base, total_size)\n",
    "    bins = np.array_split(indices, n_subsample)\n",
    "    sampled_indices = [np.random.choice(bin, 1)[0] for bin in bins]\n",
    "    \n",
    "    return np.array(sampled_indices)\n",
    "\n",
    "# Z_org = Z_sim\n",
    "Z_org = Z_sim_noise\n",
    "\n",
    "_f = f\n",
    "_Z = Z_org\n",
    "\n",
    "\n",
    "\n",
    "n_batch = 100\n",
    "n_point = 100\n",
    "\n",
    "_f_bootstrap = []\n",
    "_Z_bootstrap = []\n",
    "\n",
    "_Z_bootstrap_nf = []\n",
    "for i in range(n_batch):\n",
    "    # _idx = stratified_subsample(_f.shape[0], n_point, idx_base=1000)\n",
    "    _idx = stratified_subsample(_f.shape[0], n_point, idx_base=0)\n",
    "    # _idx[0] = 1000\n",
    "    # _idx[-1] = _f.shape[0]-1\n",
    "\n",
    "    _f_bootstrap.append(_f[_idx])\n",
    "    _Z_bootstrap.append(_Z[_idx])\n",
    "    _Z_bootstrap_nf.append(Z_sim[_idx])\n",
    "\n",
    "_f = np.stack(_f_bootstrap, axis=0)\n",
    "_Z = np.stack(_Z_bootstrap, axis=0)\n",
    "_Z_nf = np.stack(_Z_bootstrap_nf, axis=0)\n",
    "\n",
    "if False:\n",
    "    plt.figure()\n",
    "    for i in range(_f.shape[0]):\n",
    "        plt.loglog(_f[i,:], np.abs(_Z[i,:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604d6c8",
   "metadata": {},
   "source": [
    "### From PDF to Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa89e18",
   "metadata": {},
   "source": [
    "\n",
    "尝试了很多方法，包括用quad算G积分，用G不定积分解析式F计算G积分，均匀采样或者不均匀采样，都可以！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "146b70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def log_uniform_weights_from_F(xi, F):\n",
    "    \"\"\"\n",
    "    xi: log10均匀采样点 (e.g. np.logspace(-3, 3, 100))\n",
    "    F: 核函数 G(x) 的不定积分函数 (callable)\n",
    "    return: 每个 xi 对应的积分区间的权重 yi\n",
    "    \"\"\"\n",
    "    log_xi = np.log10(xi)\n",
    "    delta_log = log_xi[1] - log_xi[0]  # 等间距\n",
    "    log_edges = np.concatenate([\n",
    "        [log_xi[0] - delta_log / 2],\n",
    "        (log_xi[:-1] + log_xi[1:]) / 2,\n",
    "        [log_xi[-1] + delta_log / 2]\n",
    "    ])\n",
    "    x_edges = 10**log_edges\n",
    "    yi = F(x_edges[1:]) - F(x_edges[:-1])\n",
    "    return yi\n",
    "\n",
    "\n",
    "\n",
    "def nonuniform_weights_from_Fx(xi, F):\n",
    "    \"\"\"\n",
    "    xi: 非等距采样点，必须单调递增\n",
    "    F: 不定积分函数\n",
    "    return: 每个 xi 的积分权重 yi\n",
    "    \"\"\"\n",
    "    xi = np.log(xi)\n",
    "    x_edges = np.zeros(len(xi)+1)\n",
    "    x_edges[1:-1] = (xi[:-1] + xi[1:]) / 2\n",
    "    x_edges[0] = xi[0] - (xi[1] - xi[0]) / 2\n",
    "    x_edges[-1] = xi[-1] + (xi[-1] - xi[-2]) / 2\n",
    "    yi = F(x_edges[1:]) - F(x_edges[:-1])\n",
    "    return yi\n",
    "\n",
    "def nonuniform_weights_from_Gx(xi, G):\n",
    "    \"\"\"\n",
    "    xi: 非等距采样点，必须单调递增\n",
    "    F: 不定积分函数\n",
    "    return: 每个 xi 的积分权重 yi\n",
    "    \"\"\"\n",
    "    xi = np.log(xi)\n",
    "    x_edges = np.zeros(len(xi)+1)\n",
    "    x_edges[1:-1] = (xi[:-1] + xi[1:]) / 2\n",
    "    x_edges[0] = xi[0] - (xi[1] - xi[0]) / 2\n",
    "    x_edges[-1] = xi[-1] + (xi[-1] - xi[-2]) / 2\n",
    "    yi = np.array([quad(G, x_edges[i], x_edges[i+1])[0] for i in range(xi.shape[0])])\n",
    "    return yi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_drt_list = []\n",
    "_nf_list = []\n",
    "\n",
    "_theo_den_list = []\n",
    "_theo_list = []\n",
    "_theo_list_G = []\n",
    "_theo_uni_list = []\n",
    "\n",
    "_theo_non_drt = []\n",
    "_theo_uni_drt = []\n",
    "\n",
    "\n",
    "\n",
    "t0 = np.power(R1*Y1, 1/n1)\n",
    "\n",
    "\n",
    "CPE_G1 = lambda x: np.sin(n1*np.pi) / (np.cosh(n1*(x-np.log(t0))) + np.cos(n1*np.pi)) /2/np.pi\n",
    "CPE_G2 = lambda t: np.sin(n1*np.pi) / (np.cosh(n1*(np.log(t/t0))) + np.cos(n1*np.pi)) /2/np.pi\n",
    "CPE_F1 = lambda x: np.arctan(np.tan(n1*np.pi/2) * np.tanh(n1/2*(x-np.log(t0)))) /np.pi/n1\n",
    "CPE_F2 = lambda t: np.arctan(np.tan(n1*np.pi/2) * np.tanh(n1/2*(np.log(t/t0)))) /np.pi/n1\n",
    "\n",
    "uni_order = []\n",
    "uni_order_nf = []\n",
    "\n",
    "for i in range(_f.shape[0]):\n",
    "    # if i <20: continue\n",
    "    _R_i, _C_i, _tau_i, _, _, _ = Loe_Analysis_Single(_f[i,:], _Z[i,:], REALFLAG=True)\n",
    "    _R_nf, _C_nf, _tau_nf, _, _, _ = Loe_Analysis_Single(_f[i,:], _Z_nf[i,:], REALFLAG=True)\n",
    "    _drt_list.append(np.array([_R_i, _C_i, _tau_i]))\n",
    "    _nf_list.append(np.array([_R_nf, _C_nf, _tau_nf]))\n",
    "\n",
    "\n",
    "    ## nf\n",
    "    theo_tau_list = _tau_nf[_tau_nf.argsort()]\n",
    "    D_den_theo = np.array([CPE_G2(i) for i in theo_tau_list]) * R1\n",
    "    _theo_den_list.append(np.array([theo_tau_list, D_den_theo]))\n",
    "    \n",
    "\n",
    "    D_theo = nonuniform_weights_from_Fx(theo_tau_list, CPE_F1) * R1\n",
    "    _theo_list.append(np.array([theo_tau_list, D_theo]))\n",
    "\n",
    "    \n",
    "    D_G_theo = nonuniform_weights_from_Gx(theo_tau_list, CPE_G1) * R1\n",
    "    _theo_list_G.append(np.array([theo_tau_list, D_G_theo]))\n",
    "\n",
    "    \n",
    "    # tau_uni = np.logspace(-np.log10(2*np.pi*f.max()), -np.log10(2*np.pi*f.min()), _tau_nf.shape[0])\n",
    "    # D_uni = log_uniform_weights_from_F(tau_uni, CPE_F2) * R1\n",
    "    # _theo_uni_list.append(np.array([tau_uni, D_uni]))\n",
    "\n",
    "    uni_order_nf.append(_tau_nf.shape[0])\n",
    "\n",
    "    ## drt_noise\n",
    "    theo_tau_list = _tau_i[_tau_i.argsort()]\n",
    "\n",
    "    \n",
    "    D_theo = nonuniform_weights_from_Fx(theo_tau_list, CPE_F1) * R1\n",
    "    _theo_non_drt.append(np.array([theo_tau_list, D_theo]))\n",
    "    \n",
    "    uni_order.append(_tau_i.shape[0])\n",
    "    \n",
    "\n",
    "uni_order = int(np.round(np.mean(uni_order)))\n",
    "tau_uni = np.logspace(-np.log10(2*np.pi*f.max()), -np.log10(2*np.pi*f.min()), uni_order)\n",
    "# tau_uni = np.logspace(np.log10(t0/1e2), np.log10(t0*1e2), _tau_i.shape[0])\n",
    "D_uni = log_uniform_weights_from_F(tau_uni, CPE_F2) * R1\n",
    "_theo_uni_drt.append(np.array([tau_uni, D_uni]))\n",
    "\n",
    "\n",
    "\n",
    "uni_order_nf = int(np.round(np.mean(uni_order_nf)))\n",
    "\n",
    "tau_uni = np.logspace(-np.log10(2*np.pi*f.max()), -np.log10(2*np.pi*f.min()), uni_order_nf)\n",
    "D_uni = log_uniform_weights_from_F(tau_uni, CPE_F2) * R1\n",
    "_theo_uni_list.append(np.array([tau_uni, D_uni]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25385f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_uni[(tau_uni>_RQ_peak/10) & (tau_uni<_RQ_peak*10)]\n",
    "# tau_uni[(tau_uni>_RQ_peak/10) & (tau_uni<_RQ_peak*10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8a7460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_uniform_weights_from_F(\n",
    "#     [_RQ_peak/(__alpha/__alpha),_RQ_peak/__alpha,_RQ_peak,_RQ_peak*__alpha,_RQ_peak*__alpha*__alpha], \n",
    "#     CPE_F2) * R1\n",
    "\n",
    "# __Rp = log_uniform_weights_from_F(\n",
    "#     [_RQ_peak/(__alpha**2),_RQ_peak,_RQ_peak*(__alpha**2)], \n",
    "#     CPE_F2) * R1\n",
    "# __Rp\n",
    "\n",
    "# log_uniform_weights_from_F(\n",
    "#     tau_uni[(tau_uni>_RQ_peak/10) & (tau_uni<_RQ_peak*10)], \n",
    "#     CPE_F2) * R1\n",
    "# _RQ_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "595fee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-09 20:55:20.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1m\n",
      "Peak[9.973682993875135e-08, 755.7658339186091]\n",
      " [5.50018919939476e-08, 1.9175789132526927e-07]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def find_half_max_loglog(x, y, x0, plot=True):\n",
    "    # 转 log-log\n",
    "    logx = np.log10(x)\n",
    "    logy = np.log10(y)\n",
    "\n",
    "    # 插值函数（单调性允许使用线性插值）\n",
    "    interp_logy = interp1d(logx, logy, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "    # 找到log(x0)对应的log(y0)\n",
    "    logx0 = np.log10(x0)\n",
    "    logy0 = float(interp_logy(logx0))\n",
    "    y0 = 10 ** logy0\n",
    "    logy_half = logy0 - np.log10(2)\n",
    "\n",
    "    # 寻找左半部分小于logx0的点\n",
    "    left_mask = logx < logx0\n",
    "    right_mask = logx > logx0\n",
    "\n",
    "    def get_crossing_x(logx_sub, logy_sub):\n",
    "        # 只处理 y 递增到 y0/2 处的交点\n",
    "        diff = logy_sub - logy_half\n",
    "        sign = np.sign(diff)\n",
    "        cross_indices = np.where(np.diff(sign))[0]\n",
    "\n",
    "        if len(cross_indices) == 0:\n",
    "            return None, np.inf  # 无法找到交点\n",
    "\n",
    "        idx = cross_indices[0]\n",
    "        x1 = np.interp(logy_half, logy_sub[idx:idx+2], logx_sub[idx:idx+2])\n",
    "        error = abs(diff[idx]) + abs(diff[idx+1])\n",
    "        return 10 ** x1, error\n",
    "\n",
    "    # 处理左右\n",
    "    x1, err1 = get_crossing_x(logx[left_mask][::-1], logy[left_mask][::-1])\n",
    "    x2, err2 = get_crossing_x(logx[right_mask], logy[right_mask])\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.loglog(x, y, 'o-', label='Data')\n",
    "        plt.axvline(x0, color='gray', linestyle='--', label='x0')\n",
    "        plt.axhline(y0, color='green', linestyle='--', label='y0')\n",
    "        plt.axhline(y0/2, color='red', linestyle='--', label='y0/2')\n",
    "        if x1: plt.axvline(x1, color='red', linestyle=':', label='x1')\n",
    "        if x2: plt.axvline(x2, color='red', linestyle=':', label='x2')\n",
    "        plt.legend()\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.title('Half Maximum Detection (log-log)')\n",
    "        plt.grid(True, which='both', ls='--')\n",
    "        plt.show()\n",
    "\n",
    "    return y0, x1, x2, err1, err2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def robust_peak_halfwidth(x, y, x0, window_ratio=0.2, smooth_factor=1e-3, plot=False):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    # 1. 在x0附近截取局部数据（自适应窗口）\n",
    "    x_range = x.max() - x.min()\n",
    "    window = x_range * window_ratio\n",
    "    mask = (x > x0 - window) & (x < x0 + window)\n",
    "    x_local = x[mask]\n",
    "    y_local = y[mask]\n",
    "\n",
    "    if len(x_local) < 5:\n",
    "        raise ValueError(\"局部点太少，无法拟合\")\n",
    "\n",
    "    # 2. 拟合局部三次多项式，估计 y0\n",
    "    p = np.polyfit(x_local, y_local, deg=3)\n",
    "    y0 = np.polyval(p, x0)\n",
    "\n",
    "    # 3. 全局拟合光滑曲线（spline），忽略明显的outlier\n",
    "    spline = UnivariateSpline(x, y - y0/2, s=smooth_factor)\n",
    "    roots = spline.roots()\n",
    "\n",
    "    # 4. 找最接近x0的左右两个点作为x1, x2\n",
    "    roots = np.array(roots)\n",
    "    left = roots[roots < x0]\n",
    "    right = roots[roots > x0]\n",
    "\n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        raise RuntimeError(\"无法找到两个半高点\")\n",
    "\n",
    "    x1 = left[-1]\n",
    "    x2 = right[0]\n",
    "\n",
    "    # 5. 估算误差：用拟合残差作为粗略标准差\n",
    "    residuals = y_local - np.polyval(p, x_local)\n",
    "    error = np.std(residuals)\n",
    "\n",
    "    # 可视化检查\n",
    "    if plot:\n",
    "        plt.scatter(x, y, label='Raw Data', alpha=0.3)\n",
    "        x_fit = np.linspace(min(x), max(x), 1000)\n",
    "        plt.plot(x_fit, np.polyval(p, x_fit), 'g--', label='Local Polyfit')\n",
    "        plt.axvline(x1, color='r', linestyle='--', label='x1, x2')\n",
    "        plt.axvline(x2, color='r', linestyle='--')\n",
    "        plt.axhline(y0, color='k', linestyle='--', label='y0')\n",
    "        plt.axhline(y0/2, color='grey', linestyle=':')\n",
    "        plt.scatter([x0], [y0], color='blue', label='x0, y0')\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.title(\"Robust Peak Analysis\")\n",
    "        plt.show()\n",
    "\n",
    "    return y0, x1, x2, error\n",
    "\n",
    "\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "_drt_all = np.concatenate(_drt_list, axis=1)\n",
    "_drt_all = _drt_all[:,_drt_all[2,:].argsort()]\n",
    "_RQ_peak = (R1*Y1)**(1/n1)\n",
    "\n",
    "\n",
    "_drtRC_log_loess = lowess(np.log(_drt_all[0,:]), np.log(_drt_all[2,:]), frac=0.05, it=3, return_sorted=False)\n",
    "_drtRC_log_loess = np.exp(_drtRC_log_loess)\n",
    "\n",
    "y0, x1, x2, error1, error2 = find_half_max_loglog(_drt_all[2,:],_drtRC_log_loess, _RQ_peak, plot=True)\n",
    "axis = plt.gca()\n",
    "axis.plot(_drt_all[2,:], _drt_all[0,:])\n",
    "# y0, x1, x2, error = estimate_half_max_width_loglog(_drt_all[2,:],_drt_all[0,:], _RQ_peak, plot=True)\n",
    "# y0, x1, x2, error = robust_peak_halfwidth(_drt_all[2,:],_drt_all[0,:], _RQ_peak, \n",
    "#                                           window_ratio=0.2, smooth_factor=1e-3,plot=True)\n",
    "logger.info(f\"\\nPeak[{_RQ_peak}, {y0}]\\n [{x1}, {x2}]\")\n",
    "# logger.info(f\"\\n{_RQ_peak/x1}\\t{x2/_RQ_peak}\")\n",
    "__eta = _RQ_peak/x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3b547fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x227c791b150>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# __t0 = (R1*Y1)**(1/n1)\n",
    "# __fp = 6557\n",
    "# __alpha = np.sqrt(tau_uni_drt[1]/tau_uni_drt[0])\n",
    "# __tl = 1.296e-4\n",
    "# __tr = 3.704e-4\n",
    "# __tr = __t0**2/__tl\n",
    "# axis[1].vlines(__t0,D_uni_drt.min(), D_uni_drt.max())\n",
    "# axis[1].vlines(__t0/__alpha,D_uni_drt.min(), D_uni_drt.max())\n",
    "# axis[1].vlines(__t0*__alpha,D_uni_drt.min(), D_uni_drt.max())\n",
    "# axis[1].hlines(__fp/2,tau_uni_drt.min(), tau_uni_drt.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e89de0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(1,2)\n",
    "axis = axis.flatten()\n",
    "cmap = plt.get_cmap('rainbow_r')\n",
    "for i in range(_f.shape[0]):\n",
    "    if i!=10: continue\n",
    "    _R_i, _C_i, _tau_i = _drt_list[i][0,:], _drt_list[i][1,:], _drt_list[i][2,:]\n",
    "    _R_nf, _C_nf, _tau_nf = _nf_list[i][0,:], _nf_list[i][1,:], _nf_list[i][2,:]\n",
    "\n",
    "    theo_den_tau, D_den_theo = _theo_den_list[i][0,:], _theo_den_list[i][1,:]\n",
    "    theo_tau, D_theo = _theo_list[i][0,:], _theo_list[i][1,:]\n",
    "    theo_G_tau, D_G_theo = _theo_list_G[i][0,:], _theo_list_G[i][1,:]\n",
    "\n",
    "    # tau_uni, D_uni = _theo_uni_list[i][0,:], _theo_uni_list[i][1,:]\n",
    "    tau_uni, D_uni = _theo_uni_list[0][0,:], _theo_uni_list[0][1,:]\n",
    "\n",
    "    \n",
    "    tau_non_drt, D_non_drt = _theo_non_drt[i][0,:], _theo_non_drt[i][1,:]\n",
    "\n",
    "    tau_uni_drt, D_uni_drt = _theo_uni_drt[0][0,:], _theo_uni_drt[0][1,:]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # axis[0].scatter(_R_i[0]*_C_i[0], _R_i[0], s=2, color = 'orange')\n",
    "    axis[0].scatter(_R_nf[:]*_C_nf[:], _R_nf[:], s=10, color = 'blue')\n",
    "    axis[0].scatter(theo_den_tau, D_den_theo, s=10, color='green')\n",
    "    axis[0].scatter(theo_tau, D_theo, s=10, color = 'red')\n",
    "    # axis[0].scatter(theo_G_tau, D_G_theo, color = 'red')\n",
    "    axis[0].scatter(tau_uni, D_uni, s=10, color = 'orange')\n",
    "    axis[0].scatter(_R_i[1:]*_C_i[1:], _R_i[1:]*2, s=2, color = 'gray')\n",
    "\n",
    "    \n",
    "    axis[1].scatter(_R_i[1:]*_C_i[1:], _R_i[1:], s=5, color = 'gray')\n",
    "    # axis[1].scatter(theo_den_tau, D_den_theo, s=2, color='green')\n",
    "    axis[1].scatter(tau_non_drt, D_non_drt, s=5, color = 'red')\n",
    "    # axis[1].scatter(tau_uni_drt, D_uni_drt, s=50, color = 'orange')\n",
    "    \n",
    "\n",
    "    axis[1].scatter(tau_uni_drt, D_uni_drt, s=50, color = cmap(i/_f.shape[0]))\n",
    "    # axis[1].scatter(tau_uni, D_uni, s=50, color = 'orange')\n",
    "\n",
    "\n",
    "axis[0].set_xscale('log')\n",
    "axis[0].set_yscale('log')\n",
    "axis[0].set_aspect('equal')\n",
    "axis[1].set_xscale('log')\n",
    "axis[1].set_yscale('log')\n",
    "axis[1].set_aspect('equal')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c462e79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.8133345294690293)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "__alpha = np.sqrt(tau_uni_drt[i+1]/tau_uni_drt[i])\n",
    "__alpha\n",
    "__eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5bcf9c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Equation 1] 解为 beta ≈ 1.194812\tphi=0.760641\terror:-0.154843\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "# 参数设定\n",
    "a = __alpha\n",
    "eta = __eta\n",
    "\n",
    "def lhs_eq1(beta):\n",
    "    return np.tanh(beta * np.log(a) / np.pi)\n",
    "\n",
    "def rhs_eq1(beta):\n",
    "    t1 = np.tanh(beta * np.log(a * eta) / np.pi)\n",
    "    t2 = np.tanh(beta * np.log(a / eta) / np.pi)\n",
    "    denom = 1 - (np.tan(beta) ** 2) * t1 * t2\n",
    "    if np.isclose(denom, 0):\n",
    "        return np.nan  # 避免除以0\n",
    "    return (t1 + t2) / denom\n",
    "\n",
    "# 定义误差函数用于求解 beta\n",
    "def residual_eq1(beta):\n",
    "    return lhs_eq1(beta) - rhs_eq1(beta)\n",
    "\n",
    "# 绘图检查曲线交点\n",
    "b_vals = np.linspace(1e-6, np.pi / 2 - 1e-6, 500)\n",
    "lhs_vals = [lhs_eq1(b) for b in b_vals]\n",
    "rhs_vals = [rhs_eq1(b) for b in b_vals]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(b_vals, lhs_vals, label='LHS', color='blue')\n",
    "plt.plot(b_vals, rhs_vals, label='RHS', color='red')\n",
    "plt.xlabel('β')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Equation 1: LHS vs RHS')\n",
    "plt.show()\n",
    "\n",
    "# 数值求解：选择合适初值\n",
    "sol1 = root_scalar(residual_eq1, bracket=[0.01, np.pi/2 - 0.01], method='brentq')\n",
    "print(f\"[Equation 1] 解为 beta ≈ {sol1.root:.6f}\\tphi={2*sol1.root/np.pi:.6f}\\terror:{(2*sol1.root/np.pi-n1)/n1:.6f}\")\n",
    "\n",
    "# --------------------------------------------\n",
    "\n",
    "# 另一个公式\n",
    "def Fp(beta):\n",
    "    return np.arctan(np.tan(beta) * np.tanh(beta * np.log(a) / np.pi))\n",
    "\n",
    "def Fh(beta):\n",
    "    t1 = np.arctan(np.tan(beta) * np.tanh(beta * np.log(a * eta) / np.pi))\n",
    "    t2 = np.arctan(np.tan(beta) * np.tanh(beta * np.log(a / eta) / np.pi))\n",
    "    return t1 + t2\n",
    "\n",
    "def residual_eq2(beta):\n",
    "    return Fp(beta) - Fh(beta)\n",
    "\n",
    "# 绘图\n",
    "Fp_vals = [Fp(b) for b in b_vals]\n",
    "Fh_vals = [Fh(b) for b in b_vals]\n",
    "# plt.figure()\n",
    "plt.plot(b_vals, Fp_vals, label='Fp', color='green')\n",
    "plt.plot(b_vals, Fh_vals, label='Fh', color='orange')\n",
    "plt.xlabel('β')\n",
    "plt.ylabel('Angle')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Equation 2: Fp vs Fh')\n",
    "plt.show()\n",
    "\n",
    "# 数值求解\n",
    "# sol2 = root_scalar(residual_eq2, bracket=[1e-6, np.pi/2 - 1e-6], method='bisect')\n",
    "# print(f\"[Equation 2] 解为 beta ≈ {sol2.root:.6f}\")\n",
    "__beta = sol1.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80acf74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-09 20:56:11.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m\n",
      "1059.5103670807343, 574.8664714380806, 780.4338448425768\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "__beta = sol1.root\n",
    "__fp_1 = 1/__beta*np.arctan(np.tan(__beta)*np.tanh(__beta*np.log(__alpha)/np.pi))\n",
    "__fp_2 = 1/__beta*(np.arctan(np.tan(__beta)*np.tanh(__beta*np.log(__alpha*__eta)/np.pi))\n",
    "                 +np.arctan(np.tan(__beta)*np.tanh(__beta*np.log(__alpha/__eta)/np.pi)))\n",
    "logger.info(f\"\\n{y0/__fp_1}, {y0/__fp_2}, {y0/np.sqrt(__fp_1*__fp_2)}\")\n",
    "# logger.info(f\"\\nR1_error: {(y0/__fp_1-R1)/R1}, {(y0-__Rp[1])/__Rp[1]}\")\n",
    "# logger.info(f\"\\nfp_error: {(__fp_1-__Rp[1]/R1)/(__Rp[1]/R1)}\")\n",
    "# __fp\n",
    "# __fp_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e958d9c",
   "metadata": {},
   "source": [
    "### From Data to IPDF to PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378bf19",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "103602a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import lsq_linear\n",
    "\n",
    "def _build_L(N, diff_order=2):\n",
    "    if diff_order == 0:\n",
    "        L = np.eye(N)\n",
    "    elif diff_order == 1:\n",
    "        L = np.eye(N, k=0) - np.eye(N, k=1)\n",
    "        L = L[:-1]\n",
    "    elif diff_order == 2:\n",
    "        L = np.zeros((N-2, N))\n",
    "        for i in range(N-2):\n",
    "            L[i, i:i+3] = [1, -2, 1]\n",
    "    else:\n",
    "        raise ValueError(\"diff_order must be 0,1,2\")\n",
    "    return L\n",
    "\n",
    "def tikhonov_inversion_robust(\n",
    "    A, y, lam=1e-2, nonneg=True, diff_order=2,\n",
    "    weights=None,                   # 可传入逐区间权重向量（或与 y 同形）\n",
    "    huber_delta=None,               # 设为正数启用 Huber IRLS，如 1e-2\n",
    "    max_irls_iter=25, irls_tol=1e-6,\n",
    "    dx=None,                        # 标量或长度 N 的数组；用于归一化约束\n",
    "    norm_mu=1e3,                    # 归一化约束强度；越大越接近硬约束\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Solve: min ||W^{1/2}(A p - y)||^2 + lam ||L p||^2  s.t. (soft) sum(p*dx)=1, p>=0 (optional)\n",
    "    - A, y: 也可为 list[ndarray]，表示多组 IPDF；函数内部会按行堆叠\n",
    "    - weights: 与 y 同形或堆叠后长度相同的权重（可与 Huber 同时使用）\n",
    "    - huber_delta: 启用 Huber IRLS 以抑制离群；None 则不用\n",
    "    - dx: 标量（等距）或长度 N 的数组（不等距）；若 None 则归一化不施加\n",
    "    - norm_mu: 归一化软约束的权重（建议 1e2~1e5）\n",
    "    \"\"\"\n",
    "    # ---- 堆叠多组数据 ----\n",
    "    if isinstance(A, (list, tuple)):\n",
    "        A_stack = np.vstack(A)\n",
    "        y_stack = np.concatenate(y)\n",
    "    else:\n",
    "        A_stack = np.asarray(A)\n",
    "        y_stack = np.asarray(y)\n",
    "    m, N = A_stack.shape\n",
    "    y_stack = y_stack.reshape(-1)\n",
    "\n",
    "    # ---- 差分矩阵 ----\n",
    "    L = _build_L(N, diff_order=diff_order)\n",
    "\n",
    "    # ---- 初始权重向量 ----\n",
    "    if weights is None:\n",
    "        w = np.ones(m)\n",
    "    else:\n",
    "        w = np.asarray(weights).reshape(-1)\n",
    "        if w.size != m:\n",
    "            raise ValueError(\"weights length mismatch after stacking\")\n",
    "\n",
    "    # ---- 归一化约束向量 q ----\n",
    "    if dx is not None:\n",
    "        if np.isscalar(dx):\n",
    "            q = np.full(N, float(dx))\n",
    "        else:\n",
    "            q = np.asarray(dx).reshape(-1)\n",
    "            if q.size != N:\n",
    "                raise ValueError(\"dx length must equal N (number of columns in A)\")\n",
    "    else:\n",
    "        q = None\n",
    "\n",
    "    # ---- IRLS 主循环（若未启用 Huber，则只跑一轮）----\n",
    "    p = np.full(N, 1.0 / max(N, 1))  # 初值：均匀\n",
    "    last_obj = np.inf\n",
    "\n",
    "    for it in range(1 if huber_delta is None else max_irls_iter):\n",
    "        # 形成加权 A,y\n",
    "        W_sqrt = np.sqrt(w)\n",
    "        Aw = (W_sqrt[:, None] * A_stack)\n",
    "        yw = W_sqrt * y_stack\n",
    "\n",
    "        # 增广系统\n",
    "        A_aug = [Aw, np.sqrt(lam) * L]\n",
    "        y_aug = [yw, np.zeros(L.shape[0])]\n",
    "        if q is not None and norm_mu > 0:\n",
    "            A_aug.append(np.sqrt(norm_mu) * q.reshape(1, -1))\n",
    "            y_aug.append(np.array([np.sqrt(norm_mu) * 1.0]))\n",
    "        A_aug = np.vstack(A_aug)\n",
    "        y_aug = np.concatenate(y_aug)\n",
    "\n",
    "        # 解：非负/无约束\n",
    "        if nonneg:\n",
    "            res = lsq_linear(A_aug, y_aug, bounds=(0, np.inf), lsmr_tol='auto', max_iter=5000)\n",
    "            p = res.x\n",
    "        else:\n",
    "            # 正规方程（注意可能更数值不稳，建议优先用 lsq_linear）\n",
    "            ATA = A_aug.T @ A_aug\n",
    "            ATy = A_aug.T @ y_aug\n",
    "            p = np.linalg.solve(ATA, ATy)\n",
    "\n",
    "        # 可选：求目标函数值以监控收敛\n",
    "        resid = A_stack @ p - y_stack\n",
    "        if huber_delta is None:\n",
    "            # 纯加权二范数\n",
    "            data_term = np.sum((np.sqrt(w) * resid) ** 2)\n",
    "        else:\n",
    "            # Huber 代价（仅用于监控，不影响权重更新）\n",
    "            a = np.abs(resid)\n",
    "            delta = huber_delta\n",
    "            data_term = np.sum(np.where(a <= delta, 0.5 * a**2, delta * (a - 0.5 * delta)) * w)\n",
    "\n",
    "        reg_term = lam * np.sum((L @ p) ** 2)\n",
    "        norm_term = 0.0\n",
    "        if q is not None and norm_mu > 0:\n",
    "            norm_term = norm_mu * (q @ p - 1.0) ** 2\n",
    "        obj = data_term + reg_term + norm_term\n",
    "        if verbose:\n",
    "            print(f\"[IRLS {it+1}] obj={obj:.6e}, data={data_term:.6e}, reg={reg_term:.6e}, norm={norm_term:.6e}\")\n",
    "\n",
    "        # IRLS: 更新权重 w（基于上一轮残差）\n",
    "        if huber_delta is not None:\n",
    "            r = resid\n",
    "            a = np.abs(r)\n",
    "            delta = huber_delta\n",
    "            # Huber 的等价权（W）= ψ(r)/r；对应到二次近似中 sqrt(w)\n",
    "            # 这里直接用 w = max(delta/|r|, 1) 的裁剪版本以避免 0/0\n",
    "            new_w = np.ones_like(a)\n",
    "            mask = a > delta\n",
    "            new_w[mask] = delta / (a[mask] + 1e-12)\n",
    "            # 累乘用户权重（若提供）\n",
    "            if weights is not None:\n",
    "                new_w *= np.asarray(weights).reshape(-1)\n",
    "            # 收敛判据\n",
    "            if np.linalg.norm(new_w - w) / (np.linalg.norm(w) + 1e-12) < irls_tol:\n",
    "                w = new_w\n",
    "                break\n",
    "            w = new_w\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 最后再做一次严格归一化（避免数值误差）\n",
    "    if q is not None:\n",
    "        Z = q @ p\n",
    "        if Z > 0:\n",
    "            p = p / Z\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "498ce435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_A_trapz(bin_edges, grid):\n",
    "    \"\"\"\n",
    "    构造梯形积分法的 A 矩阵\n",
    "    bin_edges: shape (M+1,) 测量区间边界\n",
    "    grid: shape (N+1,) PDF 网格的边界（cell 边界）\n",
    "    返回: A shape (M, N+1) ，这里 p_j 定义在节点（grid 顶点）上\n",
    "    \"\"\"\n",
    "    M = len(bin_edges) - 1\n",
    "    N = len(grid) - 1\n",
    "    # 节点个数 = N+1\n",
    "    A = np.zeros((M, N+1))\n",
    "\n",
    "    # 对每个测量区间\n",
    "    for i in range(M):\n",
    "        L, R = bin_edges[i], bin_edges[i+1]\n",
    "        for j in range(N):\n",
    "            x0, x1 = grid[j], grid[j+1]\n",
    "\n",
    "            # 找区间和单元的重叠部分\n",
    "            left = max(L, x0)\n",
    "            right = min(R, x1)\n",
    "            overlap = right - left\n",
    "            if overlap <= 0:\n",
    "                continue\n",
    "\n",
    "            # 梯形积分的权重分配：\n",
    "            # 单元的左节点和右节点各占一半，但要按重叠比例缩放\n",
    "            cell_len = x1 - x0\n",
    "            w_left = overlap / cell_len / 2\n",
    "            w_right = overlap / cell_len / 2\n",
    "\n",
    "            A[i, j] += w_left * cell_len\n",
    "            A[i, j+1] += w_right * cell_len\n",
    "\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e2fd91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.optimize import lsq_linear\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: build integration matrix A\n",
    "# -----------------------------\n",
    "def build_A(bin_edges, grid):\n",
    "    \"\"\"\n",
    "    构造 A 矩阵：每个测量区间（由 bin_edges 给出）对 grid 中每个小单元的积分权重。\n",
    "    bin_edges: shape (M+1,) 测量区间边界，测量 i 对应 [bin_edges[i], bin_edges[i+1]]\n",
    "    grid: shape (N+1,) 细分网格的边界（通常可以等于 bin_edges 或更细）\n",
    "    返回 A shape (M, N) ，p_j 定义在 grid 单元上（中心或cell-average）\n",
    "    \"\"\"\n",
    "    M = len(bin_edges)-1\n",
    "    N = len(grid)-1\n",
    "    A = np.zeros((M, N))\n",
    "    # 对每个测量区间 i，对每个细网格单元 j 计算重叠长度\n",
    "    for i in range(M):\n",
    "        L, R = bin_edges[i], bin_edges[i+1]\n",
    "        # for each cell j\n",
    "        for j in range(N):\n",
    "            a, b = grid[j], grid[j+1]\n",
    "            overlap = max(0.0, min(R, b) - max(L, a))\n",
    "            A[i, j] = overlap\n",
    "    return A\n",
    "\n",
    "# -----------------------------\n",
    "# Method 1: naive IPDF / Δx\n",
    "# -----------------------------\n",
    "def naive_pdf_from_ipdf(ipdf, bin_edges):\n",
    "    widths = np.diff(bin_edges)\n",
    "    pdf = ipdf / widths\n",
    "    grid_centers = 0.5*(bin_edges[:-1] + bin_edges[1:])\n",
    "    return grid_centers, pdf\n",
    "\n",
    "# -----------------------------\n",
    "# Method 2: Tikhonov (regularized LS), optionally non-negative\n",
    "# -----------------------------\n",
    "def tikhonov_inversion(A, y, lam=1e-3, nonneg=True, diff_order=2):\n",
    "    \"\"\"\n",
    "    Solve min ||A p - y||^2 + lam ||L p||^2\n",
    "    If nonneg: enforce p >= 0 via lsq_linear\n",
    "    diff_order: 0 -> identity, 1 -> first diff, 2 -> second diff\n",
    "    \"\"\"\n",
    "    N = A.shape[1]\n",
    "    # build L\n",
    "    if diff_order == 0:\n",
    "        L = np.eye(N)\n",
    "    elif diff_order == 1:\n",
    "        L = np.eye(N, k=0) - np.eye(N, k=1)\n",
    "        L = L[:-1]  # shape (N-1, N)\n",
    "    elif diff_order == 2:\n",
    "        L = np.zeros((N-2, N))\n",
    "        for i in range(N-2):\n",
    "            L[i, i] = 1\n",
    "            L[i, i+1] = -2\n",
    "            L[i, i+2] = 1\n",
    "    else:\n",
    "        raise ValueError(\"diff_order 0/1/2 only\")\n",
    "    # Augmented system trick: [A; sqrt(lam)*L] p = [y; 0]\n",
    "    A_aug = np.vstack([A, np.sqrt(lam)*L])\n",
    "    y_aug = np.concatenate([y, np.zeros(L.shape[0])])\n",
    "    if nonneg:\n",
    "        res = lsq_linear(A_aug, y_aug, bounds=(0, np.inf), lsmr_tol='auto', max_iter=2000)\n",
    "        p = res.x\n",
    "    else:\n",
    "        # analytical solution via normal eqn (A^T A + lam L^T L) p = A^T y\n",
    "        ATA = A.T @ A\n",
    "        LTL = L.T @ L\n",
    "        mat = ATA + lam * LTL\n",
    "        rhs = A.T @ y\n",
    "        p = np.linalg.solve(mat, rhs)\n",
    "    return p\n",
    "\n",
    "##\n",
    "def Tikhonov_IPDF2PDF(tau, R, lam = 1e-3):\n",
    " \n",
    "    tau_log = np.log10(tau)\n",
    "\n",
    "    integral_edge = (tau_log[:-1] + tau_log[:-1])/2    \n",
    "    pdf_grid =  np.linspace(math.floor(integral_edge[0]), math.ceil(integral_edge[-1]), \n",
    "                            1+20*(math.ceil(integral_edge[-1]) - math.floor(integral_edge[0])))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Method 1: naive\n",
    "    # pdf_x, pdf_est = naive_pdf_from_ipdf(R[1:-1], integral_edge)\n",
    "    # pdf_x = np.power(10, pdf_x)\n",
    "    # Method 2: tikhonov ls (nonneg)\n",
    "    A = build_A(integral_edge, pdf_grid)\n",
    "    # A = build_A_trapz(integral_edge, (pdf_grid[:-1] + pdf_grid[1:]) / 2)\n",
    "    pdf_x = np.power(10, (pdf_grid[:-1] + pdf_grid[1:]) / 2)\n",
    "    pdf_est = tikhonov_inversion(A, R[1:-1], lam=lam, nonneg=True, diff_order=2)\n",
    "    # pdf_est = tikhonov_inversion_robust(A, R[1:-1], lam=lam, nonneg=True, diff_order=2)\n",
    "\n",
    "    return pdf_x, pdf_est\n",
    "\n",
    "    \n",
    "\n",
    "def Tikhonov_IPDF2PDF_list(drt_list, lam = 1e-3):\n",
    "\n",
    "    R_list          = [_drt[0,1:-1] for _drt in drt_list]\n",
    "    tau_list        = [_drt[2,:] for _drt in drt_list]\n",
    "\n",
    "    R_list_conc     = np.concatenate(R_list, axis=0)\n",
    "    tau_list_conc   = np.concatenate(tau_list, axis=0)\n",
    "    tau_list_conc_log = np.log10(tau_list_conc)\n",
    "\n",
    "    pdf_grid =  np.linspace(math.floor(np.min(tau_list_conc_log)), math.ceil(np.max(tau_list_conc_log)), \n",
    "                            1+20*(math.ceil(np.max(tau_list_conc_log)) - math.floor(np.min(tau_list_conc_log))))\n",
    "        \n",
    "\n",
    "    A_list = []\n",
    "    for i in range(len(tau_list)):\n",
    "        tau_log = np.log10(tau_list[i])\n",
    "        integral_edge = (tau_log[:-1] + tau_log[:-1])/2    \n",
    "        A = build_A(integral_edge, pdf_grid)\n",
    "        # A = build_A_trapz(integral_edge, pdf_grid)\n",
    "\n",
    "        A_list.append(A)\n",
    "\n",
    "    A_list = np.concatenate(A_list, axis=0)\n",
    "\n",
    "\n",
    "    # Method 1: naive\n",
    "    # centers_naive, pdf_naive = naive_pdf_from_ipdf(R, integral_edge)\n",
    "\n",
    "    # Method 2: tikhonov ls (nonneg)\n",
    "    # logger.info(f\"A:{A.shape}, R:{R.shape}\")\n",
    "\n",
    "    pdf_x = np.power(10, (pdf_grid[:-1] + pdf_grid[1:]) / 2)\n",
    "    pdf_est = tikhonov_inversion(A_list, R_list_conc, lam=lam, nonneg=True, diff_order=2)\n",
    "    # pdf_est = tikhonov_inversion_robust(A_list, R_list_conc, lam=lam, nonneg=True, diff_order=2)\n",
    "\n",
    "    return pdf_x, pdf_est\n",
    "\n",
    "    \n",
    "def ipdf_to_pdf(ipdf_x, ipdf_p, pdf_x, s=0.001):\n",
    "    pdf_x = np.log10(pdf_x)\n",
    "    ipdf_x = np.log10(ipdf_x)\n",
    "    # 排序输入数据（确保x单调增加）\n",
    "    idx = np.argsort(ipdf_x)\n",
    "    x = np.array(ipdf_x)[idx]\n",
    "    p = np.array(ipdf_p)[idx]\n",
    "    n = len(x)\n",
    "    # 估计每个IPDF点对应的区间边界（取相邻中点的中间为边界）\n",
    "    edges = np.empty(n+1)\n",
    "    edges[1:n] = (x[:-1] + x[1:]) / 2\n",
    "    # 外推两端边界\n",
    "    edges[0] = x[0] - (x[1] - x[0]) / 2 if n>1 else x[0] - 0.5\n",
    "    edges[n] = x[-1] + (x[-1] - x[-2]) / 2 if n>1 else x[0] + 0.5\n",
    "    # 确保概率非负并归一化\n",
    "    p = np.clip(p, 0, None)\n",
    "    # if p.sum() > 0:\n",
    "    #     p = p / p.sum()\n",
    "    # 计算累积分布函数 (CDF) 在每个边界处的值\n",
    "    cdf_x = edges\n",
    "    cdf_y = np.concatenate(([0], np.cumsum(p)))\n",
    "    # 用样条拟合CDF数据并求导得到PDF\n",
    "    spl = UnivariateSpline(cdf_x, cdf_y, k=3, s=s)\n",
    "    pdf_y = spl.derivative()(pdf_x)\n",
    "    # 截断微小的负值并再次归一化PDF（确保概率意义）\n",
    "    pdf_y[pdf_y < 0] = 0.0\n",
    "    # pdf_y /= np.trapz(pdf_y, pdf_x)\n",
    "    return pdf_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c7820c",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a84e1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_drt_list = []\n",
    "_nf_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t0 = np.power(R1*Y1, 1/n1)\n",
    "\n",
    "\n",
    "CPE_G1 = lambda x: np.sin(n1*np.pi) / (np.cosh(n1*(x-np.log(t0))) + np.cos(n1*np.pi)) /2/np.pi\n",
    "CPE_G2 = lambda t: np.sin(n1*np.pi) / (np.cosh(n1*(np.log(t/t0))) + np.cos(n1*np.pi)) /2/np.pi\n",
    "CPE_F1 = lambda x: np.arctan(np.tan(n1*np.pi/2) * np.tanh(n1/2*(x-np.log(t0)))) /np.pi/n1 + 0.5\n",
    "CPE_F2 = lambda t: np.arctan(np.tan(n1*np.pi/2) * np.tanh(n1/2*(np.log(t/t0)))) /np.pi/n1 + 0.5\n",
    "\n",
    "uni_order = []\n",
    "uni_order_nf = []\n",
    "\n",
    "for i in range(_f.shape[0]):\n",
    "    # if i <20: continue\n",
    "    _R_i, _C_i, _tau_i, _, _, _ = Loe_Analysis_Single(_f[i,:], _Z[i,:], REALFLAG=True)\n",
    "    _R_nf, _C_nf, _tau_nf, _, _, _ = Loe_Analysis_Single(_f[i,:], _Z_nf[i,:], REALFLAG=True)\n",
    "    _drt_list.append(np.array([_R_i, _C_i, _tau_i]))\n",
    "    _nf_list.append(np.array([_R_nf, _C_nf, _tau_nf]))\n",
    "\n",
    "    \n",
    "    uni_order_nf.append(_tau_nf.shape[0])\n",
    "    uni_order.append(_tau_i.shape[0])\n",
    "\n",
    "\n",
    "if True:\n",
    "    plt.figure()\n",
    "    plt.loglog(_f[i,:], np.abs(_Z[i,:]), label='Simulated Data')\n",
    "    # plt.plot((1/Z_sim).real, (1/Z_sim).imag, label='Simulated Data')\n",
    "    plt.title(ECM_TYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "df15932a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_33616\\2163392410.py:161: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  spl = UnivariateSpline(cdf_x, cdf_y, k=3, s=s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "_nf_drt = []\n",
    "_noise_drt = []\n",
    "_theo_pdf_list = []\n",
    "_theo_cdf_list = []\n",
    "\n",
    "\n",
    "pdf_x = np.logspace(-np.log10(2*np.pi*f.max()), -np.log10(2*np.pi*f.min()), 501)\n",
    "\n",
    "for i in range(_f.shape[0]):\n",
    "    _drt = _drt_list[i]\n",
    "    _nf = _nf_list[i]\n",
    "\n",
    "    _R_i, _C_i, _tau_i = _drt[0,:], _drt[1,:], _drt[2,:]\n",
    "    _R_nf, _C_nf, _tau_nf = _nf[0,:], _nf[1,:], _nf[2,:]\n",
    "\n",
    "\n",
    "    # nf\n",
    "    # pdf_x, pdf_est = Tikhonov_IPDF2PDF(_tau_nf, _R_nf, lam = 1e-3)\n",
    "    # _nf_drt.append(np.array([pdf_x, pdf_est]))\n",
    "\n",
    "    pdf_est = ipdf_to_pdf(_tau_nf, _R_nf, pdf_x, s=1)\n",
    "    _nf_drt.append(np.array([pdf_x, pdf_est]))\n",
    "\n",
    "    # noise\n",
    "    # pdf_x, pdf_est = Tikhonov_IPDF2PDF(_tau_i, _R_i, lam = 1e-3)\n",
    "    # _noise_drt.append(np.array([pdf_x, pdf_est]))\n",
    "\n",
    "    pdf_est = ipdf_to_pdf(_tau_i, _R_i, pdf_x, s=1)\n",
    "    _noise_drt.append(np.array([pdf_x, pdf_est]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "theo_tau_list = np.logspace(-np.log10(2*np.pi*f.max()), -np.log10(2*np.pi*f.min()), 500)\n",
    "\n",
    "D_den_theo = np.array([CPE_G2(i) for i in theo_tau_list]) * R1\n",
    "_theo_pdf_list.append(np.array([theo_tau_list, D_den_theo]))\n",
    "\n",
    "D_den_theo = np.array([CPE_F2(i) for i in theo_tau_list]) * R1\n",
    "_theo_cdf_list.append(np.array([theo_tau_list, D_den_theo]))\n",
    "\n",
    "\n",
    "pdf_x_all, pdf_est_all = Tikhonov_IPDF2PDF_list(_drt_list, lam = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232d02c",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fig, axis = plt.subplots(1,1)\n",
    "# axis = [axis]\n",
    "# # axis = axis.flatten()\n",
    "# cmap = plt.get_cmap('rainbow_r')\n",
    "# for i in range(_f.shape[0]):\n",
    "#     if i>4: continue\n",
    "#     _R_i, _C_i, _tau_i = _drt_list[i][0,:], _drt_list[i][1,:], _drt_list[i][2,:]\n",
    "#     _R_nf, _C_nf, _tau_nf = _nf_list[i][0,:], _nf_list[i][1,:], _nf_list[i][2,:]\n",
    "\n",
    "#     _pdf_x_nf, _pdf_est_nf = _nf_drt[i][0,:], _nf_drt[i][1,:]\n",
    "#     _pdf_x_drt, _pdf_est_drt = _noise_drt[i][0,:], _noise_drt[i][1,:]\n",
    "#     theo_den_tau, D_den_theo = _theo_pdf_list[0][0,:], _theo_pdf_list[0][1,:]\n",
    "\n",
    "\n",
    "#     axis[0].scatter(_pdf_x_nf, _pdf_est_nf, s=2, color='blue')\n",
    "#     axis[0].scatter(_pdf_x_drt, _pdf_est_drt, s=2, color='red')\n",
    "#     axis[0].scatter(theo_den_tau, D_den_theo, s=2, color='green')\n",
    "\n",
    "    \n",
    "#     # axis[0].scatter(_tau_i, _R_i, s=10, color='orange')\n",
    "#     # axis[0].scatter(_tau_nf, _R_nf, s=10, color='orange')\n",
    "\n",
    "\n",
    "# # axis[0].scatter(pdf_x_all, pdf_est_all, s=10, color='orange')\n",
    "\n",
    "# axis[0].set_xscale('log')\n",
    "# axis[0].set_yscale('log')\n",
    "# # axis[0].set_aspect('equal')\n",
    "# # axis[1].set_xscale('log')\n",
    "# # axis[1].set_yscale('log')\n",
    "# # axis[1].set_aspect('equal')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e053318",
   "metadata": {},
   "source": [
    "#### CDF Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c8fb2",
   "metadata": {},
   "source": [
    "##### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d06ba03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "def ipdf_to_ipdf_loess(ipdf_x, ipdf_p, pdf_x):\n",
    "    pdf_x = np.log10(pdf_x)\n",
    "    ipdf_x_log = np.log10(ipdf_x)\n",
    "    # 排序输入数据（确保x单调增加）\n",
    "    idx = np.argsort(ipdf_x_log)\n",
    "    ipdf_x_log = np.array(ipdf_x_log)[idx]\n",
    "    p = np.array(ipdf_p)[idx]\n",
    "\n",
    "    # 确保概率非负并归一化\n",
    "    # p = np.clip(p, 0, None)\n",
    "    p_sum = p.sum()\n",
    "    if p_sum > 0:\n",
    "        p = p / p_sum\n",
    "    # 计算累积分布函数 (CDF) 在每个边界处的值\n",
    "    p_log = np.log10(p)\n",
    "\n",
    "    \n",
    "    loess_result = lowess(p_log, ipdf_x_log, frac=0.05)\n",
    "    ipdf_est = np.interp(pdf_x, loess_result[:,0], loess_result[:,1])\n",
    "\n",
    "    pdf_x = np.power(10, pdf_x)\n",
    "    ipdf_est = np.power(10, ipdf_est)\n",
    "\n",
    "    # ipdf_est_sum = np.sum(ipdf_est)\n",
    "    # p_sum = p_sum \n",
    "\n",
    "\n",
    "    return pdf_x, ipdf_est * p_sum\n",
    "\n",
    "\n",
    "\n",
    "def ipdf_to_ipdf_gauss(ipdf_x, ipdf_p, pdf_x):\n",
    "    pdf_x = np.log10(pdf_x)\n",
    "    ipdf_x_log = np.log10(ipdf_x)\n",
    "    # 排序输入数据（确保x单调增加）\n",
    "    idx = np.argsort(ipdf_x_log)\n",
    "    ipdf_x_log = np.array(ipdf_x_log)[idx]\n",
    "    p = np.array(ipdf_p)[idx]\n",
    "\n",
    "    # 确保概率非负并归一化\n",
    "    # p = np.clip(p, 0, None)\n",
    "    p_sum = p.sum()\n",
    "    if p_sum > 0:\n",
    "        p = p / p_sum\n",
    "    # 计算累积分布函数 (CDF) 在每个边界处的值\n",
    "    p_log = np.log10(p)\n",
    "\n",
    "    d = np.diff(p)\n",
    "    sigma_noise = 1.4826 * np.median(np.abs(d - np.median(d))) \n",
    "\n",
    "    \n",
    "    X = ipdf_x_log.reshape(-1, 1)\n",
    "    # kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + WhiteKernel(noise_level=sigma_noise**2, noise_level_bounds=(1e-5, 1e-1))\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + WhiteKernel(noise_level=sigma_noise**2)\n",
    "\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0, normalize_y=True)\n",
    "    gpr.fit(X, p_log)\n",
    "    \n",
    "    ipdf_est, ipdf_std = gpr.predict(pdf_x.reshape(-1,1), return_std=True)\n",
    "\n",
    "    pdf_x = np.power(10, pdf_x)\n",
    "    ipdf_est = np.power(10, ipdf_est)\n",
    "    ipdf_std = np.power(10, ipdf_std)\n",
    "\n",
    "    ipdf_est_sum = np.sum(ipdf_est)\n",
    "    p_sum = p_sum / ipdf_est_sum\n",
    "\n",
    "    logger.info(f\"{ipdf_est_sum}\")\n",
    "\n",
    "    return pdf_x, ipdf_est * p_sum, ipdf_std * p_sum\n",
    "\n",
    "\n",
    "def ipdf_to_ipdf(ipdf_x, ipdf_p, pdf_x):\n",
    "    pdf_x = np.log10(pdf_x)\n",
    "    ipdf_x_log = np.log10(ipdf_x)\n",
    "    # 排序输入数据（确保x单调增加）\n",
    "    idx = np.argsort(ipdf_x_log)\n",
    "    ipdf_x_log = np.array(ipdf_x_log)[idx]\n",
    "    p = np.array(ipdf_p)[idx]\n",
    "\n",
    "    # 确保概率非负并归一化\n",
    "    # p = np.clip(p, 0, None)\n",
    "    p_sum = p.sum()\n",
    "    if p_sum > 0:\n",
    "        p = p / p_sum\n",
    "    # 计算累积分布函数 (CDF) 在每个边界处的值\n",
    "    # p = np.log10(p)\n",
    "\n",
    "    d = np.diff(p)\n",
    "    sigma_noise = 1.4826 * np.median(np.abs(d - np.median(d))) \n",
    "\n",
    "    logger.info(f\"{sigma_noise}\") # rough noise level on differences\n",
    "\n",
    "    spl = UnivariateSpline(ipdf_x_log, p, k=3, s=sigma_noise)\n",
    "    # ipdf_est = np.power(10, spl(pdf_x))\n",
    "    ipdf_est = spl(pdf_x)\n",
    "    pdf_x = np.power(10, pdf_x)\n",
    "\n",
    "    \n",
    "    # ipdf_est_sum = np.sum(ipdf_est)\n",
    "    # p_sum = p_sum / ipdf_est_sum\n",
    "\n",
    "    return pdf_x, ipdf_est * p_sum\n",
    "\n",
    "\n",
    "def ipdf_to_cdf(ipdf_x, ipdf_p, pdf_x, s=0.001):\n",
    "    pdf_x = np.log10(pdf_x)\n",
    "    ipdf_x = np.log10(ipdf_x)\n",
    "    # 排序输入数据（确保x单调增加）\n",
    "    idx = np.argsort(ipdf_x)\n",
    "    x = np.array(ipdf_x)[idx]\n",
    "    p = np.array(ipdf_p)[idx]\n",
    "    n = len(x)\n",
    "    # 估计每个IPDF点对应的区间边界（取相邻中点的中间为边界）\n",
    "    edges = np.empty(n+1)\n",
    "    edges[1:n] = (x[:-1] + x[1:]) / 2\n",
    "    # 外推两端边界\n",
    "    edges[0] = x[0] - (x[1] - x[0]) / 2 if n>1 else x[0] - 0.5\n",
    "    edges[n] = x[-1] + (x[-1] - x[-2]) / 2 if n>1 else x[0] + 0.5\n",
    "\n",
    "    # 确保概率非负并归一化\n",
    "    p = np.clip(p, 0, None)\n",
    "    # p_sum = p.sum()\n",
    "    # if p_sum > 0:\n",
    "    #     p = p / p_sum\n",
    "    # 计算累积分布函数 (CDF) 在每个边界处的值\n",
    "    cdf_x = edges\n",
    "    cdf_y = np.concatenate(([1e-10], np.cumsum(p)))\n",
    "    cdf_y = np.log10(cdf_y)\n",
    "    \n",
    "    spl = UnivariateSpline(cdf_x, cdf_y, k=3, s=s)\n",
    "    cdf_y = np.power(10, spl(pdf_x))\n",
    "    cdf_x = np.power(10, pdf_x)\n",
    "\n",
    "    # PDF\n",
    "    pdf_y = spl.derivative()(pdf_x)\n",
    "    # pdf_y = cdf_y * (np.log(10) * pdf_y)\n",
    "    pdf_y = cdf_y * (pdf_y)\n",
    "\n",
    "    return cdf_x, cdf_y, pdf_y\n",
    "    # return np.power(10, cdf_x), np.power(10, cdf_y)\n",
    "    # return cdf_y\n",
    "\n",
    "## 横向对比单纯矩阵微分和加权微分，\n",
    "#   PCHIP这种分段积分微分效果是最好的\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "def ipdf_to_pdf_pchip(ipdf_x, ipdf_p, pdf_x):\n",
    "    # 排序输入数据并计算CDF点（类似前述步骤）\n",
    "    idx = np.argsort(ipdf_x)\n",
    "    x_sorted = np.array(ipdf_x)[idx]\n",
    "    p_sorted = np.clip(np.array(ipdf_p)[idx], 0, None)\n",
    "    n = len(x_sorted)\n",
    "    p_total = p_sorted.sum()\n",
    "    if p_total == 0:\n",
    "        raise ValueError(\"ipdf_p sum is zero; cannot form CDF.\")\n",
    "    p_sorted = p_sorted / p_total\n",
    "\n",
    "\n",
    "    # 构建PCHIP插值器（确保extrapolate合理处理边界外点）\n",
    "    # cdf_vals = np.concatenate(([1e-16], np.cumsum(p_sorted)))\n",
    "    # edges = np.empty(n+1)\n",
    "    # edges[1:n] = (x_sorted[:-1] + x_sorted[1:]) / 2.0\n",
    "    # edges[0] = x_sorted[0] - (x_sorted[1] - x_sorted[0]) / 2 if n > 1 else x_sorted[0] - 0.5\n",
    "    # edges[n] = x_sorted[-1] + (x_sorted[-1] - x_sorted[-2]) / 2 if n > 1 else x_sorted[-1] + 0.5\n",
    "    # log_edges = np.log10(edges)\n",
    "\n",
    "    # cdf_vals = np.cumsum(p_sorted)\n",
    "    # edges = x_sorted\n",
    "    # log_edges = np.log10(edges)\n",
    "\n",
    "    cdf_vals = np.concatenate(([1e-16], np.cumsum(p_sorted)))\n",
    "    edges = np.empty(n+1)\n",
    "    x_sorted = np.log10(x_sorted)\n",
    "    edges[1:n] = (x_sorted[:-1] + x_sorted[1:]) / 2.0\n",
    "    edges[0] = x_sorted[0] - (x_sorted[1] - x_sorted[0]) / 2 if n > 1 else x_sorted[0] - 0.5\n",
    "    edges[n] = x_sorted[-1] + (x_sorted[-1] - x_sorted[-2]) / 2 if n > 1 else x_sorted[-1] + 0.5\n",
    "    log_edges = edges\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cdf_vals = np.log10(cdf_vals)\n",
    "    pchip = PchipInterpolator(log_edges, cdf_vals, extrapolate=False)\n",
    "    # 计算拟合CDF和PDF\n",
    "    log_pdfx = np.log10(pdf_x)\n",
    "    cdf_fitted = pchip(log_pdfx)\n",
    "    # cdf_fitted = np.clip(cdf_fitted, 0.0, 1.0)\n",
    "    # 计算导数并转换为PDF\n",
    "    # d_cdf_dlogx = pchip.derivative()(log_pdfx)  # PCHIP返回一个PPoly，可直接求导\n",
    "    # pdf_fitted = d_cdf_dlogx / (pdf_x * math.log(10))\n",
    "\n",
    "\n",
    "    d_cdf_dlogx = pchip.derivative()(log_pdfx)\n",
    "    # pdf_fitted = d_cdf_dlogx\n",
    "\n",
    "    cdf_fitted = 10**cdf_fitted\n",
    "    pdf_fitted = cdf_fitted * d_cdf_dlogx\n",
    "\n",
    "\n",
    "    return pdf_x, cdf_fitted * p_total, pdf_fitted * p_total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ipdf_to_pdf_weighted(ipdf_x, ipdf_p, pdf_x, s=0.001):\n",
    "    # 1. 准备输入数据：转换为log10(x)，计算CDF（线性刻度）\n",
    "    idx = np.argsort(ipdf_x)\n",
    "    x_sorted = np.array(ipdf_x)[idx]\n",
    "    p_sorted = np.clip(np.array(ipdf_p)[idx], 0, None)\n",
    "    n = len(x_sorted)\n",
    "    # 计算每个点对应的CDF值\n",
    "    p_total = p_sorted.sum()\n",
    "    if p_total == 0:\n",
    "        raise ValueError(\"ipdf_p sum is zero; cannot form CDF.\")\n",
    "    p_sorted = p_sorted / p_total\n",
    "    cdf_vals = np.concatenate(([0], np.cumsum(p_sorted)))  # CDF从0开始, 末项应为1\n",
    "    # 构造x的边界数组（在log尺度下插值）\n",
    "    edges = np.empty(n+1)\n",
    "    edges[1:n] = (x_sorted[:-1] + x_sorted[1:]) / 2.0\n",
    "    edges[0] = x_sorted[0] - (x_sorted[1] - x_sorted[0]) / 2 if n > 1 else x_sorted[0] - 0.5\n",
    "    edges[n] = x_sorted[-1] + (x_sorted[-1] - x_sorted[-2]) / 2 if n > 1 else x_sorted[-1] + 0.5\n",
    "    log_edges = np.log10(edges)\n",
    "    # 2. 设置权重：尾部和两端权重较高\n",
    "    w = np.ones_like(cdf_vals)\n",
    "    w[0] = w[-1] = 1e3           # 确保cdf(左端)=0和cdf(右端)=1被严格拟合\n",
    "    # 提高末尾若干点权重以强调尾部拟合精度（这里以最后5点为例逐步增加）\n",
    "    m = min(5, len(w)-1)\n",
    "    for i in range(1, m+1):\n",
    "        w[-i] = max(w[-i], 100 * i)  # 尾部权重从100逐渐增加至500\n",
    "    # 3. 样条拟合（log10(x) vs CDF）\n",
    "    spl = UnivariateSpline(log_edges, cdf_vals, w=w, k=3, s=s)\n",
    "    # 4. 计算输出CDF和PDF\n",
    "    log_pdfx = np.log10(pdf_x)\n",
    "    cdf_fitted = spl(log_pdfx)\n",
    "    # 确保数值稳定在[0,1]范围内\n",
    "    cdf_fitted = np.clip(cdf_fitted, 0.0, 1.0)\n",
    "    # 样条导数 d(CDF)/d(logx)\n",
    "    d_cdf_dlogx = spl.derivative()(log_pdfx)\n",
    "    # 转换为 d(CDF)/dx\n",
    "    # pdf_fitted = d_cdf_dlogx / (pdf_x * math.log(10))\n",
    "    pdf_fitted = d_cdf_dlogx \n",
    "    return pdf_x, cdf_fitted*p_total, pdf_fitted*p_total\n",
    "\n",
    "\n",
    "def dtau_distribution(tau_list):\n",
    "    dtau_list   = [[0.5*(np.log10(_tau[:-1])+np.log10(_tau[1:])), \n",
    "                     np.diff(np.log10(_tau[:]))] for _tau in tau_list]\n",
    "    dtau_list   = np.concatenate(dtau_list, axis=1) \n",
    "\n",
    "    loess_result = lowess(dtau_list[1,:], dtau_list[0,:], frac=0.1)\n",
    "    loess_result = loess_result.T\n",
    "    tau_dt_list = 10**loess_result\n",
    "    return tau_dt_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 单纯的equidistribution，相较于均匀采样显著改进，\n",
    "# 但是PDF抖动剧烈。\n",
    "def resample_from_deltax(x_dx_array, num_points=None):\n",
    "    \n",
    "    # x = np.asarray(x_dx_array[0])\n",
    "    # dx = np.asarray(x_dx_array[1])\n",
    "    x = np.log10(x_dx_array[0])\n",
    "    dx = np.log10(x_dx_array[1])\n",
    "    dx = 1/dx\n",
    "    \n",
    "\n",
    "    _x_90 = np.quantile(x, [0.05, 0.95])\n",
    "    _x_mask = (x >= _x_90[0]) & (x <= _x_90[1])\n",
    "    x = x[_x_mask]\n",
    "    dx = dx[_x_mask]\n",
    "\n",
    "    if num_points is None:\n",
    "        num_points = len(x)\n",
    "    \n",
    "    # 累计弧长（这里假设 Δx >= 0）\n",
    "    # S = np.cumsum(dx)\n",
    "    # S = np.trapezoid(dx, x)\n",
    "    trapz_area = 0.5 * (dx[:-1]+dx[1:])*dx[1:]\n",
    "    \n",
    "    trapz_area = np.concatenate([[0.5*dx[0]*dx[0]], trapz_area])\n",
    "    S = np.cumsum(trapz_area)\n",
    "\n",
    "    S -= S[0]  # 从0开始\n",
    "    \n",
    "    # 在累计弧长上等间隔采样\n",
    "    S_target = np.linspace(S[0], S[-1], num_points)\n",
    "    \n",
    "    # 反插值得到新的 x\n",
    "    x_resampled = np.interp(S_target, S, x)\n",
    "    \n",
    "    return 10**x_resampled\n",
    "    # return x_resampled\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline, CubicSpline\n",
    "\n",
    "## 好方法！相较于单纯的equidistribution，能PDF连续\n",
    "def resample_equidistribution_C2(\n",
    "    x_dx_array,\n",
    "    n_points = None,    # 目标点数（包含两端）\n",
    "    keep_frac=0.95,   # 仅在中间 keep_frac 的范围内重采样（例如 0.95 即 2.5%~97.5%）\n",
    "    smooth_s=1e-2,    # 对 log m_t 的平滑强度（越大越平滑）\n",
    "):\n",
    "\n",
    "    x = np.log10(x_dx_array[0])\n",
    "    dx = np.log10(x_dx_array[1])\n",
    "    # x = np.log10(x_grid)\n",
    "    # dx = np.log10(deltax_grid)\n",
    "    dx = 1/dx\n",
    "    # dx = -dx\n",
    "\n",
    "    if n_points is None:\n",
    "        n_points = len(x)    \n",
    "\n",
    "\n",
    "    # _x_90 = np.quantile(x, [0.05, 0.95])\n",
    "    _x_90 = np.quantile(x, [0.025, 0.975])\n",
    "    _x_mask = (x >= _x_90[0]) & (x <= _x_90[1])\n",
    "    x = x[_x_mask]\n",
    "    dx = dx[_x_mask]\n",
    "\n",
    "\n",
    "    t = x\n",
    "    mt_raw = dx\n",
    "\n",
    "    # 在 log(mt) 上做平滑样条，保证正性 & C2\n",
    "    # spl_logmt = UnivariateSpline(t, np.log(mt_raw), s=smooth_s, k=3)\n",
    "    spl_logmt = UnivariateSpline(t, mt_raw, s=smooth_s, k=3)\n",
    "    logmt = spl_logmt(t)\n",
    "    # mt = np.exp(logmt)\n",
    "    mt = logmt\n",
    "\n",
    "    # 3) 数值积分 S(t)（用梯形法在 t 上）\n",
    "    S = np.zeros_like(t)\n",
    "    S[1:] = np.cumsum(0.5*(mt[1:]+mt[:-1])*(t[1:]-t[:-1]))\n",
    "    # 目标均匀参数（等分布）：ξ∈[0,1]，对应 S_target∈[0,S_end]\n",
    "    S_end = S[-1]\n",
    "    xi = np.linspace(0.0, 1.0, n_points)\n",
    "    S_target = xi * S_end\n",
    "    # 反插值得到离散 t_i\n",
    "    t_nodes = np.interp(S_target, S, t)\n",
    "    x_nodes = 10.0**t_nodes\n",
    "    x_resampled = x_nodes\n",
    "    return x_resampled\n",
    "\n",
    "    # 4) 构造 C2 参数化：t(ξ) 三次样条（自然边界），x(ξ)=10^{t(ξ)}\n",
    "    t_spline = CubicSpline(xi, t_nodes, bc_type='natural')  # C2\n",
    "    # 给出两个实用返回：离散点 & 可评估的 C2 映射\n",
    "    def x_of_xi(xi_eval):\n",
    "        te = t_spline(xi_eval)         # C2\n",
    "        return 10.0**te\n",
    "\n",
    "    return x_resampled, x_of_xi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332768d3",
   "metadata": {},
   "source": [
    "##### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3f12a273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x219fbc81b10>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt_lines   = []\n",
    "plt_labels  = []\n",
    "\n",
    "fig, axis = plt.subplots(1,1)\n",
    "axis = [axis]\n",
    "# axis = axis.flatten()\n",
    "cmap = plt.get_cmap('rainbow_r')\n",
    "\n",
    "\n",
    "axis[0].set_xscale('log')\n",
    "axis[0].set_yscale('log')\n",
    "# axis[1].set_xscale('log')\n",
    "# axis[1].set_yscale('log')\n",
    "\n",
    "\n",
    "# R_list          = [_drt[0,1:-1] for _drt in _nf_list]\n",
    "# tau_list        = [_drt[2,1:-1] for _drt in _nf_list]\n",
    "R_list          = [_drt[0,1:-1] for _drt in _drt_list]\n",
    "tau_list        = [_drt[2,1:-1] for _drt in _drt_list]\n",
    "# R_list          = [_drt[0,:] for _drt in _drt_list]\n",
    "# tau_list        = [_drt[2,:] for _drt in _drt_list]\n",
    "\n",
    "R_list_conc     = np.concatenate(R_list, axis=0) / len(R_list)\n",
    "# R_list_conc     = np.concatenate(R_list, axis=0)\n",
    "tau_list_conc   = np.concatenate(tau_list, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Tau Discussion\n",
    "tau_dt_list = dtau_distribution(tau_list)\n",
    "# tau_re = resample_from_deltax(tau_dt_list, num_points=41)\n",
    "# tau_re = resample_from_deltax(tau_dt_list)\n",
    "tau_re = resample_equidistribution_C2(tau_dt_list)\n",
    "# tau_re = resample_equidistribution_C2(tau_dt_list[0,:], tau_dt_list[1,:],n_points=tau_dt_list[0,:].shape[0])\n",
    "\n",
    "# axis[1].scatter(tau_dt_list[0,:], tau_dt_list[1,:], s=10, color='orange')\n",
    "# axis[1].scatter(tau_re[1:], np.exp(np.diff(np.log(tau_re))*100), s=10, color='red')\n",
    "\n",
    "\n",
    "# pdf_x = np.logspace(math.floor(np.log10(tau_list_conc.min())), math.ceil(np.log10(tau_list_conc.max())), 501)\n",
    "# pdf_x = np.logspace(np.log10(tau_list_conc.min()), np.log10(tau_list_conc.max()), 501)\n",
    "pdf_x = tau_re\n",
    "# pdf_x = np.logspace(-7, 0, len(tau_re))\n",
    "\n",
    "\n",
    "## PDF Discussion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "# poi_i = 0\n",
    "# for i in [0.001,0.01,0.1]:\n",
    "#     R_list_conc_loess = lowess(np.log(R_list_conc), np.log(tau_list_conc), frac=i, it=3, return_sorted=False)\n",
    "#     R_list_conc_loess = np.exp(R_list_conc_loess)\n",
    "#     axis[0].scatter(tau_list_conc, R_list_conc_loess, s=10, color=cmap(poi_i/3))\n",
    "#     poi_i = poi_i+1\n",
    "\n",
    "# ipdf_x, ipdf_est = ipdf_to_ipdf(tau_list_conc, R_list_conc, pdf_x)\n",
    "# ipdf_x, ipdf_est, _ = ipdf_to_ipdf_gauss(tau_list_conc, R_list_conc, tau_list_conc)\n",
    "# ipdf_x, ipdf_est, _ = ipdf_to_ipdf_gauss(tau_list_conc, R_list_conc, pdf_x)\n",
    "\n",
    "# ipdf_x, ipdf_est = ipdf_to_ipdf_loess(tau_list_conc, R_list_conc, tau_list_conc)\n",
    "ipdf_x, ipdf_est = ipdf_to_ipdf_loess(tau_list_conc, R_list_conc, pdf_x)\n",
    "# ipdf_x, ipdf_est = ipdf_to_ipdf_loess(tau_list_conc, R_list_conc, _tau_nf)\n",
    "\n",
    "# ipdf_x, ipdf_est = tau_list_conc, R_list_conc\n",
    "\n",
    "\n",
    "\n",
    "# axis[0].scatter(tau_list_conc, R_list_conc, s=10, color='red')\n",
    "# _line1 = axis[0].scatter(ipdf_x, ipdf_est*100, s=2, color='orange')\n",
    "\n",
    "# plt_lines.append(_line1)\n",
    "# plt_labels.append(f\"IPDF Equid Resample with C2 Continuity\")\n",
    "\n",
    "\n",
    "theo_den_tau = tau_list_conc\n",
    "D_den_theo = np.array([CPE_G2(i) for i in tau_list_conc]) * R1\n",
    "\n",
    "theo_mass_tau = tau_list_conc\n",
    "D_mass_theo = np.array([CPE_F2(i) for i in tau_list_conc]) * R1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_pdf_weighted(tau_list_conc, R_list_conc, pdf_x, s=0.01)\n",
    "# cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_pdf_pchip(tau_list_conc, R_list_conc, pdf_x)\n",
    "# cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_cdf(tau_list_conc, R_list_conc, pdf_x, s=0.1)\n",
    "\n",
    "\n",
    "pdf_x = np.logspace(math.floor(np.log10(tau_list_conc.min())), math.ceil(np.log10(tau_list_conc.max())), 501)\n",
    "# cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_cdf(tau_list_conc, R_list_conc, pdf_x, s=0.1)\n",
    "cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_pdf_pchip(ipdf_x, ipdf_est, pdf_x)\n",
    "\n",
    "\n",
    "# axis[0].scatter(cdf_nf_x, cdf_nf, s=10, color='red',marker='x')\n",
    "_line2 = axis[0].scatter(cdf_nf_x, pdf_nf, s=10, color='red')\n",
    "\n",
    "plt_lines.append(_line2)\n",
    "plt_labels.append(f\"PDF with Spline\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(_f.shape[0]):\n",
    "    # if i!=4: continue\n",
    "    _R_i, _C_i, _tau_i = _drt_list[i][0,1:-1], _drt_list[i][1,1:-1], _drt_list[i][2,1:-1]\n",
    "    _R_nf, _C_nf, _tau_nf = _nf_list[i][0,1:-1], _nf_list[i][1,1:-1], _nf_list[i][2,1:-1]\n",
    "    # _R_i, _C_i, _tau_i = _drt_list[i][0,:], _drt_list[i][1,:], _drt_list[i][2,:]\n",
    "    # _R_nf, _C_nf, _tau_nf = _nf_list[i][0,:], _nf_list[i][1,:], _nf_list[i][2,:]\n",
    "\n",
    "    # theo_den_tau, D_den_theo = _theo_pdf_list[0][0,:], _theo_pdf_list[0][1,:]\n",
    "    # theo_mass_tau, D_mass_theo = _theo_cdf_list[0][0,:], _theo_cdf_list[0][1,:]\n",
    "\n",
    "\n",
    "\n",
    "    # _tau_i, _R_i = ipdf_to_ipdf_loess(_tau_i, _R_i, pdf_x)\n",
    "    # _tau_nf, _R_nf = ipdf_to_ipdf_loess(_tau_nf, _R_nf, _tau_nf)\n",
    "\n",
    "\n",
    "    # cdf_i_x, cdf_i, pdf_i = ipdf_to_cdf(_tau_i, _R_i, pdf_x, s=1)\n",
    "    # cdf_i_x, cdf_i, pdf_i = ipdf_to_pdf_pchip(_tau_i, _R_i, pdf_x)\n",
    "\n",
    "    # cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_cdf(_tau_nf, _R_nf, pdf_x, s=0.001)\n",
    "    # cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_pdf_pchip(_tau_nf, _R_nf, pdf_x)\n",
    "    # cdf_nf_x, cdf_nf, pdf_nf = ipdf_to_pdf_weighted(_tau_nf, _R_nf, pdf_x, s=0.0001)\n",
    "\n",
    "\n",
    "    ## CDF\n",
    "    # axis[0].scatter(cdf_nf_x, cdf_nf, s=2, color='blue')\n",
    "    # axis[0].scatter(cdf_i_x, cdf_i, s=2, color='red')\n",
    "    # axis[0].scatter(theo_mass_tau, D_mass_theo, s=2, color='green')\n",
    "\n",
    "\n",
    "    ## PDF\n",
    "    # axis[0].scatter(cdf_nf_x, pdf_nf, s=2, color='blue')\n",
    "    # axis[0].scatter(cdf_i_x, pdf_i, s=2, color='red')\n",
    "    _line0 = axis[0].scatter(theo_den_tau, D_den_theo, s=2, color='green')\n",
    "\n",
    "    ## Raw Data    \n",
    "    # axis[0].scatter(_tau_i, _R_i, s=10, color='orange')\n",
    "    # axis[0].scatter(_tau_nf, _R_nf, s=10, color='green')\n",
    "\n",
    "\n",
    "    ## Tau Discussion\n",
    "    # axis[1].scatter(np.sqrt(_tau_i[:-1]*_tau_i[1:]), np.exp(np.diff(np.log(_tau_i))), s=1, color='gray', label='Noise')\n",
    "    # axis[1].scatter(np.sqrt(_tau_nf[:-1]*_tau_nf[1:]), np.exp(np.diff(np.log(_tau_nf))), s=10, color='blue', label='Noise Free')\n",
    "\n",
    "    # _tau_i_re = resample_from_deltax([_tau_i[1:], np.exp(np.diff(np.log(_tau_i)))])\n",
    "    # axis[0].scatter(_tau_i_re[1:], np.exp(np.diff(np.log(_tau_i_re))), s=10, color='green', label='Noise Free')\n",
    "\n",
    "# axis[0].scatter(pdf_x_all, pdf_est_all, s=10, color='orange')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# axis[0].set_xscale('log')\n",
    "# axis[0].set_yscale('log')\n",
    "# axis[0].set_aspect('equal')\n",
    "# axis[1].set_xscale('log')\n",
    "# axis[1].set_yscale('log')\n",
    "# axis[1].set_aspect('equal')\n",
    "\n",
    "\n",
    "# axis[0].legend()\n",
    "\n",
    "\n",
    "plt_lines.append(_line0)\n",
    "plt_labels.append(f\"Exact\")\n",
    "\n",
    "axis[0].legend(plt_lines, plt_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647634a",
   "metadata": {},
   "source": [
    "#### Loewner Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f3c4b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(_f.shape[0]):\n",
    "    if i != 10: continue\n",
    "    L, Ls, H_left, H_right = Loewner_Framework(_f[i,:], _Z[i,:], REALFLAG=True)\n",
    "    Ek, Ak, Bk, Ck = state_space_model(L, Ls, H_left, H_right)\n",
    "    R_i, C_i, tau_i = DRT_Transform(Ek, Ak, Bk, Ck, REALFLAG=False)\n",
    "    R_real, C_real, tau_real = DRT_Transform(Ek, Ak, Bk, Ck, REALFLAG=True)\n",
    "    # _drt_list.append(np.array([_R_i, _C_i, _tau_i]))\n",
    "\n",
    "    \n",
    "fig, axis = plt.subplots(1,2)\n",
    "axis = axis.flatten()\n",
    "\n",
    "axis[0].scatter(tau_i[R_i.real>0], R_i[R_i.real>0].real, s=20, color='red')\n",
    "axis[0].scatter(tau_i[R_i.real<0], -R_i[R_i.real<0].real, s=20,color='blue')\n",
    "# axis[0].scatter(np.abs(tau_i), np.abs(R_i), s=5,color='green')\n",
    "axis[0].scatter(tau_real, R_real , s=10, color='orange')\n",
    "\n",
    "axis[1].scatter(tau_i[R_i.imag>0], R_i[R_i.imag>0].imag, s=20, color='red')\n",
    "axis[1].scatter(tau_i[R_i.imag<0], -R_i[R_i.imag<0].imag, s=20, color='blue')\n",
    "axis[1].scatter(tau_real, R_real.imag+1e-10 , s=10, color='orange')\n",
    "\n",
    "axis[0].set_xscale('log')\n",
    "axis[0].set_yscale('log')\n",
    "axis[1].set_xscale('log')\n",
    "axis[1].set_yscale('log')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "76dc261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "real_mask = (tau_i.real>0)\n",
    "tau_i_re = np.real(tau_i[real_mask])\n",
    "R_i_re = np.real(R_i[real_mask])\n",
    "\n",
    "# Auto Sorted bu unique               \n",
    "_, _idx, _cnt = np.unique(tau_i_re, return_index=True, return_counts=True)\n",
    "\n",
    "tau_i_re = tau_i_re[_idx]\n",
    "R_i_re = R_i_re[_idx] * _cnt\n",
    "\n",
    "tau_i_re = tau_i_re[_cnt==1]\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(1,1)\n",
    "# axis = axis.flatten()\n",
    "axis = [axis]\n",
    "\n",
    "axis[0].scatter(tau_i.real,tau_i.imag, s=20, color='blue')\n",
    "axis[0].scatter(tau_i_re.real,tau_i_re.imag, s=5, color='red')\n",
    "axis[0].set_xscale('log')\n",
    "# axis[0].set_yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9110f0",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd7911",
   "metadata": {},
   "source": [
    "### Tikhonov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52edce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import lsq_linear, nnls\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: build integration matrix A\n",
    "# -----------------------------\n",
    "def build_A(bin_edges, grid):\n",
    "    \"\"\"\n",
    "    构造 A 矩阵：每个测量区间（由 bin_edges 给出）对 grid 中每个小单元的积分权重。\n",
    "    bin_edges: shape (M+1,) 测量区间边界，测量 i 对应 [bin_edges[i], bin_edges[i+1]]\n",
    "    grid: shape (N+1,) 细分网格的边界（通常可以等于 bin_edges 或更细）\n",
    "    返回 A shape (M, N) ，p_j 定义在 grid 单元上（中心或cell-average）\n",
    "    \"\"\"\n",
    "    M = len(bin_edges)-1\n",
    "    N = len(grid)-1\n",
    "    A = np.zeros((M, N))\n",
    "    # 对每个测量区间 i，对每个细网格单元 j 计算重叠长度\n",
    "    for i in range(M):\n",
    "        L, R = bin_edges[i], bin_edges[i+1]\n",
    "        # for each cell j\n",
    "        for j in range(N):\n",
    "            a, b = grid[j], grid[j+1]\n",
    "            overlap = max(0.0, min(R, b) - max(L, a))\n",
    "            A[i, j] = overlap\n",
    "    return A\n",
    "\n",
    "# -----------------------------\n",
    "# Method 1: naive IPDF / Δx\n",
    "# -----------------------------\n",
    "def naive_pdf_from_ipdf(ipdf, bin_edges):\n",
    "    widths = np.diff(bin_edges)\n",
    "    pdf = ipdf / widths\n",
    "    grid_centers = 0.5*(bin_edges[:-1] + bin_edges[1:])\n",
    "    return grid_centers, pdf\n",
    "\n",
    "# -----------------------------\n",
    "# Method 2: Tikhonov (regularized LS), optionally non-negative\n",
    "# -----------------------------\n",
    "def tikhonov_inversion(A, y, lam=1e-3, nonneg=True, diff_order=2):\n",
    "    \"\"\"\n",
    "    Solve min ||A p - y||^2 + lam ||L p||^2\n",
    "    If nonneg: enforce p >= 0 via lsq_linear\n",
    "    diff_order: 0 -> identity, 1 -> first diff, 2 -> second diff\n",
    "    \"\"\"\n",
    "    N = A.shape[1]\n",
    "    # build L\n",
    "    if diff_order == 0:\n",
    "        L = np.eye(N)\n",
    "    elif diff_order == 1:\n",
    "        L = np.eye(N, k=0) - np.eye(N, k=1)\n",
    "        L = L[:-1]  # shape (N-1, N)\n",
    "    elif diff_order == 2:\n",
    "        L = np.zeros((N-2, N))\n",
    "        for i in range(N-2):\n",
    "            L[i, i] = 1\n",
    "            L[i, i+1] = -2\n",
    "            L[i, i+2] = 1\n",
    "    else:\n",
    "        raise ValueError(\"diff_order 0/1/2 only\")\n",
    "    # Augmented system trick: [A; sqrt(lam)*L] p = [y; 0]\n",
    "    A_aug = np.vstack([A, np.sqrt(lam)*L])\n",
    "    y_aug = np.concatenate([y, np.zeros(L.shape[0])])\n",
    "    if nonneg:\n",
    "        res = lsq_linear(A_aug, y_aug, bounds=(0, np.inf), lsmr_tol='auto', max_iter=2000)\n",
    "        p = res.x\n",
    "    else:\n",
    "        # analytical solution via normal eqn (A^T A + lam L^T L) p = A^T y\n",
    "        ATA = A.T @ A\n",
    "        LTL = L.T @ L\n",
    "        mat = ATA + lam * LTL\n",
    "        rhs = A.T @ y\n",
    "        p = np.linalg.solve(mat, rhs)\n",
    "    return p\n",
    "\n",
    "# -----------------------------\n",
    "# Method 3: CDF-based (interpolate CDF, then differentiate)\n",
    "# -----------------------------\n",
    "def cdf_from_ipdf(ipdf, bin_edges):\n",
    "    \"\"\"\n",
    "    ipdf: integrated pdf over each bin (i.e., integral value)\n",
    "    bin_edges: edges len M+1\n",
    "    返回 CDF at bin edges (len M+1)\n",
    "    \"\"\"\n",
    "    # cumulative: CDF at right edge k = sum_{i<=k-1} ipdf[i]\n",
    "    cdf = np.zeros(len(bin_edges))\n",
    "    cdf[1:] = np.cumsum(ipdf)\n",
    "    return cdf\n",
    "\n",
    "def pdf_from_cdf_interp(bin_edges, ipdf, num_out_pts_per_bin=10, monotone=True):\n",
    "    cdf = cdf_from_ipdf(ipdf, bin_edges)\n",
    "    # CDF defined at edges (x_0 ... x_M)\n",
    "    xs = bin_edges\n",
    "    ys = cdf\n",
    "    # use monotone (PCHIP) to avoid oscillation\n",
    "    interp = PchipInterpolator(xs, ys) if monotone else PchipInterpolator(xs, ys)  # PCHIP monotone-like\n",
    "    x_dense = np.linspace(xs[0], xs[-1], (len(xs)-1)*num_out_pts_per_bin)\n",
    "    cdf_dense = interp(x_dense)\n",
    "    # derivative (numerical)\n",
    "    pdf_dense = np.gradient(cdf_dense, x_dense)\n",
    "    return x_dense, pdf_dense, interp\n",
    "\n",
    "# -----------------------------\n",
    "# Bootstrap error estimate\n",
    "# -----------------------------\n",
    "def bootstrap_pdf(A, ipdf, solve_func, nboot=200, noise_scale=None, **solve_kwargs):\n",
    "    \"\"\"\n",
    "    ipdf: observed integrated values (shape M)\n",
    "    noise_scale: if None, estimate from residuals; else used as std dev\n",
    "    solve_func: function(A, y, **solve_kwargs) -> p\n",
    "    returns mean_p, std_p\n",
    "    \"\"\"\n",
    "    M = len(ipdf)\n",
    "    # estimate residual std if not provided\n",
    "    if noise_scale is None:\n",
    "        # simple estimate: small constant fraction\n",
    "        noise_scale = max(1e-6, 0.01 * np.median(np.abs(ipdf)))\n",
    "    ps = []\n",
    "    for _ in range(nboot):\n",
    "        yb = ipdf + np.random.normal(0, noise_scale, size=M)\n",
    "        p = solve_func(A, yb, **solve_kwargs)\n",
    "        ps.append(p)\n",
    "    ps = np.array(ps)\n",
    "    return ps.mean(axis=0), ps.std(axis=0)\n",
    "\n",
    "# 构造样例：真实 PDF（smooth）\n",
    "xgrid = np.linspace(0, 10, 501)  # fine grid boundaries\n",
    "# true pdf (normalized)\n",
    "xc = (xgrid[:-1] + xgrid[1:]) / 2\n",
    "true_pdf = np.exp(-0.5*((xc-5)/0.6)**2)\n",
    "true_pdf /= np.trapezoid(true_pdf, xc)  # normalize\n",
    "\n",
    "# define measurement bins (coarser)\n",
    "bin_edges = np.linspace(0, 10, 41)  # 40 bins\n",
    "bc = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "# generate IPDF = integral over bins\n",
    "A = build_A(bin_edges, xgrid)\n",
    "ipdf = A @ true_pdf  # exact integrals\n",
    "# add noise\n",
    "ipdf_noise = ipdf + 0.01 * np.max(ipdf) * np.random.randn(len(ipdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6aa46323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 1: naive\n",
    "centers_naive, pdf_naive = naive_pdf_from_ipdf(ipdf_noise, bin_edges)\n",
    "\n",
    "# Method 2: tikhonov ls (nonneg)\n",
    "# Build a coarser grid for p unknowns (use xgrid cell-average as unknowns)\n",
    "A_fine = A.copy()\n",
    "# for _ in range(100):\n",
    "p_est_reg = tikhonov_inversion(A_fine, ipdf_noise, lam=1e-2, nonneg=True, diff_order=2)\n",
    "\n",
    "# Method 3: cdf interp\n",
    "x_dense, pdf_dense, interp_cdf = pdf_from_cdf_interp(bin_edges, ipdf_noise, num_out_pts_per_bin=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e5f1136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bootstrap error for method 2\n",
    "mean_p, std_p = bootstrap_pdf(A_fine, ipdf_noise, tikhonov_inversion, nboot=200, lam=1e-2, nonneg=True, diff_order=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78771cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(xc, true_pdf, label='true pdf', lw=2)\n",
    "# plt.plot(centers_naive, pdf_naive, 'x-', label='naive ipdf/Δx')\n",
    "plt.plot(xc, p_est_reg, '-', label='tikhonov reg (est)', lw=2)\n",
    "plt.fill_between(xc, mean_p-std_p, mean_p+std_p, color='gray', alpha=0.8, label='bootstrap ±1σ (reg)')\n",
    "# plt.plot(x_dense, pdf_dense, '--', label='from CDF interp')\n",
    "\n",
    "\n",
    "# plt.plot(bc, ipdf, label='true pdf', lw=2)\n",
    "# plt.plot(bc, ipdf_noise, label='true pdf', lw=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('pdf')\n",
    "plt.title('Reconstruction from IPDF (demo)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2376e45",
   "metadata": {},
   "source": [
    "### Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97621014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as ipdf_to_pdf_examples.py\n",
    "import numpy as np\n",
    "from scipy import optimize, integrate, special\n",
    "from scipy.optimize import lsq_linear\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- helper: build Δx from sample points (centers) ----------\n",
    "def estimate_bin_edges_from_centers(x):\n",
    "    x = np.asarray(x)\n",
    "    order = np.argsort(x)\n",
    "    xs = x[order]\n",
    "    # internal edges: midpoints\n",
    "    mid = 0.5*(xs[1:] + xs[:-1])\n",
    "    edges = np.empty(len(xs)+1)\n",
    "    edges[1:-1] = mid\n",
    "    edges[0] = xs[0] - (mid[0]-xs[0])\n",
    "    edges[-1]= xs[-1] + (xs[-1]-mid[-1])\n",
    "    widths = edges[1:] - edges[:-1]\n",
    "    return edges, widths, order\n",
    "\n",
    "# ---------- synthesize data: true gaussian, compute IPDF (integrals) ----------\n",
    "def synth_ipdf_from_pdf(pdf_fun, edges):\n",
    "    # edges: bin edges array length n+1\n",
    "    b = np.array([integrate.quad(pdf_fun, edges[i], edges[i+1])[0] for i in range(len(edges)-1)])\n",
    "    return b\n",
    "\n",
    "# ---------- Method A: parametric Gaussian fit via minimizing bin-integral squared error ----------\n",
    "def fit_gaussian_by_bin_integrals(x_centers, ipdf, edges):\n",
    "    # model: normal pdf with params (mu, sigma)\n",
    "    def model_bin_integrals(params):\n",
    "        mu, log_sigma = params\n",
    "        sigma = np.exp(log_sigma)\n",
    "        cdf = lambda z: 0.5*(1 + special.erf((z - mu)/(sigma*np.sqrt(2))))\n",
    "        ints = np.array([cdf(edges[i+1]) - cdf(edges[i]) for i in range(len(edges)-1)])\n",
    "        return ints\n",
    "    def loss(params):\n",
    "        ints = model_bin_integrals(params)\n",
    "        return np.sum((ints - ipdf)**2)\n",
    "    # init: mean ~ weighted center, sigma ~ std estimate\n",
    "    mu0 = (x_centers * ipdf).sum() / ipdf.sum()\n",
    "    sigma0 = max(1e-3, np.sqrt(np.abs(( (x_centers-mu0)**2 * ipdf ).sum() / ipdf.sum())))\n",
    "    res = optimize.minimize(loss, x0=[mu0, np.log(sigma0)], method='L-BFGS-B')\n",
    "    mu_hat, sigma_hat = res.x[0], np.exp(res.x[1])\n",
    "    return mu_hat, sigma_hat, res\n",
    "\n",
    "# ---------- Method B: linear inversion with Tikhonov (discrete grid) ----------\n",
    "def tikhonov_inversion(x_grid, x_centers, ipdf, edges, lam=1e-2, order=2):\n",
    "    # Discretize PDF on x_grid; build A such that ipdf ~= A @ p * dx\n",
    "    dx = np.diff(x_grid)\n",
    "    nx = len(x_grid)\n",
    "    m = len(ipdf)\n",
    "    A = np.zeros((m, nx))\n",
    "    # for each bin, mark grid points whose centers lie inside bin, use trapezoid weighting\n",
    "    for i in range(m):\n",
    "        left, right = edges[i], edges[i+1]\n",
    "        # compute overlap of each grid cell [xj - dxj/2, xj + dxj/2] with [left,right]\n",
    "        cell_left = x_grid - 0.5*np.concatenate(([dx[0]], dx))[:nx]  # approximate\n",
    "        cell_right = x_grid + 0.5*np.concatenate((dx, [dx[-1]]))[:nx]\n",
    "        overlap = np.maximum(0, np.minimum(cell_right, right) - np.maximum(cell_left, left))\n",
    "        A[i,:] = overlap  # so ipdf_i ~= sum_j overlap_j * p_j\n",
    "    # regularization matrix D (finite difference)\n",
    "    if order==2:\n",
    "        D = np.zeros((nx-2, nx))\n",
    "        for i in range(nx-2):\n",
    "            D[i, i] = 1\n",
    "            D[i, i+1] = -2\n",
    "            D[i, i+2] = 1\n",
    "    else:\n",
    "        D = np.eye(nx)\n",
    "    # augment system: [A; sqrt(lam)*D] p = [ipdf; 0]\n",
    "    sqrtlam = np.sqrt(lam)\n",
    "    A_aug = np.vstack([A, sqrtlam * D])\n",
    "    b_aug = np.concatenate([ipdf, np.zeros(D.shape[0])])\n",
    "    # bounds: nonnegativity\n",
    "    res = lsq_linear(A_aug, b_aug, bounds=(0, np.inf), lsmr_tol='auto', max_iter=2000)\n",
    "    p = res.x\n",
    "    # convert p from \"per-grid-cell integral\" to density: divide by cell widths\n",
    "    # But our A already used overlaps, so p approximates density values; more robust: normalize\n",
    "    return p, res\n",
    "\n",
    "# ---------- Method C: Richardson-Lucy style for linear operator A ----------\n",
    "def richardson_lucy_matrix(A, b, iters=100, eps=1e-12):\n",
    "    # A: m x n, b: m\n",
    "    m, n = A.shape\n",
    "    p = np.ones(n)\n",
    "    At1 = A.sum(axis=0)  # A^T 1\n",
    "    for k in range(iters):\n",
    "        Ap = A.dot(p) + eps\n",
    "        ratio = b / Ap\n",
    "        update = A.T.dot(ratio)\n",
    "        p = p * (update / (At1 + eps))\n",
    "        # optional: enforce nonnegativity trivially by clipping\n",
    "        p = np.maximum(p, 0)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "# 1) define true pdf (gaussian)\n",
    "mu_true = 0.5; sigma_true = 0.2\n",
    "pdf_true = lambda x: (1/(sigma_true*np.sqrt(2*np.pi)))*np.exp(-0.5*((x-mu_true)/sigma_true)**2)\n",
    "# build a fine grid for true pdf visualization\n",
    "xgrid_fine = np.linspace(-0.5, 1.5, 2000)\n",
    "pdf_vals = pdf_true(xgrid_fine)\n",
    "# 2) sample non-uniform centers and estimate edges\n",
    "centers = np.sort(np.concatenate([np.linspace(-0.4,0.2,10), np.linspace(0.25,1.4,20)]))\n",
    "edges, widths, order = estimate_bin_edges_from_centers(centers)\n",
    "# 3) synthesize IPDF by integrating true pdf over edges\n",
    "b = synth_ipdf_from_pdf(pdf_true, edges)\n",
    "# add small noise\n",
    "noise_level = 1e-1\n",
    "b_noisy = b + np.random.normal(0, noise_level, b.shape) * b\n",
    "# b_noisy = np.clip(b_noisy, 0, None)\n",
    "\n",
    "# Method A: parametric gaussian fit\n",
    "mu_hat, sigma_hat, resA = fit_gaussian_by_bin_integrals(centers, b_noisy, edges)\n",
    "print(\"Param fit: mu_hat, sigma_hat =\", mu_hat, sigma_hat)\n",
    "\n",
    "# Method B: Tikhonov inversion on grid\n",
    "x_grid = np.linspace(-0.6, 1.6, 300)\n",
    "p_tik, resB = tikhonov_inversion(x_grid, centers, b_noisy, edges, lam=1e-3, order=2)\n",
    "\n",
    "# Method C: RL using same A as in B\n",
    "# rebuild A used earlier:\n",
    "dx = np.diff(x_grid)\n",
    "nx = len(x_grid)\n",
    "m = len(b_noisy)\n",
    "A = np.zeros((m, nx))\n",
    "cell_left = x_grid - 0.5*np.concatenate(([dx[0]], dx))[:nx]\n",
    "cell_right = x_grid + 0.5*np.concatenate((dx, [dx[-1]]))[:nx]\n",
    "for i in range(m):\n",
    "    left, right = edges[i], edges[i+1]\n",
    "    overlap = np.maximum(0, np.minimum(cell_right, right) - np.maximum(cell_left, left))\n",
    "    A[i,:] = overlap\n",
    "p0 = np.ones(nx)\n",
    "p_rl = richardson_lucy_matrix(A, b_noisy, iters=200)\n",
    "\n",
    "# normalize densities for plotting\n",
    "p_tik = p_tik / (np.trapezoid(p_tik, x_grid) + 1e-12)\n",
    "p_rl  = p_rl  / (np.trapezoid(p_rl, x_grid) + 1e-12)\n",
    "pdf_true_norm = pdf_vals / (np.trapz(pdf_vals, xgrid_fine))\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(xgrid_fine, pdf_true_norm, label='true pdf')\n",
    "plt.plot(x_grid, p_tik, label='tikhonov')\n",
    "plt.plot(x_grid, p_rl, label='richardson-lucy')\n",
    "# param fit pdf\n",
    "pdf_param = lambda x: (1/(sigma_hat*np.sqrt(2*np.pi)))*np.exp(-0.5*((x-mu_hat)/sigma_hat)**2)\n",
    "plt.plot(xgrid_fine, pdf_param(xgrid_fine), '--', label='param gaussian fit')\n",
    "plt.legend(); plt.title('PDF recovery examples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac288ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(centers, b)\n",
    "plt.scatter(centers, b_noisy)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1abe8660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12d43bae0d0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def ipdf_to_pdf(ipdf_x, ipdf_p, pdf_x, s=0.001):\n",
    "    # 排序输入数据（确保x单调增加）\n",
    "    idx = np.argsort(ipdf_x)\n",
    "    x = np.array(ipdf_x)[idx]\n",
    "    p = np.array(ipdf_p)[idx]\n",
    "    n = len(x)\n",
    "    # 估计每个IPDF点对应的区间边界（取相邻中点的中间为边界）\n",
    "    edges = np.empty(n+1)\n",
    "    edges[1:n] = (x[:-1] + x[1:]) / 2\n",
    "    # 外推两端边界\n",
    "    edges[0] = x[0] - (x[1] - x[0]) / 2 if n>1 else x[0] - 0.5\n",
    "    edges[n] = x[-1] + (x[-1] - x[-2]) / 2 if n>1 else x[0] + 0.5\n",
    "    # 确保概率非负并归一化\n",
    "    p = np.clip(p, 0, None)\n",
    "    # if p.sum() > 0:\n",
    "    #     p = p / p.sum()\n",
    "    # 计算累积分布函数 (CDF) 在每个边界处的值\n",
    "    cdf_x = edges\n",
    "    cdf_y = np.concatenate(([0], np.cumsum(p)))\n",
    "    # 用样条拟合CDF数据并求导得到PDF\n",
    "    spl = UnivariateSpline(cdf_x, cdf_y, k=3, s=s)\n",
    "    pdf_y = spl.derivative()(pdf_x)\n",
    "    # 截断微小的负值并再次归一化PDF（确保概率意义）\n",
    "    pdf_y[pdf_y < 0] = 0.0\n",
    "    # pdf_y /= np.trapz(pdf_y, pdf_x)\n",
    "    return pdf_y\n",
    "\n",
    "# 示例：对给定IPDF数据（x位置和对应概率）估计PDF\n",
    "# ipdf_x = np.array([-2, -1, 0, 1, 2])            # IPDF中心点（不均匀分布）\n",
    "# ipdf_p = np.array([0.13, 0.34, 0.35, 0.13, 0.05])*10  # 每个区间的概率（含噪声）\n",
    "ipdf_x = np.log10(tau_ii)         # IPDF中心点（不均匀分布）\n",
    "ipdf_p = R_ii  # 每个区间的概率（含噪声）\n",
    "pdf_x = np.linspace(math.floor(np.min(ipdf_x)), math.ceil(np.max(ipdf_x)), 51)      # 希望输出PDF的x网格（均匀）\n",
    "pdf_est = ipdf_to_pdf(ipdf_x, ipdf_p, pdf_x)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(pdf_x, pdf_est)\n",
    "plt.scatter(ipdf_x, ipdf_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca2f706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ii = _R_i\n",
    "tau_ii = _tau_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199ff9f",
   "metadata": {},
   "source": [
    "## CDF + Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "215f904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def _centers_to_edges(x):\n",
    "    \"\"\"把区间中心点 x 转成边界 edges（两端用相邻间距外推）。\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    n = len(x)\n",
    "    edges = np.empty(n + 1, dtype=float)\n",
    "    if n == 1:  # 退化情形\n",
    "        h = 0.5\n",
    "        edges[0], edges[1] = x[0] - h, x[0] + h\n",
    "        return edges\n",
    "    edges[1:n] = 0.5 * (x[:-1] + x[1:])\n",
    "    edges[0]   = x[0] - 0.5 * (x[1] - x[0])\n",
    "    edges[n]   = x[-1] + 0.5 * (x[-1] - x[-2])\n",
    "    return edges\n",
    "\n",
    "def _logit(u, eps=1e-9):\n",
    "    u = np.clip(u, eps, 1.0 - eps)\n",
    "    return np.log(u) - np.log(1.0 - u)\n",
    "\n",
    "def _sigmoid(z):\n",
    "    # 数值稳定版 sigmoid\n",
    "    out = np.empty_like(z, dtype=float)\n",
    "    pos = z >= 0\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def _cdf_from_ipdf(ipdf_p):\n",
    "    \"\"\"由区间概率 p 得到边界上的 CDF（左->右）。\"\"\"\n",
    "    p = np.asarray(ipdf_p, dtype=float)\n",
    "    p = np.clip(p, 0, None)\n",
    "    if p.sum() > 0:\n",
    "        p = p / p.sum()\n",
    "    F_edges = np.concatenate(([0.0], np.cumsum(p)))\n",
    "    return F_edges\n",
    "\n",
    "def _right_cumulative(ipdf_p):\n",
    "    \"\"\"右向累积（生存函数 S 的“右->左”累加）；返回与 edges 对齐的 1 - F_R。\"\"\"\n",
    "    p = np.asarray(ipdf_p, dtype=float)\n",
    "    p = np.clip(p, 0, None)\n",
    "    if p.sum() > 0:\n",
    "        p = p / p.sum()\n",
    "    # 从右往左：S_k = sum_{i>=k} p_i, 于是 F_R = 1 - S\n",
    "    S_edges_right2left = np.concatenate((np.cumsum(p[::-1])[::-1], [0.0]))  # 与左边界对齐\n",
    "    F_from_right = 1.0 - S_edges_right2left\n",
    "    return F_from_right\n",
    "\n",
    "def _default_cdf_weights(n_edges):\n",
    "    \"\"\"\n",
    "    对 CDF 点做简单方差加权：w_k ~ 1/sqrt(k+1) ，\n",
    "    反映左->右累加时误差方差递增的趋势（不知道真实方差时的保守缺省）。\n",
    "    \"\"\"\n",
    "    k = np.arange(n_edges, dtype=float)  # 0..n\n",
    "    w = 1.0 / np.sqrt(k + 1.0)\n",
    "    # 两端稍微减弱一点，防止边界“拉扯”\n",
    "    w[0] *= 0.7\n",
    "    w[-1] *= 0.7\n",
    "    return w\n",
    "\n",
    "def _fit_logit_cdf_and_diff(edges, F_edges, s=0.0, w=None):\n",
    "    \"\"\"\n",
    "    在 logit(F) 上做样条拟合，返回在任意 x 上评估 PDF 的闭包：\n",
    "      f(x) = sigmoid(g(x)) * (1 - sigmoid(g(x))) * g'(x)\n",
    "    \"\"\"\n",
    "    if w is None:\n",
    "        w = _default_cdf_weights(len(edges))\n",
    "    g_vals = _logit(F_edges)\n",
    "    spl = UnivariateSpline(edges, g_vals, w=w, s=s, k=3)\n",
    "    def pdf_eval(x):\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        g = spl(x)\n",
    "        gp = spl.derivative()(x)\n",
    "        sig = _sigmoid(g)\n",
    "        f = sig * (1.0 - sig) * gp\n",
    "        return f\n",
    "    return pdf_eval\n",
    "\n",
    "def pdf_from_ipdf_logit_two_sided(ipdf_x, ipdf_p, pdf_x, s=0.0, blend_width=0.2, eps=1e-12):\n",
    "    \"\"\"\n",
    "    方案A：双向累积 + logit(CDF) 样条 + 链式法则求导，并在中部平滑融合左右两个 PDF 估计。\n",
    "    参数：\n",
    "      ipdf_x: 区间中心点（不必均匀）\n",
    "      ipdf_p: 对应每个区间的概率（可带噪声，和不要求正好为1）\n",
    "      pdf_x : 需要输出 PDF 的均匀网格\n",
    "      s     : 样条平滑参数（越大越平滑；可用CV/网格搜索）\n",
    "      blend_width: 融合带宽（占整体区间长度的比例，0.1~0.3 常用）\n",
    "      eps   : 数值稳定项\n",
    "    返回：\n",
    "      pdf_y : 在 pdf_x 上的 PDF 估计（>=0，已归一化）\n",
    "    \"\"\"\n",
    "    ipdf_x = np.asarray(ipdf_x, dtype=float)\n",
    "    ipdf_p = np.asarray(ipdf_p, dtype=float)\n",
    "    pdf_x  = np.asarray(pdf_x, dtype=float)\n",
    "\n",
    "    # 1) 构造边界\n",
    "    edges = _centers_to_edges(ipdf_x)\n",
    "\n",
    "    # 2) 左累积的 CDF，并在 logit 空间拟合\n",
    "    F_L = _cdf_from_ipdf(ipdf_p)\n",
    "    wL  = _default_cdf_weights(len(edges))\n",
    "    pdf_L = _fit_logit_cdf_and_diff(edges, F_L, s=s, w=wL)\n",
    "\n",
    "    # 3) 右累积（通过 F_R=1-S），同样拟合\n",
    "    F_R = _right_cumulative(ipdf_p)\n",
    "    wR  = wL[::-1]  # 右侧也做相反方向的方差加权\n",
    "    pdf_R = _fit_logit_cdf_and_diff(edges, F_R, s=s, w=wR)\n",
    "\n",
    "    fL = np.maximum(pdf_L(pdf_x), 0.0)\n",
    "    fR = np.maximum(pdf_R(pdf_x), 0.0)\n",
    "\n",
    "    # 4) 在中部平滑融合：靠左更信任 fL，靠右更信任 fR\n",
    "    x_left, x_right = edges[0], edges[-1]\n",
    "    xm = 0.5 * (x_left + x_right)\n",
    "    width = blend_width * (x_right - x_left)\n",
    "    # logistic 融合权\n",
    "    alpha = 1.0 / (1.0 + np.exp((pdf_x - xm) / (width + 1e-12)))\n",
    "\n",
    "    f = alpha * fL + (1.0 - alpha) * fR\n",
    "\n",
    "    # 5) 数值修正与归一化\n",
    "    f = np.clip(f, 0.0, None)\n",
    "    area = np.trapz(f, pdf_x)\n",
    "    if area > 0:\n",
    "        f = f / area\n",
    "    else:\n",
    "        # 极端失败时（几乎不发生），退回均匀\n",
    "        dx = np.mean(np.diff(pdf_x))\n",
    "        f = np.ones_like(pdf_x) / (len(pdf_x) * dx)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a1c75e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_4868\\734958049.py:127: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area = np.trapz(f, pdf_x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12d504585d0>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例：带噪声的“钟形”IPDF（以高斯为例）\n",
    "rng = np.random.default_rng(0)\n",
    "true_pdf = lambda x: np.exp(-0.5*x**2)/np.sqrt(2*np.pi)\n",
    "# 构造不均匀区间中心与区间概率（加噪声）\n",
    "ipdf_x = np.array([-3.0, -1.8, -1.2, -0.6, -0.2, 0.2, 0.6, 1.0, 1.6, 2.6])\n",
    "edges = _centers_to_edges(ipdf_x)\n",
    "# 理论区间概率\n",
    "from scipy.stats import norm\n",
    "p_clean = norm.cdf(edges[1:]) - norm.cdf(edges[:-1])\n",
    "# 加噪声（正负都有，随后会归一化）\n",
    "noise = 0.05 * rng.normal(size=p_clean.size)  # 5% 噪声\n",
    "ipdf_p = np.clip(p_clean + noise, 0, None)\n",
    "if ipdf_p.sum() > 0:\n",
    "    ipdf_p /= ipdf_p.sum()\n",
    "\n",
    "pdf_x = np.linspace(edges[0], edges[-1], 501)\n",
    "pdf_est = pdf_from_ipdf_logit_two_sided(ipdf_x, ipdf_p, pdf_x, s=1e-3, blend_width=0.2)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(pdf_x, pdf_est, color = 'red')\n",
    "plt.scatter(pdf_x, true_pdf(pdf_x), color = 'blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c749c560",
   "metadata": {},
   "source": [
    "## CDF Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "461450b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "\n",
    "def _centers_to_edges(x):\n",
    "    x = np.asarray(x, float)\n",
    "    idx = np.argsort(x); x = x[idx]\n",
    "    n = x.size\n",
    "    edges = np.empty(n+1, float)\n",
    "    if n == 1:\n",
    "        h = 0.5\n",
    "        edges[:] = (x[0]-h, x[0]+h)\n",
    "        return edges\n",
    "    edges[1:-1] = 0.5*(x[:-1] + x[1:])\n",
    "    edges[0]    = x[0] - 0.5*(x[1] - x[0])\n",
    "    edges[-1]   = x[-1] + 0.5*(x[-1] - x[-2])\n",
    "    return edges\n",
    "\n",
    "def _logit(u, eps=1e-9):\n",
    "    u = np.clip(u, eps, 1.0-eps)\n",
    "    return np.log(u) - np.log(1.0 - u)\n",
    "\n",
    "def _sigmoid(z):\n",
    "    out = np.empty_like(z, float)\n",
    "    pos = z >= 0\n",
    "    out[pos]  = 1.0/(1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez/(1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def _cdf_from_ipdf(p):\n",
    "    p = np.asarray(p, float)\n",
    "    p = np.clip(p, 0, None)\n",
    "    s = p.sum()\n",
    "    if s > 0: p = p/s\n",
    "    return np.concatenate(([0.0], np.cumsum(p)))\n",
    "\n",
    "def _cdf_from_right(p):\n",
    "    p = np.asarray(p, float)\n",
    "    p = np.clip(p, 0, None)\n",
    "    s = p.sum()\n",
    "    if s > 0: p = p/s\n",
    "    # 右向累积的生存函数 S：S_k = sum_{i>=k} p_i\n",
    "    S_edges = np.concatenate((np.cumsum(p[::-1])[::-1], [0.0]))\n",
    "    F_from_right = 1.0 - S_edges\n",
    "    return F_from_right\n",
    "\n",
    "def _fit_logit_cdf_pchip(edges, F_edges):\n",
    "    \"\"\"\n",
    "    在 g=logit(F) 上做 PCHIP（单调、无超调），返回可评估 PDF 的闭包：\n",
    "      f(x) = sigma(g)*(1-sigma(g)) * g'(x)\n",
    "    \"\"\"\n",
    "    g = _logit(F_edges)\n",
    "    # PCHIP 对单调的 g 会给出单调插值；g'(x) >= 0\n",
    "    g_spline = PchipInterpolator(edges, g, extrapolate=True)\n",
    "    def pdf_eval(x):\n",
    "        x = np.asarray(x, float)\n",
    "        g_val = g_spline(x)\n",
    "        gp    = g_spline.derivative()(x)\n",
    "        sig   = _sigmoid(g_val)\n",
    "        f     = sig*(1.0 - sig)*gp\n",
    "        return f\n",
    "    return pdf_eval\n",
    "\n",
    "def pdf_from_ipdf_logit_pchip_two_sided(ipdf_x, ipdf_p, pdf_x, blend_width=0.2):\n",
    "    \"\"\"\n",
    "    双向累积 + logit(CDF) + PCHIP + 融合（单组 IPDF 版本）\n",
    "    - ipdf_x: 区间中心（可不均匀）\n",
    "    - ipdf_p: 该组区间概率（可带噪声）\n",
    "    - pdf_x : 输出网格（一般均匀）\n",
    "    - blend_width: 左右 PDF 融合的过渡带（占区间长度比例）\n",
    "    \"\"\"\n",
    "    ipdf_x = np.asarray(ipdf_x, float)\n",
    "    ipdf_p = np.asarray(ipdf_p, float)\n",
    "    pdf_x  = np.asarray(pdf_x,  float)\n",
    "\n",
    "    edges = _centers_to_edges(ipdf_x)\n",
    "\n",
    "    # 左累积 & 右累积\n",
    "    F_L = _cdf_from_ipdf(ipdf_p)\n",
    "    F_R = _cdf_from_right(ipdf_p)\n",
    "\n",
    "    # 在 logit(CDF) 上用 PCHIP，保证单调且抑制超调\n",
    "    pdf_L = _fit_logit_cdf_pchip(edges, F_L)\n",
    "    pdf_R = _fit_logit_cdf_pchip(edges, F_R)\n",
    "\n",
    "    fL = np.maximum(pdf_L(pdf_x), 0.0)\n",
    "    fR = np.maximum(pdf_R(pdf_x), 0.0)\n",
    "\n",
    "    # 平滑融合：靠左更信任 fL，靠右更信任 fR\n",
    "    xL, xR = edges[0], edges[-1]\n",
    "    xm = 0.5*(xL + xR)\n",
    "    width = max(1e-12, blend_width * (xR - xL))\n",
    "    alpha = 1.0/(1.0 + np.exp((pdf_x - xm)/width))\n",
    "    f = alpha*fL + (1.0 - alpha)*fR\n",
    "\n",
    "    # 归一化 & 裁负\n",
    "    f = np.clip(f, 0.0, None)\n",
    "    area = np.trapz(f, pdf_x)\n",
    "    if area > 0:\n",
    "        f /= area\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0f001cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baihm\\AppData\\Local\\Temp\\4\\ipykernel_4868\\731505302.py:98: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area = np.trapz(f, pdf_x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12d4cbfee50>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例：带噪声的“钟形”IPDF（以高斯为例）\n",
    "rng = np.random.default_rng(0)\n",
    "true_pdf = lambda x: np.exp(-0.5*x**2)/np.sqrt(2*np.pi)\n",
    "# 构造不均匀区间中心与区间概率（加噪声）\n",
    "ipdf_x = np.array([-3.0, -1.8, -1.2, -0.6, -0.2, 0.2, 0.6, 1.0, 1.6, 2.6])\n",
    "edges = _centers_to_edges(ipdf_x)\n",
    "# 理论区间概率\n",
    "from scipy.stats import norm\n",
    "p_clean = norm.cdf(edges[1:]) - norm.cdf(edges[:-1])\n",
    "# 加噪声（正负都有，随后会归一化）\n",
    "noise = 0.05 * rng.normal(size=p_clean.size)  # 5% 噪声\n",
    "ipdf_p = np.clip(p_clean + noise, 0, None)\n",
    "if ipdf_p.sum() > 0:\n",
    "    ipdf_p /= ipdf_p.sum()\n",
    "\n",
    "pdf_x = np.linspace(edges[0], edges[-1], 501)\n",
    "pdf_est = pdf_from_ipdf_logit_pchip_two_sided(ipdf_x, ipdf_p, pdf_x, blend_width=0.2)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(pdf_x, pdf_est, color = 'red')\n",
    "plt.scatter(pdf_x, true_pdf(pdf_x), color = 'blue')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EISNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
